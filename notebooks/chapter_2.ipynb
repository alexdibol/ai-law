{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPGWV/IoVd3gq6+krj2v+70"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**AI LAW CHAPTER 2. REASONERS**\n","\n","---"],"metadata":{"id":"axVMdlGDGhAC"}},{"cell_type":"markdown","source":["##0.REFERENCE"],"metadata":{"id":"u5OWIx6NGpFp"}},{"cell_type":"markdown","source":["https://claude.ai/share/81dba05d-a509-4849-81ff-6606716fd5fb"],"metadata":{"id":"fHYT_7LZGfvj"}},{"cell_type":"markdown","source":["##1.CONTEXT"],"metadata":{"id":"Rw-rzMZ4GrXp"}},{"cell_type":"markdown","source":["**Introduction: Why Legal AI Must Be Different from Chatbots**\n","\n","**What You Already Know About AI**\n","\n","If you have used ChatGPT, Claude, or any AI chatbot on a website or mobile app, you already understand the basic concept. You type a question or request, the AI generates a response, and you read what it says. Maybe you ask follow-up questions. Maybe you copy the response into a document. This conversational back-and-forth feels natural and helpful. For many everyday tasks like brainstorming ideas, explaining concepts, or drafting casual emails, this simple chat interface works perfectly well.\n","\n","**Why Legal Work Demands Something Fundamentally Different**\n","\n","Legal practice cannot work this way. When you chat casually with an AI, the conversation disappears when you close the window. There is no record of what you asked or what the AI told you. There is no systematic way to verify the accuracy of responses. There is no mechanism to flag risks or track what still needs human verification. There is no audit trail showing that you exercised reasonable supervision over the AI's work. For a lawyer, all of these missing pieces create serious professional responsibility problems.\n","\n","Imagine a scenario where a client later claims you gave bad advice based on AI output. Can you prove what prompt you sent? Can you demonstrate that you verified the AI's reasoning before relying on it? Can you show that you identified the limitations and risks? Without systems to create these records, you have no defense. This notebook exists because legal AI must be engineered differently from consumer chatbots. It must create audit trails, enforce verification requirements, protect confidentiality, and produce structured outputs that enable systematic review.\n","\n","**What This Notebook Actually Does**\n","\n","This notebook transforms the casual chat experience into a professional workflow with governance guardrails. Instead of typing freely into a chat window, you work with predefined scenarios or carefully structured custom inputs. Instead of receiving freeform conversational responses, you get strictly formatted JSON outputs that always include the same components: facts provided, assumptions made, open questions identified, issues spotted, analysis structure, argument mapping, risk flags, and verification requirements. Instead of responses disappearing into the ether, every API call gets logged with cryptographic hashes, every identified risk gets recorded, and everything gets packaged into a downloadable archive.\n","\n","Think of it this way. A consumer chatbot is like having an informal conversation with a smart colleague over coffee. This notebook is like conducting a formal case analysis session with that same colleague while a court reporter creates a transcript, a supervisor takes notes about what needs verification, and a compliance officer flags potential concerns. The underlying AI is the same, but the surrounding infrastructure transforms it from a casual tool into a professional system.\n","\n","**Understanding Chapter 2: The Reasoning Stage**\n","\n","This notebook implements what we call Chapter 2 or Level 2 capabilities, which focus on structured legal reasoning rather than document drafting. If you worked through a Chapter 1 notebook, you saw AI used primarily for creating draft documents, writing sections of briefs, or generating contract language. That was about production. Chapter 2 is about analysis. It is about the thinking that happens before you write anything.\n","\n","When you start working on a new legal matter, you do not immediately begin drafting. First you identify what legal issues are present. You figure out what facts you have and what facts you still need. You map out possible arguments and anticipate counterarguments. You spot the weak points in your position. You create a mental or written structure for how the analysis should flow, often using frameworks like IRAC where you identify the Issue, state the Rule, Apply the facts to the rule, and reach a Conclusion. Chapter 2 is about getting AI support for this pre-drafting reasoning work.\n","\n","Why does this matter? Because this early analytical stage is where many legal mistakes originate. You miss a key issue. You fail to recognize a missing fact that undermines your whole theory. You overlook a strong counterargument. You proceed based on assumptions that turn out to be wrong. By getting structured reasoning support at this stage, with explicit identification of assumptions and gaps, you reduce the risk of analytical blind spots while still maintaining full human control over the ultimate legal judgments.\n","\n","**The Four Practice Area Demonstrations**\n","\n","This notebook includes four mini-cases spanning different areas of legal practice. The criminal defense scenario involves bail motion reasoning where you have limited facts about a defendant and must identify what factors matter, what information is missing, and what arguments could be made. The regulatory compliance scenario involves comment letter strategy where a client faces proposed regulations and you must map argument options and verification requirements. The international commercial scenario involves governing law and arbitration choices where you must analyze tradeoffs and assumptions. The teaching scenario involves academic policy development where you must spot enforceability and equity issues.\n","\n","These four scenarios serve multiple purposes. They demonstrate that the structured reasoning framework works across diverse legal contexts, not just one narrow specialty. They provide concrete examples of what good AI reasoning support looks like so you can develop intuition about appropriate use cases. They let you see the outputs before running your own scenarios, building confidence that the system produces useful results. Most importantly, they show you what Level 2 reasoning support is and is not. It is not legal advice. It is not final work product. It is analytical scaffolding that still requires your professional judgment to verify and complete.\n","\n","**Why Governance Systems Are Not Optional**\n","\n","Throughout this notebook you will encounter governance systems that might seem like bureaucratic overhead. Why do we need a run manifest? Why log every API call with cryptographic hashes? Why create a risk log? Why generate an audit readme? Why package everything into a zip archive? These systems exist because of professional responsibility requirements and practical risk management.\n","\n","Bar associations increasingly recognize that lawyers may use AI tools, but they emphasize that lawyers remain responsible for the work product. You cannot blame the AI if something goes wrong. You must exercise competent supervision, which requires understanding what the AI did and verifying its outputs. The governance systems in this notebook create the documentation that proves you exercised such supervision. The manifest shows what system you used. The logs show what inputs you provided and what outputs you received. The risk flags show what concerns were identified for follow-up. The verification checklists show what you still need to confirm independently.\n","\n","Beyond professional responsibility compliance, these governance systems provide practical protection. If a client relationship ever goes bad and leads to a malpractice claim or grievance, your contemporaneous documentation of reasonable AI supervision becomes crucial evidence. If your firm or legal department faces an audit about AI usage, having structured records makes compliance review straightforward rather than a nightmare investigation. If you need to reconstruct your reasoning process months later when memories have faded, the archived records provide reliable documentation.\n","\n","**Confidentiality Controls You Must Understand**\n","\n","The notebook includes redaction tools that attempt to remove sensitive information before sending anything to the AI. Email addresses, phone numbers, social security numbers, and some address patterns get automatically masked. The notebook also implements data minimization, sending only the information actually needed for analysis. Every API call gets logged in redacted form with cryptographic hashes that prove integrity without exposing content.\n","\n","You must understand that these protections, while helpful, are not perfect. Automated redaction cannot catch everything. Client names that do not appear in email addresses might slip through. Sensitive business information has no standard pattern to detect. The fundamental limitation is that using any external API means sending information to a third-party service over the internet. The notebook strongly warns you to use only hypothetical scenarios, not actual client data. This warning is not legal boilerplate. It is genuine advice about managing risk you cannot fully eliminate through technical controls.\n","\n","**What Success Looks Like**\n","\n","When you complete this notebook successfully, you will have processed four predefined scenarios and one custom scenario of your own design. For each scenario, you will have a structured JSON output and a human-readable text memo. You will have a risk log showing what concerns were flagged. You will have a complete audit trail showing what prompts were sent and what responses were received. You will have a zip archive containing everything, documented with an audit readme that explains what verification you must still perform.\n","\n","More importantly, you will have learned what structured legal reasoning support feels like. You will understand the difference between getting AI help with pre-drafting analysis versus having AI draft final documents. You will have developed intuition about what scenarios work well for this kind of support and what scenarios do not. You will have seen firsthand how governance systems create professional accountability rather than hindering productivity. You will be better positioned to have informed conversations with colleagues, clients, and supervisors about responsible AI integration in legal practice.\n","\n","**Moving Beyond Chat Interfaces**\n","\n","The fundamental message of this notebook is that legal AI must evolve beyond simple chat interfaces. Chat is fine for brainstorming or learning about unfamiliar topics. But for legal reasoning that might influence client advice or case strategy, you need structure, verification requirements, audit trails, and risk management. You need systems designed for professional accountability, not just casual convenience.\n","\n","This notebook represents one approach to that evolution. It is not the only possible approach, and it will continue to improve as technology advances and best practices develop. But it demonstrates core principles that any responsible legal AI system should embody: structured outputs that enable systematic review, explicit identification of assumptions and gaps, mandatory verification requirements, comprehensive audit trails, confidentiality protections with acknowledged limitations, and clear warnings about what the system can and cannot do.\n","\n","By working through this notebook, you are not just learning to use a specific tool. You are learning to think critically about what legal AI systems should look like when designed with professional responsibility in mind. That critical perspective will serve you well regardless of what specific AI tools you use in the future."],"metadata":{"id":"0UuQ4dJZUaI-"}},{"cell_type":"markdown","source":["##2.LIBRARIES AND ENVIRONMENT"],"metadata":{"id":"ovboO-4FGu0G"}},{"cell_type":"code","source":["# Cell 2: Install Dependencies and Create Run Directory\n","\n","print(\"=\" * 60)\n","print(\"CELL 2: SETUP - INSTALL & RUN DIRECTORY\")\n","print(\"=\" * 60)\n","\n","# Install Anthropic SDK\n","print(\"\\n[1/2] Installing anthropic SDK...\")\n","!pip install -q anthropic\n","\n","print(\"âœ… anthropic SDK installed\\n\")\n","\n","# Create timestamped run directory\n","import os\n","from datetime import datetime\n","\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","RUN_DIR = f\"/content/ai_law_ch2_runs/run_{timestamp}\"\n","DELIVERABLES_DIR = os.path.join(RUN_DIR, \"deliverables\")\n","\n","os.makedirs(DELIVERABLES_DIR, exist_ok=True)\n","\n","print(f\"[2/2] Created run directory:\")\n","print(f\"    ðŸ“ {RUN_DIR}\")\n","print(f\"    ðŸ“ {DELIVERABLES_DIR}\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"âœ… CELL 2 COMPLETE\")\n","print(\"=\" * 60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLcgiUT8HNGS","executionInfo":{"status":"ok","timestamp":1767800378078,"user_tz":360,"elapsed":6094,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"006f8a49-9aea-4b3a-adc3-e3510b853025"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","CELL 2: SETUP - INSTALL & RUN DIRECTORY\n","============================================================\n","\n","[1/2] Installing anthropic SDK...\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hâœ… anthropic SDK installed\n","\n","[2/2] Created run directory:\n","    ðŸ“ /content/ai_law_ch2_runs/run_20260107_153938\n","    ðŸ“ /content/ai_law_ch2_runs/run_20260107_153938/deliverables\n","\n","============================================================\n","âœ… CELL 2 COMPLETE\n","============================================================\n"]}]},{"cell_type":"markdown","source":["## 3.API KEY AND CLIENT INITIALIZATION"],"metadata":{"id":"xe1fL9ozHE4U"}},{"cell_type":"markdown","source":["###3.1.OVERVIEW"],"metadata":{"id":"N9aDUpQzHPYw"}},{"cell_type":"markdown","source":["**Understanding Section 3: Connecting to Claude's Brain**\n","\n","**What This Section Does**\n","\n","Section 3 is where we establish the connection between your Google Colab notebook and the Anthropic API. Think of it like plugging in a phone charger - without this connection, nothing else in the notebook will work. This section retrieves your secret API key from Colab's secure storage and uses it to create a client object that can talk to Claude.\n","\n","**Why We Need an API Key**\n","\n","The API key is like a password that proves you have permission to use Claude. Anthropic needs to know who is making requests so they can track usage, prevent abuse, and bill accordingly. Your key is unique to you and should never be shared with others. If someone else gets your key, they could use Claude on your account and you would be charged for their usage.\n","\n","**How Colab Secrets Work**\n","\n","Google Colab provides a special feature called Secrets that stores sensitive information like API keys in an encrypted format. When you add your Anthropic API key to Colab Secrets, it is stored securely on Google's servers. The notebook can retrieve it when needed, but the key never appears in your code or outputs where others might see it. This is much safer than typing your API key directly into the code, which could accidentally be shared or exposed.\n","\n","**The Client Object**\n","\n","Once we retrieve the API key, we create something called a client object. This is a software tool that knows how to communicate with Anthropic's servers. Think of it like a telephone that is already programmed with the right number - you just pick it up and start talking, without having to dial manually each time. The client handles all the technical details of sending your prompts to Claude and receiving responses back.\n","\n","**The Model Name**\n","\n","We also specify which version of Claude we want to use. In this notebook, we use Claude Sonnet 4.5, which is identified by the technical name provided. Different Claude models have different capabilities and costs. By setting this at the beginning, every time we call Claude later in the notebook, it will automatically use this specific model version.\n","\n","**What Happens If This Fails**\n","\n","If Section 3 cannot find your API key in Colab Secrets, the entire notebook will stop and show an error message. This is intentional - it prevents you from running dozens of cells only to discover at the end that nothing worked because the connection was never established. The error message tells you exactly what to do: go to the Secrets menu and add your key.\n","\n","**Moving Forward**\n","\n","Once Section 3 completes successfully, you will see confirmation messages showing that the API key was loaded and the client was initialized. At this point, the notebook is fully connected to Claude and ready to start making API calls in the later sections."],"metadata":{"id":"hhttIdnXHUF0"}},{"cell_type":"markdown","source":["###3.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"S3iat42yHUbB"}},{"cell_type":"code","source":["# Cell 3: API Key and Client Initialization\n","\n","print(\"=\" * 60)\n","print(\"CELL 3: API KEY & CLIENT SETUP\")\n","print(\"=\" * 60)\n","\n","import anthropic\n","import os\n","from google.colab import userdata\n","\n","# Retrieve API key from Colab Secrets\n","try:\n","    ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n","    os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n","    print(\"\\nâœ… API key loaded from Colab Secrets\")\n","except Exception as e:\n","    print(f\"\\nâŒ ERROR: Could not load API key from Colab Secrets\")\n","    print(f\"    Error: {e}\")\n","    print(\"\\n    âš ï¸  Please add ANTHROPIC_API_KEY to Colab Secrets:\")\n","    print(\"    Left sidebar â†’ ðŸ”‘ Secrets â†’ Add new secret\")\n","    raise\n","\n","# Initialize Anthropic client\n","client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n","MODEL = \"claude-sonnet-4-5-20250929\"\n","\n","print(f\"âœ… Anthropic client initialized\")\n","print(f\"ðŸ“‹ Model: {MODEL}\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"âœ… CELL 3 COMPLETE\")\n","print(\"=\" * 60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmAOf1XdHzcM","executionInfo":{"status":"ok","timestamp":1767800547960,"user_tz":360,"elapsed":3466,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"692b3020-2d2c-4a1f-b5c3-7cbfd46f1d6e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","CELL 3: API KEY & CLIENT SETUP\n","============================================================\n","\n","âœ… API key loaded from Colab Secrets\n","âœ… Anthropic client initialized\n","ðŸ“‹ Model: claude-sonnet-4-5-20250929\n","\n","============================================================\n","âœ… CELL 3 COMPLETE\n","============================================================\n"]}]},{"cell_type":"markdown","source":["##4.GOVERNANCE UTILITIES"],"metadata":{"id":"9N0BFIksH8gW"}},{"cell_type":"markdown","source":["###4.1.OVERVIEW"],"metadata":{"id":"a6P7FplQH_e4"}},{"cell_type":"markdown","source":["**Understanding Section 4: Building the Audit Trail Foundation**\n","\n","**What This Section Does**\n","\n","Section 4 creates the governance infrastructure that tracks everything happening in this notebook. Think of it like setting up a detailed logbook before a ship leaves port. Every decision, every API call, every risk identified will be recorded in structured files that lawyers and compliance officers can review later. This section creates those empty logbooks and writes the initial metadata about this particular run.\n","\n","**Why Governance Matters for Lawyers**\n","\n","Lawyers operate under strict professional responsibility rules. When using AI tools, you need to be able to demonstrate that you exercised reasonable supervision, maintained client confidentiality, and verified any AI outputs before relying on them. The governance artifacts created in this section provide that documentation trail. If a client ever questions your use of AI, or if a bar association asks how you ensured quality control, these files contain the evidence.\n","\n","**The Run Manifest File**\n","\n","The first file created is the run manifest, which is like a shipping label for this entire notebook session. It records the timestamp showing exactly when you ran the notebook, which Claude model you used, what capabilities you were testing, and other metadata. Think of it as the cover page of a lab report. Years from now, if you need to understand what happened during this run, the manifest tells you the who, what, when, and how.\n","\n","**The Prompts Log**\n","\n","The prompts log is a line-by-line record of every time this notebook sends something to Claude and receives a response. However, it does not store the full text of your prompts or Claude's responses because those might contain confidential information. Instead, it stores redacted previews and cryptographic hashes. A hash is like a fingerprint for text - it is a unique code that proves the text has not been altered, without revealing what the text actually says. This way you can prove you sent specific prompts without exposing privileged content.\n","\n","**The Risk Log**\n","\n","The risk log starts empty but will fill up as the notebook runs. Every time the system detects a potential issue - missing facts, possible confidentiality concerns, signs of AI overconfidence, or other red flags - an entry gets added here. Think of it like a safety inspector's checklist. At the end of your run, you can review this log to see what concerns were flagged and decide whether they require further action before using any AI outputs.\n","\n","**The Package Freeze File**\n","\n","This technical file records every software library and version number installed in your Python environment. Why does this matter? Reproducibility. If someone questions your results or wants to replicate your analysis, they need to know exactly what software versions you were using. Different versions of the same library can sometimes produce different results. The package freeze ensures that anyone can recreate your exact technical environment.\n","\n","**How These Files Work Together**\n","\n","These four files form an interconnected system. The manifest provides overview information. The prompts log shows what you asked and what you received. The risk log highlights concerns that emerged. The package freeze documents the technical foundation. Together they create a complete audit trail that satisfies both technical reproducibility standards and legal professional responsibility requirements.\n","\n","**What Makes This Different from Chapter 1**\n","\n","If you completed a Chapter 1 notebook, you may notice this governance layer is more sophisticated. Chapter 2 focuses on reasoning support rather than simple drafting, which means the stakes are higher. The analysis outputs could influence legal strategy decisions. Therefore, the governance requirements tighten - more logging, more risk tracking, more verification requirements."],"metadata":{"id":"rhu3jMG8IRVV"}},{"cell_type":"markdown","source":["###4.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"8ZKv95TwIBGr"}},{"cell_type":"code","source":["# Cell 4: Governance Utilities and Artifact Initialization\n","\n","print(\"=\" * 60)\n","print(\"CELL 4: GOVERNANCE ARTIFACTS\")\n","print(\"=\" * 60)\n","\n","import json\n","import hashlib\n","from datetime import datetime\n","\n","# Initialize run_manifest.json\n","manifest = {\n","    \"run_id\": timestamp,\n","    \"created_at\": datetime.now().isoformat(),\n","    \"notebook\": \"AI_for_Lawyers_Ch2_Level2_Reasoners\",\n","    \"model\": MODEL,\n","    \"author\": \"Alejandro Reynoso\",\n","    \"chapter\": \"Chapter 2 - Level 2: Reasoners\",\n","    \"capabilities\": [\n","        \"issue_spotting\",\n","        \"irac_structure\",\n","        \"argument_mapping\",\n","        \"risk_controlled_reasoning\"\n","    ],\n","    \"governance_mode\": \"strict_json_with_audit_trail\"\n","}\n","\n","manifest_path = os.path.join(RUN_DIR, \"run_manifest.json\")\n","with open(manifest_path, 'w') as f:\n","    json.dump(manifest, f, indent=2)\n","\n","print(f\"\\n[1/4] âœ… run_manifest.json created\")\n","print(f\"       {manifest_path}\")\n","\n","# Initialize prompts_log.jsonl\n","prompts_log_path = os.path.join(RUN_DIR, \"prompts_log.jsonl\")\n","with open(prompts_log_path, 'w') as f:\n","    f.write(\"\")  # Create empty file\n","\n","print(f\"\\n[2/4] âœ… prompts_log.jsonl initialized\")\n","print(f\"       {prompts_log_path}\")\n","\n","# Initialize risk_log.json\n","risk_log = {\n","    \"run_id\": timestamp,\n","    \"risks\": []\n","}\n","\n","risk_log_path = os.path.join(RUN_DIR, \"risk_log.json\")\n","with open(risk_log_path, 'w') as f:\n","    json.dump(risk_log, f, indent=2)\n","\n","print(f\"\\n[3/4] âœ… risk_log.json initialized\")\n","print(f\"       {risk_log_path}\")\n","\n","# Save pip freeze for reproducibility\n","pip_freeze_path = os.path.join(RUN_DIR, \"pip_freeze.txt\")\n","!pip freeze > {pip_freeze_path}\n","\n","print(f\"\\n[4/4] âœ… pip_freeze.txt saved\")\n","print(f\"       {pip_freeze_path}\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"âœ… CELL 4 COMPLETE - All governance artifacts initialized\")\n","print(\"=\" * 60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmqYDGGnIC62","executionInfo":{"status":"ok","timestamp":1767800614435,"user_tz":360,"elapsed":1421,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"abdb9a43-224e-4b6c-ffc1-4b4d914b82e0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","CELL 4: GOVERNANCE ARTIFACTS\n","============================================================\n","\n","[1/4] âœ… run_manifest.json created\n","       /content/ai_law_ch2_runs/run_20260107_153938/run_manifest.json\n","\n","[2/4] âœ… prompts_log.jsonl initialized\n","       /content/ai_law_ch2_runs/run_20260107_153938/prompts_log.jsonl\n","\n","[3/4] âœ… risk_log.json initialized\n","       /content/ai_law_ch2_runs/run_20260107_153938/risk_log.json\n","\n","[4/4] âœ… pip_freeze.txt saved\n","       /content/ai_law_ch2_runs/run_20260107_153938/pip_freeze.txt\n","\n","============================================================\n","âœ… CELL 4 COMPLETE - All governance artifacts initialized\n","============================================================\n"]}]},{"cell_type":"markdown","source":["##5.REDACTION AND MINIMUM NECESSARY INTAKE"],"metadata":{"id":"iX5hq_6hITw1"}},{"cell_type":"markdown","source":["###5.1.OVERVIEW"],"metadata":{"id":"E9_JroB0IVeh"}},{"cell_type":"markdown","source":["**Understanding Section 5: Protecting Confidential Information**\n","\n","**What This Section Does**\n","\n","Section 5 provides tools to remove sensitive information from text before it gets sent to Claude or written to log files. Think of it like a document redaction tool that lawyers use to black out privileged content before filing papers in court. This section includes two main utilities: a redaction function that finds and masks personal identifiers, and a data minimization function that strips away unnecessary fields from structured data.\n","\n","**Why Redaction Matters in Legal Practice**\n","\n","Lawyers handle extremely sensitive information every day. Client names, contact details, social security numbers, and addresses are all protected by confidentiality rules and privacy laws. When you use a third-party API like Claude, your prompts travel over the internet to Anthropic's servers. Even though Anthropic has strong security practices, the safest approach is to never send unredacted privileged information in the first place. Redaction creates a protective barrier.\n","\n","**What the Redaction Function Catches**\n","\n","The redaction utility scans text looking for common patterns of sensitive data. It finds email addresses by looking for the at-symbol and domain structures. It catches phone numbers in various formats, whether they use dashes, dots, or parentheses. It identifies social security numbers by their distinctive three-dash-two-dash-four pattern. It even attempts to find street addresses by looking for number-plus-street-name combinations. When it finds these patterns, it replaces them with placeholder text like brackets containing the word redacted.\n","\n","**The Limitations You Must Understand**\n","\n","This automated redaction is helpful but far from perfect. It cannot catch everything. Client names that do not follow standard email or phone patterns will slip through. Unusual address formats might not be recognized. Sensitive business information, trade secrets, or case strategy details have no standard pattern for the tool to detect. Think of automated redaction as a first-pass filter, not a complete solution. Your own judgment about what to include or exclude remains essential.\n","\n","**Data Minimization: Keeping Only What You Need**\n","\n","The second utility demonstrates a principle called data minimization. Imagine you have a data structure containing ten fields about a client, but your analysis only needs three of them. The minimization function keeps those three necessary fields and discards the other seven. Why does this matter? Every piece of information you send to an external API creates potential exposure. If you do not need the client's home address to analyze a contract clause, do not include it. Send the minimum necessary information to accomplish your task.\n","\n","**The Demonstration with Fake Data**\n","\n","Section 5 includes a demonstration using obviously fake information like example email addresses and made-up social security numbers. This shows you exactly what the redaction looks like in practice. You can see the before and after versions side by side. The demonstration also shows what gets removed by data minimization. This hands-on preview helps you understand what these tools do before you use them with real scenarios.\n","\n","**The Critical Warning**\n","\n","At the end of this section, you see a prominent warning that redaction is imperfect and should be used with caution. This is not legal boilerplate. It is a genuine warning about technical limitations. No automated system can perfectly identify all sensitive information in natural language text. The tool provides a layer of protection, but your professional judgment about what information to input remains the primary safeguard. When in doubt, make the scenario more hypothetical or use placeholder names from the start.\n","\n","**Building Good Habits**\n","\n","Section 5 establishes a workflow pattern that carries through the rest of the notebook. Before sending anything to Claude, think about what information is truly necessary. Strip out unnecessary identifiers. Use generic descriptions rather than specific names when possible. Treat the redaction function as one tool in a larger practice of careful information handling, not as a complete solution that eliminates all risk."],"metadata":{"id":"O4_AgOD0R4aU"}},{"cell_type":"markdown","source":["###5.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"fNajipTSIXOz"}},{"cell_type":"code","source":["# Cell 5: Redaction and Minimum-Necessary Intake\n","\n","print(\"=\" * 60)\n","print(\"CELL 5: REDACTION & DATA MINIMIZATION\")\n","print(\"=\" * 60)\n","\n","import re\n","\n","def redact(text):\n","    \"\"\"\n","    Redact sensitive information from text.\n","    WARNING: This is imperfect. Do not rely on it for actual client data.\n","    \"\"\"\n","    if not text:\n","        return text\n","\n","    redacted = text\n","    removed_items = []\n","\n","    # Redact email addresses\n","    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n","    emails_found = re.findall(email_pattern, redacted)\n","    if emails_found:\n","        removed_items.append(f\"{len(emails_found)} email(s)\")\n","    redacted = re.sub(email_pattern, '[EMAIL_REDACTED]', redacted)\n","\n","    # Redact phone numbers (various formats)\n","    phone_pattern = r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b|\\(\\d{3}\\)\\s*\\d{3}[-.]?\\d{4}'\n","    phones_found = re.findall(phone_pattern, redacted)\n","    if phones_found:\n","        removed_items.append(f\"{len(phones_found)} phone number(s)\")\n","    redacted = re.sub(phone_pattern, '[PHONE_REDACTED]', redacted)\n","\n","    # Redact SSNs\n","    ssn_pattern = r'\\b\\d{3}-\\d{2}-\\d{4}\\b'\n","    ssns_found = re.findall(ssn_pattern, redacted)\n","    if ssns_found:\n","        removed_items.append(f\"{len(ssns_found)} SSN(s)\")\n","    redacted = re.sub(ssn_pattern, '[SSN_REDACTED]', redacted)\n","\n","    # Best-effort address redaction (street numbers + street names)\n","    address_pattern = r'\\b\\d+\\s+[A-Z][a-z]+\\s+(Street|St|Avenue|Ave|Road|Rd|Boulevard|Blvd|Lane|Ln|Drive|Dr|Court|Ct)\\b'\n","    addresses_found = re.findall(address_pattern, redacted)\n","    if addresses_found:\n","        removed_items.append(f\"{len(addresses_found)} address(es)\")\n","    redacted = re.sub(address_pattern, '[ADDRESS_REDACTED]', redacted)\n","\n","    return redacted, removed_items\n","\n","def minimize_intake(data_dict, necessary_fields):\n","    \"\"\"\n","    Keep only necessary fields from input data.\n","    Returns minimized dict and list of removed fields.\n","    \"\"\"\n","    minimized = {k: v for k, v in data_dict.items() if k in necessary_fields}\n","    removed_fields = [k for k in data_dict.keys() if k not in necessary_fields]\n","    return minimized, removed_fields\n","\n","# Demonstration with fake data\n","print(\"\\nðŸ“‹ DEMONSTRATION: Redaction\")\n","print(\"-\" * 60)\n","\n","fake_text = \"\"\"\n","Client John Doe (john.doe@example.com, 555-123-4567)\n","resides at 123 Main Street and has SSN 123-45-6789.\n","Contact via johndoe@gmail.com or call (555) 987-6543.\n","\"\"\"\n","\n","print(\"BEFORE REDACTION:\")\n","print(fake_text)\n","\n","redacted_text, removed = redact(fake_text)\n","\n","print(\"\\nAFTER REDACTION:\")\n","print(redacted_text)\n","\n","print(f\"\\nREMOVED: {', '.join(removed) if removed else 'None'}\")\n","\n","print(\"\\n\" + \"-\" * 60)\n","print(\"ðŸ“‹ DEMONSTRATION: Data Minimization\")\n","print(\"-\" * 60)\n","\n","fake_data = {\n","    \"client_name\": \"Jane Smith\",\n","    \"case_type\": \"criminal_defense\",\n","    \"court\": \"Superior Court\",\n","    \"home_address\": \"456 Oak Avenue\",\n","    \"credit_card\": \"4532-xxxx-xxxx-1234\",\n","    \"charge\": \"misdemeanor\"\n","}\n","\n","necessary = [\"case_type\", \"court\", \"charge\"]\n","\n","minimized, removed_fields = minimize_intake(fake_data, necessary)\n","\n","print(\"ORIGINAL DATA:\")\n","print(json.dumps(fake_data, indent=2))\n","\n","print(\"\\nMINIMIZED DATA (only necessary fields):\")\n","print(json.dumps(minimized, indent=2))\n","\n","print(f\"\\nREMOVED FIELDS: {removed_fields}\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"âœ… CELL 5 COMPLETE - Redaction utilities ready\")\n","print(\"âš ï¸  WARNING: Redaction is imperfect. Use with caution.\")\n","print(\"=\" * 60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ji4zQGmKIa8d","executionInfo":{"status":"ok","timestamp":1767800717296,"user_tz":360,"elapsed":48,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"6a929b3a-3bd2-4219-e5b7-4d2cb6a2a6e1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","CELL 5: REDACTION & DATA MINIMIZATION\n","============================================================\n","\n","ðŸ“‹ DEMONSTRATION: Redaction\n","------------------------------------------------------------\n","BEFORE REDACTION:\n","\n","Client John Doe (john.doe@example.com, 555-123-4567) \n","resides at 123 Main Street and has SSN 123-45-6789.\n","Contact via johndoe@gmail.com or call (555) 987-6543.\n","\n","\n","AFTER REDACTION:\n","\n","Client John Doe ([EMAIL_REDACTED], [PHONE_REDACTED]) \n","resides at [ADDRESS_REDACTED] and has SSN [SSN_REDACTED].\n","Contact via [EMAIL_REDACTED] or call [PHONE_REDACTED].\n","\n","\n","REMOVED: 2 email(s), 2 phone number(s), 1 SSN(s), 1 address(es)\n","\n","------------------------------------------------------------\n","ðŸ“‹ DEMONSTRATION: Data Minimization\n","------------------------------------------------------------\n","ORIGINAL DATA:\n","{\n","  \"client_name\": \"Jane Smith\",\n","  \"case_type\": \"criminal_defense\",\n","  \"court\": \"Superior Court\",\n","  \"home_address\": \"456 Oak Avenue\",\n","  \"credit_card\": \"4532-xxxx-xxxx-1234\",\n","  \"charge\": \"misdemeanor\"\n","}\n","\n","MINIMIZED DATA (only necessary fields):\n","{\n","  \"case_type\": \"criminal_defense\",\n","  \"court\": \"Superior Court\",\n","  \"charge\": \"misdemeanor\"\n","}\n","\n","REMOVED FIELDS: ['client_name', 'home_address', 'credit_card']\n","\n","============================================================\n","âœ… CELL 5 COMPLETE - Redaction utilities ready\n","âš ï¸  WARNING: Redaction is imperfect. Use with caution.\n","============================================================\n"]}]},{"cell_type":"markdown","source":["##6.CLAUDE WRAPPER"],"metadata":{"id":"eZSI3AH_ItlU"}},{"cell_type":"markdown","source":["###6.1.OVERVIEW"],"metadata":{"id":"sINZtpGQIyTy"}},{"cell_type":"markdown","source":["**Understanding Section 6: Teaching Claude to Speak Pure JSON**\n","\n","**What This Section Does**\n","\n","Section 6 is the technical heart of the entire notebook. It creates a wrapper function that knows how to talk to Claude and force it to respond in a very specific structured format called JSON. Think of JSON as a standardized filing system where every piece of information has a labeled drawer. This section also includes multiple backup strategies for extracting that structured data even when Claude tries to add extra explanatory text, plus validation to ensure every required piece is present.\n","\n","**Why Structured Output Matters for Legal Work**\n","\n","When lawyers use AI for reasoning support, they need consistent, predictable outputs that can be reviewed systematically. Imagine if every legal memo came back in a completely different format - sometimes bullets, sometimes paragraphs, sometimes mixing the two randomly. You could not build a reliable review process. By forcing all outputs into the same JSON structure, you can always find the issues spotted in one place, the open questions in another place, and the risk flags in a third place. This consistency enables systematic verification.\n","\n","**The Challenge: Claude Wants to Be Helpful**\n","\n","Claude is trained to be conversational and helpful to humans. When you ask it a question, its natural instinct is to provide some explanatory text, then give you the answer, then maybe add some closing thoughts. For general conversation this is great. For programmatic workflows it is a disaster. If you ask Claude for JSON and it responds with a paragraph explaining what it is about to do, followed by the JSON, followed by a note about limitations, your code cannot parse that. The wrapper function in Section 6 fights against Claude's helpful instincts.\n","\n","**The Prefill Technique: Starting Claude's Response**\n","\n","The most important innovation in Section 6 is called prefill. Instead of just sending Claude a prompt and hoping it responds with pure JSON, we actually start Claude's response for it by providing the opening curly brace. Imagine interrupting someone who is about to give you a long explanation and handing them a form to fill out instead. The prefill technique tells Claude that its response has already started with an opening brace, so it must continue from there by completing the JSON object. This dramatically improves reliability.\n","\n","**Multiple Extraction Strategies: Belt and Suspenders**\n","\n","Even with prefill, sometimes Claude wraps the JSON in markdown code fences or adds a tiny bit of text. Section 6 includes four different strategies for finding and extracting the JSON from Claude's response. The first strategy tries to parse the entire response as JSON directly. If that fails, the second strategy looks for the first opening brace and last closing brace and extracts everything in between. The third strategy handles the specific case where Claude puts the JSON inside triple-backtick code blocks. The fourth strategy carefully counts braces to find a complete JSON object even if buried in other text. These layers of fallback ensure high reliability.\n","\n","**Schema Validation: Checking Every Required Piece**\n","\n","Getting JSON back from Claude is not enough. You need to verify that the JSON contains all the required fields and that each field has the right type of data. The validation function checks that every expected key exists, that lists are actually lists and not strings, that dictionaries are actually dictionaries and not lists. It also catches unexpected extra fields that were not in the specification. Think of it like a quality control inspector checking that every part is present before a product leaves the factory.\n","\n","**The Retry Logic: Three Attempts**\n","\n","If the first API call fails to produce valid JSON, Section 6 does not give up. It tries again with a lower temperature setting, which makes Claude more focused and less creative. It also adds an even more aggressive prefix to the prompt demanding pure JSON output. If that second attempt fails, it tries a third time with the same strict settings. Only after three failed attempts does the system give up and return an error fallback object. This retry logic turns occasional failures into rare exceptions.\n","\n","**The Error Fallback: Always Return Valid Structure**\n","\n","Here is a critical design decision. Even when all three attempts fail, the wrapper function does not crash or return nothing. Instead it returns a carefully constructed error object that matches the exact same JSON schema as a successful response. Every field is present, just with empty or error values. The draft output field contains an error message. The risks array includes a high-severity entry explaining what went wrong. This ensures that downstream code expecting a certain structure never breaks, even during failures.\n","\n","**Logging Everything for Audit Trails**\n","\n","Every API call gets logged to the prompts log file. However, the logging is done carefully to protect confidentiality. The actual prompt and response are redacted using the tools from Section 5. Only previews and cryptographic hashes are stored. This creates an auditable record that proves what was sent and received without exposing privileged content. If you ever need to demonstrate what prompts you used, the hashes provide cryptographic proof without revealing sensitive details.\n","\n","**Automatic Risk Detection**\n","\n","The wrapper function includes basic automatic risk flagging. It checks whether there are too many open questions, which suggests significant factual gaps. It verifies that the verification status field always says not verified, catching any instance where Claude might express inappropriate confidence. These automatically detected risks get logged to the risk log immediately, ensuring that warning signs are captured even if a human reviewer misses them initially.\n","\n","**The Smoke Test: Proving It Works**\n","\n","Section 6 ends with a smoke test that calls Claude with a very simple scenario and verifies that valid JSON comes back. This is like test-firing a new piece of equipment before putting it into production use. If the smoke test fails, you know immediately that something is wrong with the wrapper function, rather than discovering problems later after running all four mini-cases. The smoke test uses the simplest possible prompt to isolate whether the JSON extraction mechanism is working correctly.\n","\n","**Why This Complexity Is Necessary**\n","\n","You might wonder why Section 6 needs to be so elaborate. Why not just ask Claude nicely to output JSON? The answer lies in reliability requirements for legal workflows. In a casual conversation, a ninety percent success rate might be acceptable. For lawyer workflows where systematic verification depends on consistent structure, you need ninety-nine percent reliability. The prefill technique, multiple extraction strategies, schema validation, retry logic, and error fallbacks work together to achieve that higher standard. This is defense-in-depth engineering applied to AI integration."],"metadata":{"id":"T2YlZCCNMuH3"}},{"cell_type":"markdown","source":["###6.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"u466kza5Iz4V"}},{"cell_type":"code","source":["# Cell 6: Claude Wrapper with Strict JSON Extraction and Validation\n","\n","print(\"=\" * 60)\n","print(\"CELL 6: CLAUDE WRAPPER + JSON EXTRACTION + VALIDATION\")\n","print(\"=\" * 60)\n","\n","import json\n","import re\n","from datetime import datetime\n","\n","# Required JSON schema\n","REQUIRED_SCHEMA = {\n","    \"task\": str,\n","    \"facts_provided\": list,\n","    \"assumptions\": list,\n","    \"open_questions\": list,\n","    \"issues_spotted\": list,\n","    \"analysis_structure\": dict,\n","    \"argument_map\": dict,\n","    \"risks\": list,\n","    \"draft_output\": str,\n","    \"verification_status\": str,\n","    \"questions_to_verify\": list\n","}\n","\n","def extract_json_from_text(text):\n","    \"\"\"\n","    Extract JSON from text using multiple strategies.\n","    Returns (json_obj, strategy_used) or (None, error_msg)\n","    \"\"\"\n","    # Strategy 1: Direct parse\n","    try:\n","        obj = json.loads(text)\n","        return obj, \"strategy_1_direct\"\n","    except:\n","        pass\n","\n","    # Strategy 2: Slice from first { to last }\n","    try:\n","        first_brace = text.index('{')\n","        last_brace = text.rindex('}')\n","        json_str = text[first_brace:last_brace+1]\n","        obj = json.loads(json_str)\n","        return obj, \"strategy_2_slice\"\n","    except:\n","        pass\n","\n","    # Strategy 3: Handle ```json ... ``` code blocks\n","    try:\n","        pattern = r'```json\\s*(\\{.*?\\})\\s*```'\n","        match = re.search(pattern, text, re.DOTALL)\n","        if match:\n","            obj = json.loads(match.group(1))\n","            return obj, \"strategy_3_codeblock\"\n","    except:\n","        pass\n","\n","    # Strategy 4: Bracket-balancing scan\n","    try:\n","        brace_count = 0\n","        start_idx = None\n","        for i, char in enumerate(text):\n","            if char == '{':\n","                if start_idx is None:\n","                    start_idx = i\n","                brace_count += 1\n","            elif char == '}':\n","                brace_count -= 1\n","                if brace_count == 0 and start_idx is not None:\n","                    json_str = text[start_idx:i+1]\n","                    obj = json.loads(json_str)\n","                    return obj, \"strategy_4_balance\"\n","    except:\n","        pass\n","\n","    return None, \"all_strategies_failed\"\n","\n","def validate_schema(json_obj):\n","    \"\"\"\n","    Validate that JSON object matches required schema.\n","    Returns (is_valid, errors)\n","    \"\"\"\n","    errors = []\n","\n","    # Check required keys\n","    for key, expected_type in REQUIRED_SCHEMA.items():\n","        if key not in json_obj:\n","            errors.append(f\"Missing required key: {key}\")\n","        elif not isinstance(json_obj[key], expected_type):\n","            errors.append(f\"Key '{key}' has wrong type: expected {expected_type.__name__}, got {type(json_obj[key]).__name__}\")\n","\n","    # Check for extra keys\n","    extra_keys = set(json_obj.keys()) - set(REQUIRED_SCHEMA.keys())\n","    if extra_keys:\n","        errors.append(f\"Extra keys found: {extra_keys}\")\n","\n","    return len(errors) == 0, errors\n","\n","def log_prompt(task_name, redacted_prompt, redacted_response, prompt_hash, response_hash):\n","    \"\"\"Log API call to prompts_log.jsonl\"\"\"\n","    log_entry = {\n","        \"timestamp\": datetime.now().isoformat(),\n","        \"task_name\": task_name,\n","        \"prompt_preview\": redacted_prompt[:200] + \"...\" if len(redacted_prompt) > 200 else redacted_prompt,\n","        \"response_preview\": redacted_response[:200] + \"...\" if len(redacted_response) > 200 else redacted_response,\n","        \"prompt_hash\": prompt_hash,\n","        \"response_hash\": response_hash\n","    }\n","\n","    with open(prompts_log_path, 'a') as f:\n","        f.write(json.dumps(log_entry) + '\\n')\n","\n","def log_risk(risk_obj):\n","    \"\"\"Add risk to risk_log.json\"\"\"\n","    with open(risk_log_path, 'r') as f:\n","        risk_log = json.load(f)\n","\n","    risk_log[\"risks\"].append({\n","        \"timestamp\": datetime.now().isoformat(),\n","        **risk_obj\n","    })\n","\n","    with open(risk_log_path, 'w') as f:\n","        json.dump(risk_log, f, indent=2)\n","\n","def auto_flag_risks(json_obj):\n","    \"\"\"Automatically flag common risks in output\"\"\"\n","    auto_risks = []\n","\n","    # Check for missing facts\n","    if len(json_obj.get(\"open_questions\", [])) > 5:\n","        auto_risks.append({\n","            \"type\": \"missing_facts\",\n","            \"severity\": \"medium\",\n","            \"note\": f\"Many open questions ({len(json_obj['open_questions'])}) - significant factual gaps\"\n","        })\n","\n","    # Check for overconfidence (should always be \"Not verified\")\n","    if json_obj.get(\"verification_status\", \"\").lower() != \"not verified\":\n","        auto_risks.append({\n","            \"type\": \"overconfidence\",\n","            \"severity\": \"high\",\n","            \"note\": f\"Verification status is not 'Not verified': {json_obj['verification_status']}\"\n","        })\n","\n","    return auto_risks\n","\n","def call_claude(task_name, user_prompt, temperature=0.1, max_attempts=3):\n","    \"\"\"\n","    Call Claude API with strict JSON enforcement and retry logic.\n","    Uses prefill technique to force JSON output.\n","    Returns parsed JSON object matching schema or error fallback.\n","    \"\"\"\n","\n","    system_prompt = \"\"\"You are a legal reasoning assistant that outputs structured JSON analysis.\n","\n","You must respond with a valid JSON object matching this exact schema:\n","\n","{\n","  \"task\": \"description of analysis task\",\n","  \"facts_provided\": [\"fact 1\", \"fact 2\", ...],\n","  \"assumptions\": [\"assumption 1\", ...],\n","  \"open_questions\": [\"question 1\", ...],\n","  \"issues_spotted\": [\n","    {\n","      \"issue\": \"legal issue description\",\n","      \"why_it_matters\": \"significance\",\n","      \"missing_fact_dependency\": \"what facts are needed\"\n","    }\n","  ],\n","  \"analysis_structure\": {\n","    \"irac\": {\n","      \"issue\": \"main legal issue\",\n","      \"rule\": \"Not verified / source needed\",\n","      \"application\": \"facts applied to rule\",\n","      \"conclusion\": \"Tentative; Not verified\"\n","    }\n","  },\n","  \"argument_map\": {\n","    \"primary_position\": [\"argument 1\", \"argument 2\"],\n","    \"counterarguments\": [\"counter 1\", \"counter 2\"],\n","    \"weakest_links\": [\"weakness 1\", \"weakness 2\"]\n","  },\n","  \"risks\": [\n","    {\n","      \"type\": \"missing_facts\",\n","      \"severity\": \"medium\",\n","      \"note\": \"description\"\n","    }\n","  ],\n","  \"draft_output\": \"A structured memo (250-350 words) ending with: DISCLAIMER: This is a reasoning structure only. All analysis requires independent legal verification. Do not rely on this output without lawyer review.\",\n","  \"verification_status\": \"Not verified\",\n","  \"questions_to_verify\": [\"verification item 1\", ...]\n","}\n","\n","CRITICAL RULES:\n","- Output ONLY the JSON object\n","- \"rule\" must be \"Not verified / source needed\" unless user provides sources\n","- \"verification_status\" must always be \"Not verified\"\n","- \"draft_output\" must be 250-350 words and end with the disclaimer shown above\"\"\"\n","\n","    for attempt in range(1, max_attempts + 1):\n","        try:\n","            # Adjust temperature for retries\n","            temp = 0.0 if attempt > 1 else temperature\n","\n","            # Use prefill technique - provide the start of the assistant's response\n","            # This forces Claude to complete the JSON object\n","            messages = [\n","                {\"role\": \"user\", \"content\": user_prompt},\n","                {\"role\": \"assistant\", \"content\": \"{\"}  # Prefill - force JSON start\n","            ]\n","\n","            # Call API with prefill\n","            message = client.messages.create(\n","                model=MODEL,\n","                max_tokens=3000,\n","                temperature=temp,\n","                system=system_prompt,\n","                messages=messages\n","            )\n","\n","            # Prepend the { we used in prefill\n","            response_text = \"{\" + message.content[0].text\n","\n","            # Log API call (redacted with hashes)\n","            redacted_prompt = redact(user_prompt)[0]\n","            redacted_response = redact(response_text)[0]\n","            prompt_hash = hashlib.sha256(user_prompt.encode()).hexdigest()[:16]\n","            response_hash = hashlib.sha256(response_text.encode()).hexdigest()[:16]\n","            log_prompt(task_name, redacted_prompt, redacted_response, prompt_hash, response_hash)\n","\n","            # Extract JSON\n","            json_obj, strategy = extract_json_from_text(response_text)\n","\n","            if json_obj is None:\n","                print(f\"   âš ï¸  Attempt {attempt}/{max_attempts}: JSON extraction failed ({strategy})\")\n","                if attempt == max_attempts:\n","                    raise Exception(\"All JSON extraction strategies failed\")\n","                continue\n","\n","            # Validate schema\n","            is_valid, errors = validate_schema(json_obj)\n","\n","            if not is_valid:\n","                print(f\"   âš ï¸  Attempt {attempt}/{max_attempts}: Schema validation failed\")\n","                for err in errors[:3]:  # Show first 3 errors\n","                    print(f\"       - {err}\")\n","                if attempt == max_attempts:\n","                    raise Exception(f\"Schema validation failed: {errors}\")\n","                continue\n","\n","            # Auto-flag risks\n","            auto_risks = auto_flag_risks(json_obj)\n","            for risk in auto_risks:\n","                log_risk(risk)\n","\n","            # Log user-provided risks\n","            for risk in json_obj.get(\"risks\", []):\n","                log_risk(risk)\n","\n","            print(f\"   âœ… Success on attempt {attempt} (strategy: {strategy})\")\n","            return json_obj\n","\n","        except Exception as e:\n","            if attempt == max_attempts:\n","                # Return error fallback matching schema\n","                error_obj = {\n","                    \"task\": \"error_fallback\",\n","                    \"facts_provided\": [],\n","                    \"assumptions\": [],\n","                    \"open_questions\": [],\n","                    \"issues_spotted\": [],\n","                    \"analysis_structure\": {\n","                        \"irac\": {\n","                            \"issue\": \"Error processing request\",\n","                            \"rule\": \"Not verified / source needed\",\n","                            \"application\": \"Unable to complete analysis\",\n","                            \"conclusion\": \"Tentative; Not verified\"\n","                        }\n","                    },\n","                    \"argument_map\": {\n","                        \"primary_position\": [],\n","                        \"counterarguments\": [],\n","                        \"weakest_links\": []\n","                    },\n","                    \"risks\": [\n","                        {\n","                            \"type\": \"other\",\n","                            \"severity\": \"high\",\n","                            \"note\": f\"JSON_PARSE_ERROR: {str(e)}\"\n","                        }\n","                    ],\n","                    \"draft_output\": f\"ERROR: Unable to generate analysis due to technical error: {str(e)}\\n\\nDISCLAIMER: This is an error message. All analysis requires independent legal verification.\",\n","                    \"verification_status\": \"Not verified\",\n","                    \"questions_to_verify\": []\n","                }\n","\n","                log_risk(error_obj[\"risks\"][0])\n","                return error_obj\n","            else:\n","                print(f\"   âš ï¸  Attempt {attempt}/{max_attempts} failed: {str(e)}\")\n","\n","# SMOKE TEST\n","print(\"\\nðŸ§ª SMOKE TEST: Validating call_claude function with prefill\")\n","print(\"-\" * 60)\n","\n","test_prompt = \"\"\"Facts: Sales contract dispute. Delivery was 30 days late. Buyer refuses payment.\n","\n","Provide JSON analysis (250 words in draft_output).\"\"\"\n","\n","print(\"Running smoke test with prefill technique...\")\n","test_result = call_claude(\"smoke_test\", test_prompt, temperature=0.0, max_attempts=2)\n","\n","# Validate smoke test result\n","is_valid, errors = validate_schema(test_result)\n","\n","if is_valid:\n","    print(\"\\nâœ… SMOKE TEST PASSED\")\n","    print(f\"   - JSON parsed successfully\")\n","    print(f\"   - All required keys present\")\n","    print(f\"   - No extra keys\")\n","    print(f\"   - Task: {test_result['task'][:50]}...\")\n","    print(f\"   - Verification status: {test_result['verification_status']}\")\n","    if test_result['task'] != 'error_fallback':\n","        print(f\"   - Draft output length: {len(test_result['draft_output'])} chars\")\n","    else:\n","        print(f\"   âš ï¸  Note: Returned error_fallback\")\n","else:\n","    print(\"\\nâŒ SMOKE TEST FAILED\")\n","    for err in errors[:5]:\n","        print(f\"   - {err}\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"âœ… CELL 6 COMPLETE - Claude wrapper ready with prefill\")\n","print(\"=\" * 60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8V_jkB2PCiD","executionInfo":{"status":"ok","timestamp":1767802471824,"user_tz":360,"elapsed":34948,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"c8c3fe4e-7b58-48cc-d6b2-a77a3ed4fb20"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","CELL 6: CLAUDE WRAPPER + JSON EXTRACTION + VALIDATION\n","============================================================\n","\n","ðŸ§ª SMOKE TEST: Validating call_claude function with prefill\n","------------------------------------------------------------\n","Running smoke test with prefill technique...\n","   âœ… Success on attempt 1 (strategy: strategy_1_direct)\n","\n","âœ… SMOKE TEST PASSED\n","   - JSON parsed successfully\n","   - All required keys present\n","   - No extra keys\n","   - Task: Analyze sales contract dispute involving late deli...\n","   - Verification status: Not verified\n","   - Draft output length: 1919 chars\n","\n","============================================================\n","âœ… CELL 6 COMPLETE - Claude wrapper ready with prefill\n","============================================================\n"]}]},{"cell_type":"markdown","source":["##7.CASE BUILDERS"],"metadata":{"id":"OD32k8k4JJA8"}},{"cell_type":"markdown","source":["###7.1.OVERVIEW"],"metadata":{"id":"i99uyur_JKkU"}},{"cell_type":"markdown","source":["**Understanding Section 7: Designing the Four Legal Reasoning Scenarios**\n","\n","**What This Section Does**\n","\n","Section 7 defines four mini-cases that demonstrate how Claude can support structured legal reasoning across different practice areas. Each mini-case is a carefully crafted scenario with specific facts and a focused prompt that asks Claude to perform issue spotting, IRAC analysis, and argument mapping. Think of these as standardized test problems that show what Level 2 reasoning support looks like in criminal defense, regulatory compliance, international commercial law, and academic policy development.\n","\n","**Why Four Different Practice Areas**\n","\n","Legal practice is not monolithic. A criminal defense attorney thinks differently than a regulatory compliance specialist. An international transactions lawyer approaches problems differently than a law professor designing course policies. By including four diverse scenarios, this notebook demonstrates that the structured reasoning framework works across different legal contexts. It also shows lawyers from various practice areas what AI reasoning support might look like in their specific domain.\n","\n","**The Shift from Chapter 1 to Chapter 2**\n","\n","If you worked through a Chapter 1 notebook, you saw AI used primarily for drafting and document creation. Chapter 2 represents a capability shift. These mini-cases do not ask Claude to write a complete motion or contract. Instead they ask Claude to identify what legal issues are present, what facts are missing, what arguments could be made, what counterarguments exist, and where the weakest links are. This is pre-drafting analytical work. It is the reasoning that happens before you put pen to paper.\n","\n","**Criminal Defense: Bail Motion Reasoning**\n","\n","The first scenario involves a defendant facing felony theft charges who needs a bail hearing. The facts are intentionally sparse but realistic. You know the defendant's age, employment history, family situation, and limited prior record. You know a court date is coming. But many critical details are missing. What degree of felony? What exactly did the client allegedly steal? What ties to the community can be documented? The mini-case asks Claude to spot these gaps, structure a preliminary IRAC analysis about bail factors, map the arguments for release versus detention, and create a verification list of what must be checked before filing any motion.\n","\n","**Regulatory Compliance: Comment Letter Strategy**\n","\n","The second scenario puts you in the shoes of a fintech company's lawyer facing a new proposed regulation. A federal agency has issued a notice of proposed rulemaking that would require enhanced disclosures. You know the general compliance timeline and rough cost estimates, but you have not read the full proposed rule text yet. The mini-case asks Claude to identify what arguments the company might make in a comment letter, what counterarguments the agency or other stakeholders might raise, where the weak spots in the company's position are, and what specific regulatory text needs verification before drafting anything.\n","\n","**International Commercial: Governing Law and Forum Selection**\n","\n","The third scenario involves a cross-border software licensing dispute. An American company and a German company have a contract, but no clear choice of law or forum selection clause. There was a prior payment dispute that got resolved informally, but now they need to formalize dispute resolution terms. The mini-case asks Claude to map the tradeoffs between different options. Should governing law be American, German, or neutral? Should disputes go to courts or arbitration? What are the enforcement implications? What assumptions are being made? What jurisdiction-specific rules need verification before advising the client?\n","\n","**Teaching and Academia: AI Use Policy Development**\n","\n","The fourth scenario addresses a contemporary challenge facing legal educators. A law professor teaching legal writing needs a syllabus policy about student use of AI tools. The professor wants to maintain academic integrity while acknowledging that lawyers increasingly work with AI in practice. The mini-case asks Claude to spot the policy design issues, map different approaches from complete prohibition to disclosure requirements to permitted use with conditions, identify edge cases and equity concerns, and flag what would need institutional support or legal review before implementation.\n","\n","**Why the Prompts Are So Simple**\n","\n","You might notice that the prompts in Section 7 are remarkably brief compared to the detailed instructions you might expect. This simplicity is intentional and hard-won. Earlier versions of these prompts were much longer and more detailed, giving Claude extensive bullet-pointed instructions about what to include. Those complex prompts actually made things worse. Claude would respond with explanatory text about the instructions rather than pure JSON. The current simple prompts just state the facts and ask for JSON analysis. This minimalist approach works better with the prefill technique from Section 6.\n","\n","**The Word Count Constraint**\n","\n","Each prompt specifies a target word count for the draft output field, ranging from 300 to 400 words depending on the scenario complexity. This constraint serves multiple purposes. It forces conciseness, preventing Claude from generating sprawling analyses that would be hard to review. It ensures consistency across scenarios, making them easier to compare. It also helps control API token usage and costs. Most importantly, it reflects real-world constraints where lawyers need focused analysis, not exhaustive treatises.\n","\n","**Facts Provided Separately**\n","\n","Each mini-case function returns a dictionary with three elements: the task name identifier, a list of facts, and the prompt text. The facts are stored separately even though they also appear in the prompt. Why this redundancy? The separate facts list makes it easier for downstream code to display the facts clearly in output documents. It also makes the structure more maintainable if you want to modify how facts are presented to Claude versus how they are presented to human reviewers.\n","\n","**Building Blocks for Section 8**\n","\n","Section 7 does not execute anything. It simply defines four functions and stores them in a list called all cases. This design pattern separates case definitions from case execution. Section 8 will loop through this list, calling each function to get the scenario details, then using the wrapper from Section 6 to call Claude for each one. This separation makes the code more organized and easier to modify. If you want to add a fifth mini-case, you just define another function and add it to the list.\n","\n","**The Pedagogical Intent**\n","\n","These four scenarios serve as teaching examples. They show what kinds of tasks are appropriate for Level 2 reasoning support versus what should remain purely human judgment. They demonstrate how to frame prompts that yield structured analytical outputs rather than draft documents. They illustrate the importance of explicitly flagging missing facts and verification requirements. For lawyers learning to integrate AI into their practice, these mini-cases provide concrete reference points about what good AI-augmented reasoning workflows look like."],"metadata":{"id":"NXRITuDhTCti"}},{"cell_type":"markdown","source":["###7.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"UFhsr4MmJMcr"}},{"cell_type":"code","source":["# Cell 7: Mini-Case Builders for Level 2 Reasoning Tasks\n","\n","print(\"=\" * 60)\n","print(\"CELL 7: MINI-CASE DEFINITIONS (4 REASONING TASKS)\")\n","print(\"=\" * 60)\n","\n","def get_criminal_case():\n","    \"\"\"Criminal defense: bail/conditions motion issue spotting\"\"\"\n","    return {\n","        \"task_name\": \"criminal_bail_motion_reasoning\",\n","        \"facts\": [\n","            \"Defendant: Marcus Johnson, age 34, charged with felony theft\",\n","            \"Employed as warehouse supervisor for 6 years\",\n","            \"Resides with partner and two children\",\n","            \"No prior felony convictions; one 2018 misdemeanor DUI\",\n","            \"Court date: 45 days from now\"\n","        ],\n","        \"prompt\": \"\"\"Facts: Defendant Marcus Johnson, 34, charged with felony theft. Employed 6 years as warehouse supervisor. Lives with partner and two children. No prior felonies, one 2018 misdemeanor DUI. Court date in 45 days.\n","\n","Create JSON analysis for bail motion memo (300 words in draft_output). Include issues_spotted, IRAC scaffold, argument_map, open_questions, and verification list.\"\"\"\n","    }\n","\n","def get_regulatory_case():\n","    \"\"\"Regulatory/Administrative: comment letter strategy issue spotting\"\"\"\n","    return {\n","        \"task_name\": \"regulatory_comment_letter_reasoning\",\n","        \"facts\": [\n","            \"Client: Regional fintech, digital lending in 12 states\",\n","            \"Agency NPRM proposes new disclosure requirements\",\n","            \"Compliance timeline: 180 days after final rule\",\n","            \"Estimated cost: $2.5M systems upgrade plus $400K annual\",\n","            \"Challenge: legacy systems integration\"\n","        ],\n","        \"prompt\": \"\"\"Facts: Regional fintech client provides digital lending in 12 states. Federal agency NPRM proposes new disclosure requirements. 180-day compliance timeline. Estimated cost: $2.5M systems upgrade, $400K annual ongoing. Legacy systems integration challenges.\n","\n","Create JSON analysis for comment letter strategy (350 words in draft_output). Include issues_spotted, argument_map with primary position and counterarguments, open_questions, and verification list.\"\"\"\n","    }\n","\n","def get_international_case():\n","    \"\"\"International commercial: governing law/arbitration options reasoning\"\"\"\n","    return {\n","        \"task_name\": \"international_contract_law_reasoning\",\n","        \"facts\": [\n","            \"Cross-border software license: US licensor, German licensee\",\n","            \"3-year term, $450,000 total, quarterly USD payments\",\n","            \"Past dispute: 60-day payment delay last year, resolved informally\",\n","            \"Client prefers cost containment\",\n","            \"No forum agreement yet\"\n","        ],\n","        \"prompt\": \"\"\"Facts: Cross-border software license between US company (licensor) and German company (licensee). 3-year term, $450K total, quarterly USD payments. Last year: 60-day payment delay resolved informally. US client wants cost containment. No forum agreement exists yet.\n","\n","Create JSON analysis for governing law and arbitration options (300 words in draft_output). Include issues_spotted, argument_map comparing options, assumptions, open_questions, and verification list.\"\"\"\n","    }\n","\n","def get_teaching_case():\n","    \"\"\"Teaching/Academia: AI-use syllabus policy rationale\"\"\"\n","    return {\n","        \"task_name\": \"teaching_ai_policy_reasoning\",\n","        \"facts\": [\n","            \"Course: Upper-level legal writing (20-25 students)\",\n","            \"Assessment: 3 memos (40%), final memo (30%), participation (20%), peer review (10%)\",\n","            \"Concern: AI use without disclosure\",\n","            \"Honor code exists but doesn't mention AI\",\n","            \"Goal: teach research skills while acknowledging AI reality\"\n","        ],\n","        \"prompt\": \"\"\"Facts: Upper-level legal writing course, 20-25 students. Assessment: 3 memos (40%), final memo (30%), participation (20%), peer review (10%). Concern: students using AI without disclosure. Existing honor code doesn't mention AI. Goal: teach legal research skills, acknowledge AI as workplace reality.\n","\n","Create JSON analysis for AI-use syllabus policy (350 words in draft_output). Include issues_spotted (enforceability, clarity, equity), argument_map comparing policy options, assumptions, open_questions, and verification list.\"\"\"\n","    }\n","\n","# Build all cases\n","ALL_CASES = [\n","    get_criminal_case(),\n","    get_regulatory_case(),\n","    get_international_case(),\n","    get_teaching_case()\n","]\n","\n","print(\"\\nðŸ“‹ Mini-Case Task Names:\")\n","print(\"-\" * 60)\n","for i, case in enumerate(ALL_CASES, 1):\n","    print(f\"   {i}. {case['task_name']}\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"âœ… CELL 7 COMPLETE - 4 mini-cases defined with simpler prompts\")\n","print(\"=\" * 60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rZWKRhXN0pL","executionInfo":{"status":"ok","timestamp":1767802484442,"user_tz":360,"elapsed":22,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"15d8317b-1634-4c6b-c9af-16aefd70b6b0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","CELL 7: MINI-CASE DEFINITIONS (4 REASONING TASKS)\n","============================================================\n","\n","ðŸ“‹ Mini-Case Task Names:\n","------------------------------------------------------------\n","   1. criminal_bail_motion_reasoning\n","   2. regulatory_comment_letter_reasoning\n","   3. international_contract_law_reasoning\n","   4. teaching_ai_policy_reasoning\n","\n","============================================================\n","âœ… CELL 7 COMPLETE - 4 mini-cases defined with simpler prompts\n","============================================================\n"]}]},{"cell_type":"markdown","source":["##8.EXECUTING MINI CASES WITH ERROR HANDLING"],"metadata":{"id":"en3jy8PVJ1Z9"}},{"cell_type":"markdown","source":["###8.1.OVERVIEW"],"metadata":{"id":"t1QpI8krJ2km"}},{"cell_type":"markdown","source":["**Understanding Section 8: Running All Four Cases and Tracking Results**\n","\n","**What This Section Does**\n","\n","Section 8 is the execution engine that takes the four scenarios defined in Section 7 and actually runs them through Claude. It loops through each mini-case, calls the wrapper function from Section 6, handles any errors that occur, saves both structured JSON outputs and human-readable text versions, tracks success and failure statistics, and produces a final summary table. Think of it as the production line where raw scenarios get transformed into analyzed outputs with full error handling and progress reporting.\n","\n","**Why Error Handling Matters in Production Workflows**\n","\n","When you run code manually and something breaks, you can investigate and fix it. But in a notebook designed for repeated use by multiple lawyers, robust error handling becomes essential. Section 8 wraps each case execution in protective error handling that catches failures but keeps going. If the criminal defense case fails for some reason, the notebook does not crash. Instead it logs the failure, creates error placeholder files, and moves on to process the regulatory case. This resilience ensures you get partial results even when some cases encounter problems.\n","\n","**Progress Indicators for Human Monitoring**\n","\n","The section prints progress messages as it works through each case. You see which case is currently processing, numbered indicators showing one of four, two of four, and so on. You see when the API is being called. You see success or failure messages for each case. These progress indicators serve multiple purposes. They provide reassurance that the notebook is working rather than frozen. They help you identify which specific case is causing delays if API responses are slow. They create a real-time audit trail in the notebook output that complements the file-based logs.\n","\n","**Dual Output Format: JSON and Text**\n","\n","For each successfully processed case, Section 8 creates two output files. The JSON file contains the raw structured data exactly as returned by Claude, matching the schema enforced in Section 6. This JSON is machine-readable and could be processed by other tools or scripts. The text file takes that same data and formats it into a human-readable memo-style document with clear section headers, bulleted lists, and proper spacing. Lawyers reviewing the outputs can read the text files naturally without needing to understand JSON syntax.\n","\n","**The Text File Structure**\n","\n","Each text file starts with a header block showing the task name and generation timestamp. Then it lists all the facts that were provided to Claude. Next comes the draft analysis memo that Claude wrote, which is the narrative explanation a lawyer would read first. After that come structured sections pulling out specific elements: the issues spotted, the IRAC scaffold, the argument map, the open questions list, the verification to-do list, and the risks flagged. This organization lets reviewers quickly jump to the section most relevant to their immediate needs.\n","\n","**Statistics Tracking Across All Cases**\n","\n","As Section 8 processes each case, it maintains a running count of important metrics. How many cases ran successfully versus failed? How many total API calls were made? How many risks were logged across all cases? These statistics get displayed in the final summary. They provide a quick health check on the overall run. If you see that three out of four cases failed, you know something fundamental is wrong and should investigate before relying on any results. If all four succeeded but fifty risks were flagged, you know careful review is essential.\n","\n","**The Final Summary Table**\n","\n","After all cases complete, Section 8 prints a formatted table showing each task name alongside a visual status indicator. Green checkmarks indicate success. Red X marks indicate failure. This table provides an at-a-glance overview of what worked and what did not. The table format makes it easy to scan results quickly rather than reading through pages of detailed output. For a lawyer running this notebook, the summary table is often the first place to look to assess whether the run produced usable results.\n","\n","**Continuing After Failures**\n","\n","A key design choice in Section 8 is that failures do not stop execution. If the criminal defense case fails, the code catches the error, increments the failed counter, creates error placeholder files matching the expected file structure, records the failure in the results list, and then continues to process the regulatory case. This continue-on-error approach means you maximize the value from each notebook run. Even if one or two cases encounter issues, you still get results from the others rather than getting nothing at all.\n","\n","**Why Create Files Even for Failures**\n","\n","You might wonder why Section 8 bothers creating JSON and text files even when a case fails. The answer relates to downstream expectations. Section 10 will create a zip bundle of all deliverables. If some expected files are missing, the zipping process could fail or produce an incomplete archive. By always creating files with error content when needed, Section 8 ensures consistent file structure regardless of success or failure. The error files also document what went wrong in a format that matches successful outputs.\n","\n","**The Progress Counter Pattern**\n","\n","The progress indicators use a pattern showing current position out of total, like one of four or three of four. This pattern is more informative than just showing which case is running. It tells you how much work remains. If you see two of four and the notebook seems stuck, you know it is halfway through rather than just starting or nearly done. This helps set expectations about how much longer the run might take, especially important if API calls are slow.\n","\n","**Deliverables Directory Organization**\n","\n","All output files get saved into the deliverables subdirectory that was created back in Section 2. This organization keeps generated content separate from governance artifacts. The manifest, prompt logs, and risk logs live in the main run directory. The actual analysis outputs live in the deliverables folder. This separation makes it easier for reviewers to find what they need. Lawyers reviewing case analyses look in deliverables. Compliance officers reviewing audit trails look in the main run directory.\n","\n","**Real-Time Risk Aggregation**\n","\n","As cases are processed, risks get logged to the risk log file in real time. The statistics counter tracks the cumulative total. This means that even if Section 8 crashes partway through for some unexpected reason, all risks identified up to that point are already safely recorded in the risk log. You do not lose audit trail information just because something went wrong later. This incremental saving pattern protects data throughout the execution process.\n","\n","**Setting Up Section 9**\n","\n","By the time Section 8 completes, four mini-cases have been analyzed, their outputs are saved as files, statistics are calculated, and a summary is displayed. This sets the stage for Section 9, where you can input your own custom scenario and get the same structured analysis treatment. Section 8 demonstrates the workflow with predefined examples. Section 9 lets you apply that same workflow to your specific needs."],"metadata":{"id":"SWDuLTIqTU-I"}},{"cell_type":"markdown","source":["###8.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"3q026LBAJ45F"}},{"cell_type":"code","source":["# Cell 8: Execute All Mini-Cases with Error Handling and Progress Tracking\n","\n","print(\"=\" * 60)\n","print(\"CELL 8: EXECUTE 4 MINI-CASES\")\n","print(\"=\" * 60)\n","\n","import time\n","\n","# Stats tracking\n","stats = {\n","    \"total_cases\": len(ALL_CASES),\n","    \"successful\": 0,\n","    \"failed\": 0,\n","    \"total_api_calls\": 0,\n","    \"total_risks_logged\": 0\n","}\n","\n","results = []\n","\n","for i, case in enumerate(ALL_CASES, 1):\n","    print(f\"\\n{'='*60}\")\n","    print(f\"[{i}/{len(ALL_CASES)}] Processing: {case['task_name']}\")\n","    print('='*60)\n","\n","    try:\n","        # Run case\n","        print(f\"\\nðŸ“ž Calling Claude API...\")\n","        result = call_claude(case['task_name'], case['prompt'], temperature=0.1)\n","\n","        stats[\"total_api_calls\"] += 1\n","        stats[\"total_risks_logged\"] += len(result.get(\"risks\", []))\n","\n","        # Save JSON deliverable\n","        json_path = os.path.join(DELIVERABLES_DIR, f\"{case['task_name']}_output.json\")\n","        with open(json_path, 'w') as f:\n","            json.dump(result, f, indent=2)\n","\n","        # Save human-readable TXT deliverable\n","        txt_path = os.path.join(DELIVERABLES_DIR, f\"{case['task_name']}_draft.txt\")\n","        txt_content = f\"\"\"{'='*70}\n","AI FOR LAWYERS - CHAPTER 2 (LEVEL 2: REASONERS)\n","TASK: {case['task_name']}\n","Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n","{'='*70}\n","\n","FACTS PROVIDED:\n","{chr(10).join('- ' + fact for fact in case['facts'])}\n","\n","{'='*70}\n","DRAFT ANALYSIS MEMO\n","{'='*70}\n","\n","{result['draft_output']}\n","\n","{'='*70}\n","STRUCTURED OUTPUTS (for lawyer review)\n","{'='*70}\n","\n","ISSUES SPOTTED:\n","{json.dumps(result.get('issues_spotted', []), indent=2)}\n","\n","IRAC SCAFFOLD:\n","{json.dumps(result.get('analysis_structure', {}).get('irac', {}), indent=2)}\n","\n","ARGUMENT MAP:\n","{json.dumps(result.get('argument_map', {}), indent=2)}\n","\n","OPEN QUESTIONS:\n","{chr(10).join('- ' + q for q in result.get('open_questions', []))}\n","\n","VERIFICATION TO-DO LIST:\n","{chr(10).join('- ' + q for q in result.get('questions_to_verify', []))}\n","\n","RISKS FLAGGED:\n","{json.dumps(result.get('risks', []), indent=2)}\n","\n","{'='*70}\n","END OF ANALYSIS\n","{'='*70}\n","\"\"\"\n","\n","        with open(txt_path, 'w') as f:\n","            f.write(txt_content)\n","\n","        stats[\"successful\"] += 1\n","\n","        print(f\"\\nâœ… SUCCESS\")\n","        print(f\"   JSON: {json_path}\")\n","        print(f\"   TXT:  {txt_path}\")\n","\n","        results.append({\n","            \"task_name\": case['task_name'],\n","            \"status\": \"âœ… Success\",\n","            \"json_path\": json_path,\n","            \"txt_path\": txt_path\n","        })\n","\n","    except Exception as e:\n","        print(f\"\\nâŒ FAILED: {str(e)}\")\n","        stats[\"failed\"] += 1\n","\n","        # Create error deliverables\n","        error_result = {\n","            \"task\": \"error_fallback\",\n","            \"error\": str(e),\n","            \"verification_status\": \"Not verified\"\n","        }\n","\n","        json_path = os.path.join(DELIVERABLES_DIR, f\"{case['task_name']}_output.json\")\n","        with open(json_path, 'w') as f:\n","            json.dump(error_result, f, indent=2)\n","\n","        txt_path = os.path.join(DELIVERABLES_DIR, f\"{case['task_name']}_draft.txt\")\n","        with open(txt_path, 'w') as f:\n","            f.write(f\"ERROR: {str(e)}\\n\\nThis case failed to process.\")\n","\n","        results.append({\n","            \"task_name\": case['task_name'],\n","            \"status\": \"âŒ Failed\",\n","            \"json_path\": json_path,\n","            \"txt_path\": txt_path\n","        })\n","\n","# Final summary\n","print(\"\\n\" + \"=\"*60)\n","print(\"EXECUTION SUMMARY\")\n","print(\"=\"*60)\n","\n","print(f\"\\nðŸ“Š Statistics:\")\n","print(f\"   Total cases:      {stats['total_cases']}\")\n","print(f\"   Successful:       {stats['successful']}\")\n","print(f\"   Failed:           {stats['failed']}\")\n","print(f\"   Total API calls:  {stats['total_api_calls']}\")\n","print(f\"   Total risks logged: {stats['total_risks_logged']}\")\n","\n","print(f\"\\nðŸ“‹ Results Table:\")\n","print(\"-\"*60)\n","print(f\"{'Task Name':<45} {'Status':<15}\")\n","print(\"-\"*60)\n","for result in results:\n","    print(f\"{result['task_name']:<45} {result['status']:<15}\")\n","print(\"-\"*60)\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"âœ… CELL 8 COMPLETE - All mini-cases processed\")\n","print(\"=\"*60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"do615fm4J6nb","executionInfo":{"status":"ok","timestamp":1767802787816,"user_tz":360,"elapsed":300069,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"c3a82caa-b4fa-4891-a521-b60e77bd1396"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","CELL 8: EXECUTE 4 MINI-CASES\n","============================================================\n","\n","============================================================\n","[1/4] Processing: criminal_bail_motion_reasoning\n","============================================================\n","\n","ðŸ“ž Calling Claude API...\n","   âœ… Success on attempt 1 (strategy: strategy_1_direct)\n","\n","âœ… SUCCESS\n","   JSON: /content/ai_law_ch2_runs/run_20260107_153938/deliverables/criminal_bail_motion_reasoning_output.json\n","   TXT:  /content/ai_law_ch2_runs/run_20260107_153938/deliverables/criminal_bail_motion_reasoning_draft.txt\n","\n","============================================================\n","[2/4] Processing: regulatory_comment_letter_reasoning\n","============================================================\n","\n","ðŸ“ž Calling Claude API...\n","   âœ… Success on attempt 1 (strategy: strategy_1_direct)\n","\n","âœ… SUCCESS\n","   JSON: /content/ai_law_ch2_runs/run_20260107_153938/deliverables/regulatory_comment_letter_reasoning_output.json\n","   TXT:  /content/ai_law_ch2_runs/run_20260107_153938/deliverables/regulatory_comment_letter_reasoning_draft.txt\n","\n","============================================================\n","[3/4] Processing: international_contract_law_reasoning\n","============================================================\n","\n","ðŸ“ž Calling Claude API...\n","   âš ï¸  Attempt 1/3: JSON extraction failed (all_strategies_failed)\n","   âœ… Success on attempt 2 (strategy: strategy_1_direct)\n","\n","âœ… SUCCESS\n","   JSON: /content/ai_law_ch2_runs/run_20260107_153938/deliverables/international_contract_law_reasoning_output.json\n","   TXT:  /content/ai_law_ch2_runs/run_20260107_153938/deliverables/international_contract_law_reasoning_draft.txt\n","\n","============================================================\n","[4/4] Processing: teaching_ai_policy_reasoning\n","============================================================\n","\n","ðŸ“ž Calling Claude API...\n","   âœ… Success on attempt 1 (strategy: strategy_1_direct)\n","\n","âœ… SUCCESS\n","   JSON: /content/ai_law_ch2_runs/run_20260107_153938/deliverables/teaching_ai_policy_reasoning_output.json\n","   TXT:  /content/ai_law_ch2_runs/run_20260107_153938/deliverables/teaching_ai_policy_reasoning_draft.txt\n","\n","============================================================\n","EXECUTION SUMMARY\n","============================================================\n","\n","ðŸ“Š Statistics:\n","   Total cases:      4\n","   Successful:       4\n","   Failed:           0\n","   Total API calls:  4\n","   Total risks logged: 20\n","\n","ðŸ“‹ Results Table:\n","------------------------------------------------------------\n","Task Name                                     Status         \n","------------------------------------------------------------\n","criminal_bail_motion_reasoning                âœ… Success      \n","regulatory_comment_letter_reasoning           âœ… Success      \n","international_contract_law_reasoning          âœ… Success      \n","teaching_ai_policy_reasoning                  âœ… Success      \n","------------------------------------------------------------\n","\n","============================================================\n","âœ… CELL 8 COMPLETE - All mini-cases processed\n","============================================================\n"]}]},{"cell_type":"markdown","source":["##9.USER EXERCISE"],"metadata":{"id":"lHAVHVoYPmQF"}},{"cell_type":"markdown","source":["###9.1.OVERVIEW"],"metadata":{"id":"nT93YkpKPnsq"}},{"cell_type":"markdown","source":["**Understanding Section 9: Your Turn to Use the System**\n","\n","**What This Section Does**\n","\n","Section 9 is where the notebook becomes interactive and personally useful. Instead of processing predefined scenarios created by the notebook author, this section lets you input your own hypothetical legal scenario and receive structured reasoning support. You can choose whether you want an internal analysis memo or guidance for client communication. The section applies the same redaction, API calling, and file saving processes used in Section 8, but now with your content and your choices.\n","\n","**The User Input Variables**\n","\n","At the top of Section 9, you see two variables you can modify. The first is a text block where you describe your scenario. The second is an output type selector where you choose between analysis memo or client email about next steps. These are the only two things you need to change. Everything else in the section runs automatically once you have set these values. This design minimizes what you need to understand about Python programming while maximizing what you can accomplish with the notebook.\n","\n","**Why Hypothetical Scenarios Only**\n","\n","The section includes a prominent warning reminding you not to input actual client data. This warning appears again because the temptation to use real cases is strong. You have a tool that seems useful and you want to apply it to your actual work. But remember that anything you type gets sent to a third-party API over the internet. The redaction tools help but are not perfect. The professional responsibility implications of exposing real client information to outside systems are serious. Hypothetical scenarios that mirror your real situations provide nearly all the same analytical value without the confidentiality risks.\n","\n","**Two Output Type Options**\n","\n","The output type choice reflects different use cases. An analysis memo is internal work product for your own reasoning and case planning. It focuses on issue spotting, legal analysis structure, argument mapping, and verification requirements. A client email about next steps is guidance for external communication. It focuses on explaining issues in plain language, identifying what information you need from the client, recommending investigation steps, and setting expectations about next stages. Same underlying analysis, different presentation focus.\n","\n","**The Redaction Preview**\n","\n","Before calling Claude, Section 9 runs your scenario text through the redaction function from Section 5 and shows you what was removed. This preview serves as a safety check. You can see whether the automated redaction caught what you expected it to catch. If you notice that something sensitive was not redacted, you can go back and revise your scenario text to be more generic before the API call happens. This preview-before-send pattern gives you a chance to catch problems before they occur.\n","\n","**Building the Appropriate Prompt**\n","\n","Based on your output type choice, Section 9 constructs different prompts for Claude. If you selected analysis memo, the prompt asks for issue spotting, IRAC scaffolding, argument mapping, and verification lists. If you selected client email guidance, the prompt asks for plain language issue explanation, client questions to answer, investigation recommendations, and next step suggestions. The prompt construction happens automatically based on your selection. You do not need to write prompts yourself.\n","\n","**Calling the Wrapper Function**\n","\n","Section 9 uses the same call Claude wrapper from Section 6 that processed the mini-cases in Section 8. This means your custom scenario benefits from all the reliability engineering built into that function. The prefill technique forces JSON output. Multiple extraction strategies handle various response formats. Schema validation ensures completeness. Retry logic handles transient failures. Automatic risk detection flags concerns. The error fallback provides graceful degradation. All of this happens transparently when you run your scenario.\n","\n","**Saving Your Custom Outputs**\n","\n","Just like the mini-cases, your custom scenario produces two output files. The JSON file contains the structured data. The text file formats it for human reading. Both files get saved in the deliverables directory with names indicating they came from the user custom scenario. These files persist after the notebook finishes running, so you can download them, review them offline, share them with colleagues for discussion, or incorporate insights into your actual case planning.\n","\n","**The Confirmation Messages**\n","\n","After processing completes, Section 9 prints confirmation showing the file paths where your outputs were saved. This immediate feedback confirms that your run succeeded and tells you exactly where to find the results. The file paths are clickable in Colab, letting you open and review the files without leaving the notebook interface. This quick feedback loop encourages experimentation. You can try different scenarios, different output types, and different fact patterns to explore how the reasoning support responds.\n","\n","**Iterative Experimentation**\n","\n","Section 9 is designed for multiple runs. You can change the scenario text and output type variables, then rerun just this section without rerunning the entire notebook. Each run overwrites the previous custom scenario files, which is intentional. If you want to preserve multiple custom scenarios, you should download the output files after each run before running again. This workflow encourages iterative refinement. Run a scenario, review the output, adjust your facts or framing, run again, see how the analysis changes.\n","\n","**Learning What Works**\n","\n","Through experimentation in Section 9, you learn what kinds of scenarios produce useful reasoning support and what kinds do not. Scenarios with concrete facts and specific questions tend to work better than vague open-ended situations. Scenarios where you can articulate what you are trying to decide or determine work better than scenarios with no clear analytical goal. Scenarios at an appropriate level of complexity work better than either trivially simple situations or impossibly tangled fact patterns. This learning happens through doing.\n","\n","**Connecting to Your Practice**\n","\n","Section 9 is where the notebook transitions from educational demonstration to potential workflow tool. The mini-cases in Section 8 showed you what is possible. Section 9 lets you apply those same capabilities to situations that resemble your actual practice areas. Over time, you develop intuition about when this kind of structured reasoning support adds value versus when traditional methods work better. You discover which parts of the analysis are most helpful and which parts require the most careful verification.\n","\n","**The Path to Section 10**\n","\n","Once you have processed your custom scenario and reviewed the outputs, Section 9 is complete. Your deliverables directory now contains four mini-case analyses plus your custom scenario analysis. All of the API calls have been logged. All of the identified risks have been recorded. The statistics have been updated. Section 10 will take all of these artifacts and package them into a single downloadable archive with documentation explaining what happened during this run and what you should verify before relying on any of the outputs."],"metadata":{"id":"A8bkv7OCTn2A"}},{"cell_type":"markdown","source":["###9.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"YvccRCCoPqr6"}},{"cell_type":"code","source":["# Cell 9: User Exercise - Custom Scenario Input\n","\n","print(\"=\" * 60)\n","print(\"CELL 9: USER EXERCISE - YOUR CUSTOM SCENARIO\")\n","print(\"=\" * 60)\n","\n","print(\"\\nâš ï¸  CONFIDENTIALITY REMINDER:\")\n","print(\"Do not input actual client data. Use redacted/hypothetical scenarios only.\")\n","print()\n","\n","# User inputs (modify these)\n","user_scenario_text = \"\"\"\n","Scenario: Employment contract dispute\n","\n","Facts:\n","- Employee worked for tech startup for 2 years as senior developer\n","- Employment contract includes 12-month non-compete clause covering \"similar technology companies\"\n","- Employee resigned and accepted position at competitor 30 days later\n","- Former employer sent cease-and-desist letter claiming breach of non-compete\n","- Employee's new role: different technology stack but same industry (cloud infrastructure)\n","- State: California (user should verify specific state law)\n","\"\"\"\n","\n","output_type = \"analysis_memo\"  # Options: \"analysis_memo\" or \"client_email_about_next_steps\"\n","\n","# Redact user input\n","print(\"ðŸ“ Processing user scenario...\")\n","redacted_scenario, removed_items = redact(user_scenario_text)\n","\n","print(f\"\\nðŸ”’ Redaction Summary:\")\n","if removed_items:\n","    print(f\"   Removed: {', '.join(removed_items)}\")\n","else:\n","    print(\"   No sensitive data detected (or already redacted)\")\n","\n","# Build prompt based on output type\n","if output_type == \"analysis_memo\":\n","    user_prompt = f\"\"\"{redacted_scenario}\n","\n","Task: Produce issue spotting, IRAC scaffold, and argument map for this employment dispute scenario (400 words max).\n","\n","Your response should include:\n","- Issues spotted (non-compete enforceability, jurisdiction-specific factors, missing facts)\n","- IRAC scaffold for key legal issues\n","- Argument map: employee's strongest arguments, employer counterarguments, weakest links\n","- Open questions and verification to-do list\n","- State-specific law must be marked \"Not verified / source needed\"\n","\n","Include the required disclaimer at the end.\"\"\"\n","\n","elif output_type == \"client_email_about_next_steps\":\n","    user_prompt = f\"\"\"{redacted_scenario}\n","\n","Task: Produce issue spotting and next steps reasoning for client communication (300 words max).\n","\n","Your response should include:\n","- Key legal issues identified\n","- Assumptions we're making\n","- Critical open questions for client to answer\n","- Recommended next steps (investigation, document gathering, expert consultation)\n","- Risks to flag in client communication\n","- Verification to-do list for lawyer\n","\n","Include the required disclaimer at the end.\"\"\"\n","\n","else:\n","    print(f\"\\nâŒ Invalid output_type: {output_type}\")\n","    print(\"   Valid options: 'analysis_memo' or 'client_email_about_next_steps'\")\n","    raise ValueError(\"Invalid output_type\")\n","\n","# Call Claude\n","print(f\"\\nðŸ“ž Calling Claude API for {output_type}...\")\n","user_result = call_claude(\"user_custom_scenario\", user_prompt, temperature=0.1)\n","\n","# Save outputs\n","user_json_path = os.path.join(DELIVERABLES_DIR, \"user_custom_scenario_output.json\")\n","with open(user_json_path, 'w') as f:\n","    json.dump(user_result, f, indent=2)\n","\n","user_txt_path = os.path.join(DELIVERABLES_DIR, \"user_custom_scenario_draft.txt\")\n","txt_content = f\"\"\"{'='*70}\n","AI FOR LAWYERS - CHAPTER 2 (LEVEL 2: REASONERS)\n","USER CUSTOM SCENARIO\n","Output Type: {output_type}\n","Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n","{'='*70}\n","\n","SCENARIO (REDACTED):\n","{redacted_scenario}\n","\n","{'='*70}\n","DRAFT OUTPUT\n","{'='*70}\n","\n","{user_result['draft_output']}\n","\n","{'='*70}\n","STRUCTURED ANALYSIS\n","{'='*70}\n","\n","ISSUES SPOTTED:\n","{json.dumps(user_result.get('issues_spotted', []), indent=2)}\n","\n","OPEN QUESTIONS:\n","{chr(10).join('- ' + q for q in user_result.get('open_questions', []))}\n","\n","VERIFICATION TO-DO LIST:\n","{chr(10).join('- ' + q for q in user_result.get('questions_to_verify', []))}\n","\n","ARGUMENT MAP:\n","{json.dumps(user_result.get('argument_map', {}), indent=2)}\n","\n","RISKS:\n","{json.dumps(user_result.get('risks', []), indent=2)}\n","\n","{'='*70}\n","END OF ANALYSIS\n","{'='*70}\n","\"\"\"\n","\n","with open(user_txt_path, 'w') as f:\n","    f.write(txt_content)\n","\n","print(f\"\\nâœ… User scenario processed\")\n","print(f\"   JSON: {user_json_path}\")\n","print(f\"   TXT:  {user_txt_path}\")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"âœ… CELL 9 COMPLETE - User exercise saved\")\n","print(\"=\"*60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6evw2QZZPsYy","executionInfo":{"status":"ok","timestamp":1767802861448,"user_tz":360,"elapsed":52663,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"7e866f6e-0728-4846-8b56-effc0398fa8d"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","CELL 9: USER EXERCISE - YOUR CUSTOM SCENARIO\n","============================================================\n","\n","âš ï¸  CONFIDENTIALITY REMINDER:\n","Do not input actual client data. Use redacted/hypothetical scenarios only.\n","\n","ðŸ“ Processing user scenario...\n","\n","ðŸ”’ Redaction Summary:\n","   No sensitive data detected (or already redacted)\n","\n","ðŸ“ž Calling Claude API for analysis_memo...\n","   âœ… Success on attempt 1 (strategy: strategy_1_direct)\n","\n","âœ… User scenario processed\n","   JSON: /content/ai_law_ch2_runs/run_20260107_153938/deliverables/user_custom_scenario_output.json\n","   TXT:  /content/ai_law_ch2_runs/run_20260107_153938/deliverables/user_custom_scenario_draft.txt\n","\n","============================================================\n","âœ… CELL 9 COMPLETE - User exercise saved\n","============================================================\n"]}]},{"cell_type":"markdown","source":["##10.AUDIT README"],"metadata":{"id":"Z_WbZkeCP467"}},{"cell_type":"markdown","source":["###10.1.OVERVIEW"],"metadata":{"id":"eq7Nv_cMP6SA"}},{"cell_type":"markdown","source":["**Understanding Section 10: Packaging Everything for Compliance Review**\n","\n","**What This Section Does**\n","\n","Section 10 is the final packaging and documentation stage. It creates a comprehensive audit readme file that summarizes everything that happened during this notebook run, then bundles all the governance artifacts and deliverables into a single compressed zip file that you can download and archive. Think of it as assembling a complete case file with an executive summary cover memo. Everything you need for compliance review, quality control, or future reference gets packaged together in one portable archive.\n","\n","**The Audit Readme: Your Executive Summary**\n","\n","The audit readme is a plain text document that serves as the entry point for anyone reviewing this run in the future. It starts with basic identification information including the run timestamp and model used. It then provides a structured overview of what artifacts exist, what statistics were recorded, what verification is required, and what limitations apply. If a compliance officer or supervising partner needs to understand what happened during this AI-assisted analysis session, they read the audit readme first before diving into detailed log files.\n","\n","**Statistics That Matter for Oversight**\n","\n","The audit readme includes key statistics that help oversight reviewers quickly assess the run. How many API calls were made total? How many risks were flagged and what types? How many deliverable files were created? These numbers provide a health check. A run with zero risks flagged might indicate insufficient scrutiny. A run with a hundred risks might indicate problematic prompts or scenarios. A run with only two deliverables when five were expected indicates failures that need investigation.\n","\n","**The Verification Requirements Checklist**\n","\n","One of the most important sections in the audit readme is the verification requirements checklist. This is a series of checkbox items reminding the reviewing lawyer what must be verified before relying on any AI outputs. Verify all factual assumptions against actual case facts. Verify all legal rules and authorities cited. Check jurisdiction-specific law for accuracy. Review open questions and gather missing information. This checklist is not optional guidance. It reflects professional responsibility obligations when using AI tools in legal practice.\n","\n","**Confidentiality and Privilege Documentation**\n","\n","The audit readme documents what confidentiality protections were applied during the run. It confirms that all user inputs were redacted before API transmission. It notes that all logged data contains only redacted text with cryptographic hashes. It also includes a limitations section acknowledging that redaction is imperfect and that API transmission inherently involves third-party processing. This documentation creates a record showing that you took reasonable steps to protect confidential information, even while acknowledging the inherent limitations of using external AI services.\n","\n","**Risk Breakdown by Type**\n","\n","The audit readme includes a breakdown showing how many risks were flagged in each category. How many missing facts risks? How many confidentiality concerns? How many hallucination warnings? This breakdown helps reviewers prioritize their verification efforts. If ten hallucination risks were flagged but zero confidentiality risks, the reviewer knows to focus extra attention on checking factual accuracy rather than worrying about information exposure. The categorized breakdown guides efficient review.\n","\n","**File Listing for Navigation**\n","\n","The audit readme lists every file that exists in the run directory and deliverables subdirectory. This serves as a table of contents for the entire archive. A reviewer can quickly see what files are available without hunting through folders. The listing also serves as a completeness check. If a deliverable that should exist is missing from the listing, that absence becomes immediately obvious rather than being discovered much later when someone needs that specific file.\n","\n","**Usage Notes for Future Reference**\n","\n","The audit readme includes a usage notes section explaining what this run produced and what the next steps should be. It reminds you that the run created four mini-case analyses plus one custom scenario analysis. It suggests concrete actions: review all deliverables, verify open questions, conduct independent legal research, update client files with verified analysis, and archive the bundle per firm retention policy. These action items transform the audit readme from a passive record into an active workflow guide.\n","\n","**The Disclaimer Section**\n","\n","Every audit readme ends with a comprehensive disclaimer section. This reminds readers that the notebook and all outputs are for educational and workflow demonstration purposes only. It emphasizes that all AI-generated content is marked not verified and requires independent legal verification. It warns against relying on unverified outputs for legal advice or decisions. It directs readers to consult applicable professional conduct rules regarding AI tool usage. This disclaimer protects both the notebook creator and the users from misunderstandings about appropriate usage.\n","\n","**Creating the Zip Archive**\n","\n","After writing the audit readme, Section 10 uses file compression tools to create a zip archive containing the entire run directory. This zip file includes the manifest, the prompt logs, the risk logs, the pip freeze, the audit readme, the deliverables folder with all JSON and text files, and anything else that was created during the run. Everything gets bundled together. The zip file gets saved in a location outside the run directory so it remains accessible even after the run directory is deleted or modified.\n","\n","**Why Zipping Matters**\n","\n","The zip archive serves multiple practical purposes. It makes downloading easier because you get one file instead of dozens. It makes archiving simpler because you can store one compressed file rather than a complex directory structure. It makes sharing safer because the recipient gets a complete consistent snapshot rather than individual files that might be missing pieces. It makes compliance review more reliable because everything that belongs together stays together in a single immutable package.\n","\n","**The File Listing Display**\n","\n","Section 10 prints a hierarchical listing showing the complete contents of the run directory before zipping. You see the directory tree structure with proper indentation showing which files are at the top level and which are inside the deliverables subdirectory. This visual representation helps you understand what is being packaged into the zip file. It also serves as documentation in the notebook output showing exactly what was included in this particular run.\n","\n","**The Final Checklist**\n","\n","The section ends with a comprehensive checklist showing green checkmarks next to every major artifact that should exist. Run directory created. Manifest written. Prompt logs written. Risk logs written. Pip freeze saved. Audit readme created. Deliverables folder populated. Zip bundle created. This checklist provides final confirmation that all expected outputs were successfully generated. If any item shows a red X or false indicator, you know that component failed and needs investigation before the archive can be considered complete.\n","\n","**Download Instructions**\n","\n","The final output includes the exact path to the zip file and instructions about downloading. The path is displayed prominently. The file size is shown so you know what to expect. The message encourages you to download your audit trail. In Google Colab, you can click the files icon in the left sidebar, navigate to the zip file, right-click it, and select download. This explicit guidance removes any uncertainty about how to retrieve your results.\n","\n","**What Happens Next**\n","\n","Once you download the zip file, you have a complete portable archive of this notebook run. You can extract it on your local machine and review all the files. You can share the archive with supervisors or colleagues for discussion. You can store it in your firm's document management system as work product documentation. You can reference it weeks or months later when you need to remember what analysis was done and what was flagged for verification. The zip archive becomes a permanent record that outlasts the temporary Colab session.\n","\n","**The Complete Workflow**\n","\n","Section 10 completes the full workflow that began in Section 1. You started with orientation and safety warnings. You set up the technical infrastructure and governance systems. You created redaction and API calling tools. You ran predefined scenarios and your own custom scenario. You generated structured reasoning outputs with risk flags and verification requirements. Now you have packaged everything into a professional archive with comprehensive documentation. This workflow demonstrates what responsible AI integration in legal practice looks like when done with appropriate safeguards and transparency."],"metadata":{"id":"F4H8PGjSP7b7"}},{"cell_type":"markdown","source":["###10.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"lkI5CGsNP9Ua"}},{"cell_type":"code","source":["# Cell 10: Create AUDIT_README and ZIP Bundle\n","\n","print(\"=\" * 60)\n","print(\"CELL 10: AUDIT TRAIL FINALIZATION\")\n","print(\"=\" * 60)\n","\n","import shutil\n","\n","# Create AUDIT_README.txt\n","audit_readme_path = os.path.join(RUN_DIR, \"AUDIT_README.txt\")\n","\n","# Count risks\n","with open(risk_log_path, 'r') as f:\n","    risk_data = json.load(f)\n","    total_risks = len(risk_data.get(\"risks\", []))\n","    risk_breakdown = {}\n","    for risk in risk_data.get(\"risks\", []):\n","        risk_type = risk.get(\"type\", \"unknown\")\n","        risk_breakdown[risk_type] = risk_breakdown.get(risk_type, 0) + 1\n","\n","# Count prompts\n","with open(prompts_log_path, 'r') as f:\n","    prompt_count = len(f.readlines())\n","\n","# List deliverables\n","deliverable_files = os.listdir(DELIVERABLES_DIR)\n","\n","audit_content = f\"\"\"{'='*70}\n","AI FOR LAWYERS - CHAPTER 2 (LEVEL 2: REASONERS)\n","AUDIT TRAIL SUMMARY\n","{'='*70}\n","\n","RUN ID: {timestamp}\n","Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n","\n","NOTEBOOK INFORMATION:\n","- Chapter: Chapter 2 - Level 2: Reasoners\n","- Model: {MODEL}\n","- Author: Alejandro Reynoso\n","- Capabilities: Issue spotting, IRAC structure, argument mapping\n","\n","{'='*70}\n","GOVERNANCE ARTIFACTS\n","{'='*70}\n","\n","1. run_manifest.json\n","   - Complete metadata and configuration\n","\n","2. prompts_log.jsonl\n","   - Total API calls logged: {prompt_count}\n","   - Each entry includes: timestamp, task_name, redacted prompt/response, hashes\n","\n","3. risk_log.json\n","   - Total risks flagged: {total_risks}\n","   - Risk breakdown:\n","{chr(10).join(f'     * {risk_type}: {count}' for risk_type, count in sorted(risk_breakdown.items()))}\n","\n","4. deliverables/ directory\n","   - Total files: {len(deliverable_files)}\n","   - Files:\n","{chr(10).join(f'     * {f}' for f in sorted(deliverable_files))}\n","\n","5. pip_freeze.txt\n","   - Complete package environment for reproducibility\n","\n","{'='*70}\n","VERIFICATION REQUIREMENTS\n","{'='*70}\n","\n","âš ï¸  ALL OUTPUTS REQUIRE INDEPENDENT LEGAL VERIFICATION\n","\n","Review checklist:\n","â–¡ Verify all factual assumptions against actual case facts\n","â–¡ Verify all legal rules and authorities cited (if any)\n","â–¡ Check jurisdiction-specific law for accuracy\n","â–¡ Review open questions list - gather missing information\n","â–¡ Evaluate risks flagged in risk_log.json\n","â–¡ Confirm confidentiality/privilege boundaries maintained\n","â–¡ Red-team the argument map - test weakest links\n","â–¡ Verify verification_status = \"Not verified\" in all outputs\n","\n","{'='*70}\n","CONFIDENTIALITY & PRIVILEGE HYGIENE\n","{'='*70}\n","\n","âœ… All user inputs were redacted before API transmission\n","âœ… All logged data contains only redacted text\n","âœ… Prompt/response hashes enable audit without exposing content\n","\n","âš ï¸  Limitations:\n","- Redaction is imperfect; manual review recommended\n","- API transmission inherently involves third-party processing\n","- Do not use this system for unredacted privileged material\n","\n","{'='*70}\n","USAGE NOTES\n","{'='*70}\n","\n","This run produced:\n","1. Four mini-case analyses (criminal, regulatory, international, teaching)\n","2. One user custom scenario analysis\n","3. Complete audit trail for governance review\n","\n","Next steps:\n","1. Review all deliverables in deliverables/ directory\n","2. Verify open questions and missing facts\n","3. Conduct independent legal research for all \"Not verified\" rules\n","4. Update client file with verified analysis\n","5. Archive this ZIP bundle per firm retention policy\n","\n","{'='*70}\n","DISCLAIMER\n","{'='*70}\n","\n","This notebook and all outputs are for educational and workflow demonstration\n","purposes only. All AI-generated content is marked \"Not verified\" and requires\n","independent legal verification. Do not rely on unverified AI outputs for legal\n","advice or decisions. Consult applicable rules of professional conduct regarding\n","use of AI tools in legal practice.\n","\n","{'='*70}\n","END OF AUDIT README\n","{'='*70}\n","\"\"\"\n","\n","with open(audit_readme_path, 'w') as f:\n","    f.write(audit_content)\n","\n","print(f\"\\n[1/2] âœ… AUDIT_README.txt created\")\n","print(f\"       {audit_readme_path}\")\n","\n","# Create ZIP bundle\n","zip_base_name = f\"ai_law_ch2_run_{timestamp}\"\n","zip_path = f\"/content/{zip_base_name}\"\n","\n","print(f\"\\n[2/2] ðŸ“¦ Creating ZIP bundle...\")\n","shutil.make_archive(zip_path, 'zip', RUN_DIR)\n","\n","final_zip_path = f\"{zip_path}.zip\"\n","\n","print(f\"       âœ… ZIP created: {final_zip_path}\")\n","\n","# List ZIP contents\n","print(f\"\\nðŸ“‚ ZIP Contents:\")\n","print(\"-\" * 60)\n","\n","for root, dirs, files in os.walk(RUN_DIR):\n","    level = root.replace(RUN_DIR, '').count(os.sep)\n","    indent = ' ' * 2 * level\n","    print(f\"{indent}{os.path.basename(root)}/\")\n","    sub_indent = ' ' * 2 * (level + 1)\n","    for file in files:\n","        print(f\"{sub_indent}{file}\")\n","\n","print(\"-\" * 60)\n","\n","# Final checklist\n","print(f\"\\nâœ… FINAL CHECKLIST:\")\n","print(\"-\" * 60)\n","print(f\"âœ… Run directory created: {RUN_DIR}\")\n","print(f\"âœ… run_manifest.json: {os.path.exists(manifest_path)}\")\n","print(f\"âœ… prompts_log.jsonl: {os.path.exists(prompts_log_path)}\")\n","print(f\"âœ… risk_log.json: {os.path.exists(risk_log_path)}\")\n","print(f\"âœ… pip_freeze.txt: {os.path.exists(pip_freeze_path)}\")\n","print(f\"âœ… AUDIT_README.txt: {os.path.exists(audit_readme_path)}\")\n","print(f\"âœ… deliverables/ directory: {len(deliverable_files)} files\")\n","print(f\"âœ… ZIP bundle: {os.path.exists(final_zip_path)}\")\n","print(\"-\" * 60)\n","\n","print(f\"\\nðŸ“¥ DOWNLOAD YOUR AUDIT TRAIL:\")\n","print(f\"   File: {final_zip_path}\")\n","print(f\"   Size: {os.path.getsize(final_zip_path) / 1024:.1f} KB\")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"âœ… CELL 10 COMPLETE - Notebook execution finished\")\n","print(\"=\"*60)\n","\n","print(f\"\\nðŸŽ‰ All tasks completed successfully!\")\n","print(f\"\\nðŸ“‹ Next steps:\")\n","print(f\"   1. Download the ZIP file: {final_zip_path}\")\n","print(f\"   2. Review all deliverables for verification\")\n","print(f\"   3. Check risk_log.json for flagged concerns\")\n","print(f\"   4. Verify all 'Not verified' content independently\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iBmH7UlkP_aW","executionInfo":{"status":"ok","timestamp":1767802861458,"user_tz":360,"elapsed":11,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"1e78441b-f897-4cd1-e000-8f824b971757"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","CELL 10: AUDIT TRAIL FINALIZATION\n","============================================================\n","\n","[1/2] âœ… AUDIT_README.txt created\n","       /content/ai_law_ch2_runs/run_20260107_153938/AUDIT_README.txt\n","\n","[2/2] ðŸ“¦ Creating ZIP bundle...\n","       âœ… ZIP created: /content/ai_law_ch2_run_20260107_153938.zip\n","\n","ðŸ“‚ ZIP Contents:\n","------------------------------------------------------------\n","run_20260107_153938/\n","  prompts_log.jsonl\n","  pip_freeze.txt\n","  risk_log.json\n","  run_manifest.json\n","  AUDIT_README.txt\n","  deliverables/\n","    regulatory_comment_letter_reasoning_draft.txt\n","    user_custom_scenario_output.json\n","    user_custom_scenario_draft.txt\n","    teaching_ai_policy_reasoning_draft.txt\n","    criminal_bail_motion_reasoning_draft.txt\n","    regulatory_comment_letter_reasoning_output.json\n","    criminal_bail_motion_reasoning_output.json\n","    teaching_ai_policy_reasoning_output.json\n","    international_contract_law_reasoning_draft.txt\n","    international_contract_law_reasoning_output.json\n","------------------------------------------------------------\n","\n","âœ… FINAL CHECKLIST:\n","------------------------------------------------------------\n","âœ… Run directory created: /content/ai_law_ch2_runs/run_20260107_153938\n","âœ… run_manifest.json: True\n","âœ… prompts_log.jsonl: True\n","âœ… risk_log.json: True\n","âœ… pip_freeze.txt: True\n","âœ… AUDIT_README.txt: True\n","âœ… deliverables/ directory: 10 files\n","âœ… ZIP bundle: True\n","------------------------------------------------------------\n","\n","ðŸ“¥ DOWNLOAD YOUR AUDIT TRAIL:\n","   File: /content/ai_law_ch2_run_20260107_153938.zip\n","   Size: 51.7 KB\n","\n","============================================================\n","âœ… CELL 10 COMPLETE - Notebook execution finished\n","============================================================\n","\n","ðŸŽ‰ All tasks completed successfully!\n","\n","ðŸ“‹ Next steps:\n","   1. Download the ZIP file: /content/ai_law_ch2_run_20260107_153938.zip\n","   2. Review all deliverables for verification\n","   3. Check risk_log.json for flagged concerns\n","   4. Verify all 'Not verified' content independently\n"]}]},{"cell_type":"markdown","source":["##11.CONCLUSIONS"],"metadata":{"id":"li7sSOpyUelv"}},{"cell_type":"markdown","source":["**Conclusion: The Complete Pipeline from Start to Finish**\n","\n","**The Journey You Just Completed**\n","\n","This notebook guided you through a complete professional AI workflow designed specifically for legal reasoning support. Unlike casual chatbot interactions where responses disappear after the conversation ends, you built a comprehensive system with governance, documentation, verification requirements, and audit trails. Understanding how all the pieces fit together helps you appreciate why each section was necessary and how the complete pipeline creates accountability that simple chat interfaces cannot provide.\n","\n","**Section 1: Foundation and Orientation**\n","\n","Your journey began with orientation to what this notebook does and does not do. You learned that Chapter 2 focuses on structured reasoning rather than document drafting. You saw warnings about confidentiality limitations and the critical requirement that all outputs must be independently verified. You reviewed the governance artifacts that would be created during the run. This foundation set expectations and established the professional context for everything that followed. Without this orientation, users might treat the notebook like a casual tool rather than a professional system with specific limitations and requirements.\n","\n","**Section 2: Creating the Infrastructure**\n","\n","The second section installed necessary software and created a timestamped run directory with a deliverables subdirectory. This organizational structure ensures that every notebook run produces a distinct set of outputs that never gets mixed up with previous runs. The timestamp becomes the unique identifier linking all artifacts from this specific session. This infrastructure setup happens invisibly but provides the foundation that every subsequent section depends on. Without proper directory structure, files would scatter chaotically across your workspace making audit trails impossible to maintain.\n","\n","**Section 3: Establishing the Connection**\n","\n","Section 3 retrieved your Anthropic API key from Colab's secure storage and initialized the client object that communicates with Claude. This connection step verified that you have proper credentials and that the notebook can reach the AI service. The section also locked in the specific model version to be used throughout the run. This standardization ensures consistency across all API calls. If this section fails, the entire notebook stops immediately rather than letting you discover connection problems after running many subsequent sections uselessly.\n","\n","**Section 4: Building the Governance Layer**\n","\n","The fourth section created four critical governance files. The run manifest documented metadata about this session including model used and capabilities tested. The prompts log was initialized to record every API interaction. The risk log was created to accumulate flagged concerns. The pip freeze documented the exact software environment for reproducibility. These governance artifacts transform the notebook from a simple tool into an auditable professional system. Every subsequent API call, every identified risk, every processing step gets recorded into these files automatically.\n","\n","**Section 5: Implementing Confidentiality Controls**\n","\n","Section 5 provided redaction utilities to remove sensitive information and data minimization functions to send only necessary information. The demonstration with fake data showed you exactly what these protections look like in practice. Critically, the section included prominent warnings that automated redaction is imperfect and cannot replace careful judgment about what information to input. These tools provide a safety layer but not a complete solution. Understanding both their utility and limitations helps you use them appropriately throughout the workflow.\n","\n","**Section 6: Engineering Reliable JSON Output**\n","\n","The sixth section created the wrapper function that calls Claude and forces structured JSON responses. The prefill technique starts Claude's response with an opening brace, dramatically improving reliability. Multiple extraction strategies handle various response formats. Schema validation ensures every required field is present. Retry logic provides three attempts before giving up. Error fallback returns valid structure even during failures. Automatic risk detection flags concerns. Logging captures everything for audit trails. This engineering effort solves the fundamental challenge of getting consistent structured output from a conversational AI that naturally wants to be helpful and explanatory rather than strictly formatted.\n","\n","**Section 7: Defining the Test Scenarios**\n","\n","Section 7 defined four mini-cases across different practice areas with deliberately simple prompts. Criminal defense bail motion reasoning. Regulatory comment letter strategy. International commercial law and arbitration choices. Academic AI use policy development. These scenarios demonstrated Level 2 reasoning capabilities across diverse legal contexts. The functions stored task names, fact lists, and prompts in structured format ready for execution. This separation between scenario definition and scenario execution created clean modular code that is easy to understand and modify.\n","\n","**Section 8: Processing the Mini-Cases**\n","\n","The eighth section executed the pipeline for all four predefined scenarios. It looped through each case, called the wrapper function, handled errors gracefully, saved both JSON and text outputs, tracked statistics, and produced a summary table. The continue-on-error approach meant that failures in one case did not prevent processing of remaining cases. Progress indicators provided real-time feedback. The dual output format gave you both machine-readable structure and human-readable narrative. By the end of this section, you had four complete analyses demonstrating what the system produces.\n","\n","**Section 9: Your Custom Analysis**\n","\n","Section 9 shifted from demonstration to practical application by letting you input your own hypothetical scenario. You chose between analysis memo or client communication guidance. The section applied redaction to your input, constructed an appropriate prompt based on your output type choice, called the wrapper function, and saved your custom outputs. This section transformed the notebook from an educational demonstration into a potentially useful workflow tool. Through experimentation you learned what kinds of scenarios produce helpful reasoning support.\n","\n","**Section 10: Packaging the Complete Archive**\n","\n","The final section created a comprehensive audit readme summarizing everything that happened during the run, then bundled all artifacts into a downloadable zip file. The audit readme provided statistics, verification checklists, confidentiality documentation, risk breakdowns, file listings, usage notes, and disclaimers. The zip archive packaged the manifest, logs, deliverables, and documentation into a single portable file. This packaging step transformed scattered outputs into a professional archive suitable for compliance review, quality control, or long-term retention.\n","\n","**The Complete Data Flow**\n","\n","Following the data flow helps solidify understanding. Your scenario facts and prompt enter through Section 9 or come from predefined cases in Section 7. Section 5's redaction tools clean the input. Section 6's wrapper function sends the redacted prompt to Claude using the connection from Section 3, applying prefill to force JSON output. The wrapper validates the response against the required schema and retries if needed. Successful responses get logged to the prompts file from Section 4. Identified risks get logged to the risk file from Section 4. Section 8 or 9 saves the output as both JSON and text in the deliverables directory from Section 2. Section 10 documents everything in the audit readme and bundles it all into a zip file using the run directory structure from Section 2.\n","\n","**Why This Pipeline Matters**\n","\n","Every step in this pipeline serves professional responsibility requirements that casual chatbot interactions ignore. The governance layer creates documentation proving reasonable supervision. The structured outputs enable systematic verification. The risk logging captures concerns for follow-up. The audit trail provides evidence of responsible AI usage. The confidentiality controls demonstrate reasonable precautions. The verification requirements ensure you never rely on unverified AI reasoning. Together these components transform AI from a risky black box into a tool that can be used responsibly within legal practice when properly supervised and verified by competent lawyers."],"metadata":{"id":"5HJMPk2LU29v"}}]}