{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyM/XSS03YedhMFt9ttVteMW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**AI LAW CHAPTER 3. AGENTS**\n","---"],"metadata":{"id":"5l5xKKiuLa3g"}},{"cell_type":"markdown","source":["##0.REFERENCE"],"metadata":{"id":"i-ntS8gKMhJc"}},{"cell_type":"markdown","source":["https://claude.ai/share/c4e700cb-2603-4b72-b3d7-7ef33ec6791f"],"metadata":{"id":"KqukQsnOipN8"}},{"cell_type":"markdown","source":["##1.CONTEXT"],"metadata":{"id":"Z625nbvKMjV7"}},{"cell_type":"markdown","source":["**Welcome to Chapter 3: Understanding Multi-Step AI Workflows for Legal Practice**\n","\n","**What You're About to Experience**\n","\n","You're about to work with a Google Colab notebook that demonstrates how artificial intelligence can assist with complex legal tasks through coordinated, multi-step workflows. If you've used ChatGPT, Claude, or similar chatbots through a website or mobile app, you already understand the basics: you type a question or request, the AI responds, and you continue the conversation. This notebook takes that familiar experience and transforms it into something fundamentally different, more powerful, and more appropriate for professional legal work.\n","\n","**Why Casual Chatbot Use Isn't Enough for Lawyers**\n","\n","When you use a chatbot casually, you might ask it to write an email, explain a concept, or brainstorm ideas. If the response isn't quite right, you refine your prompt and try again. If it makes something up, it's annoying but rarely catastrophic. You're the only person who sees the conversation, there's no record of what happened, and you're not professionally or ethically obligated to verify every claim the AI makes.\n","\n","Legal practice operates under completely different constraints. When you use AI to help with legal work, you're creating work product that might affect someone's rights, liberty, property, or livelihood. You have ethical duties to your clients including competence, confidentiality, and diligence. You have duties to tribunals including candor and honesty. You operate under rules of professional conduct that can result in discipline, malpractice liability, or sanctions if violated. A hallucinated case citation in a court filing isn't just embarrassing; it can result in sanctions, damage to your reputation, and harm to your client's interests.\n","\n","This notebook teaches you how to build systems that acknowledge and address these heightened responsibilities. It demonstrates controls, documentation, and governance practices that transform casual AI interaction into professional-grade legal technology.\n","\n","**What Makes This Chapter Different: Multi-Step Workflows**\n","\n","In earlier chapters of this course, you learned to use AI for single-task work: summarize this document, draft this email, check this contract for standard provisions. Those are valuable skills, but they represent only a fraction of what modern AI can do. Chapter 3 introduces orchestrated workflows where multiple specialized AI calls work together to accomplish complex objectives that no single prompt could handle.\n","\n","Think about how a law firm actually works. When a new client matter arrives, you don't assign one lawyer to do everything simultaneously. Instead, different people with different expertise handle different phases. Someone conducts intake and gathers facts. Someone spots legal issues and researches precedents. Someone drafts the primary work product. Someone else reviews it for quality. Perhaps another person performs adversarial review, deliberately trying to find weaknesses. Finally, someone assembles everything into a polished final deliverable. This division of labor produces better results than any single person working alone could achieve.\n","\n","This notebook implements that same pattern using AI. Instead of asking Claude to \"write a legal memo about this situation,\" which often produces mediocre results, the system breaks the task into discrete steps. An orchestrator function plans the workflow. Specialist functions handle intake, issue spotting, drafting, quality assurance, adversarial review, and final assembly. Each specialist focuses on one thing, does it well, and hands off to the next specialist with notes about what to do next. The result is dramatically higher quality than single-shot generation.\n","\n","**The Critical Addition: Human Oversight Checkpoints**\n","\n","The most important feature this chapter introduces isn't the multi-step workflow itself; it's the human approval gates built into the process. After the orchestrator creates a plan, the system pauses for human review and approval before proceeding. After quality assurance identifies potential problems, a human decides whether to continue or stop. These checkpoints ensure that lawyers remain in control rather than allowing AI to operate autonomously.\n","\n","This matters enormously for professional responsibility. Many bar ethics opinions about AI emphasize that lawyers must supervise AI tools and cannot delegate professional judgment to machines. By building explicit approval points into the workflow, this notebook demonstrates a architecture that keeps humans in the loop at critical decision points. The AI proposes, analyzes, and drafts, but humans approve, direct, and take responsibility.\n","\n","**Governance and Audit Trails: Proving You Did It Right**\n","\n","Another fundamental difference between casual chatbot use and professional legal AI is documentation. When you use ChatGPT for personal tasks, the conversation might be saved in your account, but there's no systematic audit trail, no risk logging, no verification tracking, and no archival package you could present to opposing counsel or a disciplinary committee.\n","\n","This notebook generates comprehensive governance artifacts. Every API call gets logged with cryptographic hashes that prove it happened while protecting confidential content. Every risk the system identifies gets recorded with severity levels and context. Every output includes structured quality checks and explicit statements about what hasn't been verified. At the end, you download a complete audit package with a human-readable guide explaining what everything means.\n","\n","Why does this matter? Because if you use AI in legal practice, you may eventually need to explain what you did and why. A court might question your methodology. A malpractice insurer might investigate your use of technology. A bar ethics committee might examine whether you properly supervised AI tools. Having a complete, contemporaneous record of what the system did, what risks it flagged, and what verification it recommended gives you defensible documentation of responsible AI use.\n","\n","**Confidentiality and Privilege: Built-In Protections**\n","\n","When you use consumer chatbot services, your inputs typically get sent to the company's servers, potentially used for model training, and stored indefinitely. That's acceptable for casual use but completely inappropriate for privileged attorney-client communications or confidential client information.\n","\n","This notebook implements multiple layers of protection. It includes redaction functions that attempt to remove emails, phone numbers, social security numbers, and addresses before anything goes to the API. It demonstrates minimum-necessary-data principles, sending only information relevant to the task rather than wholesale client files. It logs only cryptographic hashes of prompts rather than actual content. It includes prominent warnings that redaction is imperfect and that you should never paste actual sensitive data into educational tools.\n","\n","These protections aren't foolproof, and the notebook makes that clear. But they demonstrate the kind of thinking required when building legal AI systems. You must constantly ask: what data am I exposing, where is it going, who can access it, how long is it retained, and what are the privilege implications?\n","\n","**Why This Chapter Matters for Your Practice**\n","\n","Chapter 3 represents a inflection point in legal AI capability. Simple single-task AI assistance is already commonplace and relatively low risk. Multi-step agentic workflows are dramatically more powerful but also more complex and potentially risky. They can handle tasks that previously required days of lawyer time. They can coordinate multiple analytical perspectives on the same problem. They can produce work product that, with appropriate human review, rivals what senior associates generate.\n","\n","But with that power comes responsibility. You need to understand not just how to make these systems work, but how to make them work safely, ethically, and defensibly. You need governance frameworks that scale as your AI usage becomes more sophisticated. You need to develop judgment about when multi-step AI workflows are appropriate and when simpler approaches suffice.\n","\n","This notebook gives you hands-on experience with production-grade patterns you could actually adapt for practice. It's not a toy demo that skips the hard parts. It includes error handling, retry logic, risk logging, quality checks, and documentation practices you'd need in real use. By working through it, you develop both technical skills and professional judgment about responsible legal AI deployment.\n","\n","**Your Learning Path Through Ten Sections**\n","\n","The notebook contains exactly ten sections, each building on the previous ones. You'll start by understanding the concepts, then set up your environment, connect to the AI service, initialize governance systems, learn about confidentiality protections, build the critical JSON communication wrapper, define your agent team and cases, execute complete workflows, practice with your own scenario, and finally package everything for audit and archive.\n","\n","By the end, you'll have generated multiple complete legal work products through coordinated multi-step workflows, examined the audit trail showing exactly what happened, and downloaded a governance package demonstrating responsible AI use. More importantly, you'll understand the architecture, controls, and thinking required to deploy powerful AI systems in legal practice while maintaining professional and ethical standards.\n","\n","Welcome to Chapter 3. Let's begin."],"metadata":{"id":"1_B9j9orimVf"}},{"cell_type":"code","source":[],"metadata":{"id":"2WQPA6pEMkhE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##2.LIBRARIES AND ENVIRONMENT"],"metadata":{"id":"Gw6ndeDvMlAk"}},{"cell_type":"code","source":["# Cell 2: Installation and Setup\n","\n","import os\n","import json\n","import hashlib\n","from datetime import datetime\n","from pathlib import Path\n","import re\n","\n","# Create timestamped run directory\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","RUN_DIR = Path(f\"/content/ai_law_ch3_runs/run_{timestamp}\")\n","RUN_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Create subdirectories\n","DELIVERABLES_DIR = RUN_DIR / \"deliverables\"\n","DELIVERABLES_DIR.mkdir(exist_ok=True)\n","\n","print(f\"‚úÖ Run directory created: {RUN_DIR}\")\n","print(f\"‚úÖ Deliverables directory: {DELIVERABLES_DIR}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yImzIhg8Mqr6","executionInfo":{"status":"ok","timestamp":1767822965705,"user_tz":360,"elapsed":45,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"ea04ba21-b485-4db5-ae6a-6561cd22e7c6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Run directory created: /content/ai_law_ch3_runs/run_20260107_215606\n","‚úÖ Deliverables directory: /content/ai_law_ch3_runs/run_20260107_215606/deliverables\n"]}]},{"cell_type":"markdown","source":["##3.API KEY AND CLIENT INITIALIZATION"],"metadata":{"id":"xohs6ldsNTJ3"}},{"cell_type":"markdown","source":["###3.1.OVERVIEW"],"metadata":{"id":"ymAmvhSIMrNn"}},{"cell_type":"markdown","source":["**Section 3: Connecting to Claude's Brain**\n","\n","**What This Section Does**\n","\n","This section establishes the connection between your notebook and Claude, the AI model that will perform the legal analysis work. Think of it as plugging in a power cord before you can use an appliance. Without this connection, nothing else in the notebook can function.\n","\n","**The API Key: Your Access Credential**\n","\n","An API key is like a password that proves you have permission to use Claude's services. Anthropic (the company that created Claude) issues these keys to paying customers. When you store your key in Google Colab's secure \"Secrets\" area, you're putting it in a digital vault that only your notebook can access. This prevents anyone who sees your notebook from stealing your credentials.\n","\n","**Why We Need a Client Object**\n","\n","The \"client\" is a software tool that handles all communication with Claude's servers. When you want Claude to analyze a legal document or generate a memo, the client packages your request properly, sends it over the internet to Anthropic's computers, waits for Claude to process it, and brings the response back to your notebook. Without initializing this client, you'd have no way to talk to Claude.\n","\n","**The Model Name Matters**\n","\n","We specify \"claude-sonnet-4-5-20250929\" as our model because Anthropic offers different versions of Claude, each with different capabilities and costs. Sonnet 4.5 is the most intelligent version available as of this writing, making it ideal for complex legal analysis where accuracy matters most. The numbers at the end indicate the exact release date, which is important for reproducibility. If someone runs your notebook in the future, they'll know exactly which version of Claude you used.\n","\n","**What Success Looks Like**\n","\n","When this section runs successfully, you'll see three green checkmarks confirming that your API key loaded, the correct model was selected, and the client initialized properly. If something goes wrong, you'll see a red X with an error message, typically indicating that you forgot to add your API key to Colab Secrets or that you mistyped the secret name.\n","\n","**Why This Comes Early**\n","\n","We set up the API connection in Section 3, right after creating folders but before doing any real work, because every subsequent section depends on it. You can't generate legal documents, log API calls, or run workflows without first establishing this fundamental connection. It's the foundation upon which everything else is built."],"metadata":{"id":"-Kg8N-SUfo8R"}},{"cell_type":"markdown","source":["###3.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"mMfmX3mRNYBH"}},{"cell_type":"code","source":["# Cell 3: API Key and Client Initialization\n","\n","!pip install anthropic -q\n","\n","import anthropic\n","from google.colab import userdata\n","\n","# Load API key from Colab Secrets\n","try:\n","    ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n","    os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n","\n","    # Initialize client\n","    client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n","    MODEL = \"claude-sonnet-4-5-20250929\"\n","\n","    print(\"‚úÖ API key loaded successfully\")\n","    print(f\"‚úÖ Model: {MODEL}\")\n","    print(f\"‚úÖ Client initialized\")\n","\n","except Exception as e:\n","    print(f\"‚ùå Error loading API key: {e}\")\n","    print(\"Please add ANTHROPIC_API_KEY to Colab Secrets (Settings ‚Üí Secrets)\")"],"metadata":{"id":"mSysx22_NZ7y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767822979711,"user_tz":360,"elapsed":11200,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"9dffff0c-5ffd-4bb6-c8f4-e4c2cfdd5981"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/388.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m378.9/388.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h‚úÖ API key loaded successfully\n","‚úÖ Model: claude-sonnet-4-5-20250929\n","‚úÖ Client initialized\n"]}]},{"cell_type":"markdown","source":["##4.GOVERNANCE UTILITIES AND INITIAL ARTIFACTS"],"metadata":{"id":"liynvWZjNaan"}},{"cell_type":"markdown","source":["###4.1.OVERVIEW"],"metadata":{"id":"23pnC2AQODt1"}},{"cell_type":"markdown","source":["**Section 4: Building the Paper Trail**\n","\n","**What This Section Does**\n","\n","This section creates the foundational audit files that track every decision and action your AI workflow takes. Think of it as setting up a filing cabinet before you start generating documents. In legal practice, being able to prove what happened, when it happened, and why it happened is absolutely critical. This section ensures you can do exactly that.\n","\n","**The Run Manifest: Your Case File Cover Sheet**\n","\n","The run manifest is a single file that captures basic metadata about this particular execution. It records the timestamp, which model you used, what chapter of the course you're working on, and where all the files are stored. If you need to come back six months later and figure out what happened during this run, the manifest is your starting point. It's like the cover page of a case file that tells you what's inside.\n","\n","**Prompts Log: The Redacted Conversation Record**\n","\n","The prompts log uses a special format called JSONL, where each line is a separate log entry. Every time your notebook talks to Claude, it writes one line to this file. However, we don't store the actual text of your prompts or Claude's responses, because those might contain confidential client information. Instead, we store cryptographic hashes, which are like digital fingerprints. You can prove a conversation happened and verify its contents haven't been tampered with, but you can't reverse-engineer the original text from the hash. This protects privilege while maintaining accountability.\n","\n","**Risk Log: Your Early Warning System**\n","\n","The risk log starts as an empty container ready to collect problems. As your workflow runs, each step evaluates itself for issues like missing facts, potential hallucinations, confidentiality concerns, or unauthorized practice of law. Every risk gets logged here with its severity level, which step detected it, and what the concern was. By the end of your workflow, this file becomes a comprehensive quality control report.\n","\n","**Pip Freeze: The Reproducibility Safety Net**\n","\n","This file captures the exact version of every Python library installed in your environment. Software changes constantly, and code that works today might break tomorrow if a library updates. By recording these versions, someone could recreate your exact setup years from now. In legal technology, where you might need to defend your methodology in court or explain it to a bar ethics committee, this level of documentation is invaluable.\n","\n","**Why We Do This First**\n","\n","These files must exist before any substantive work begins because they need to capture everything that happens. You can't retroactively create an audit trail. By initializing these governance files in Section 4, we ensure that from the very first API call onward, everything is tracked and documented."],"metadata":{"id":"zhhXqfBgf5oA"}},{"cell_type":"markdown","source":["###4.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"HEh91uJVdGUm"}},{"cell_type":"code","source":["# Cell 4: Governance Utilities and Initial Artifacts\n","\n","import subprocess\n","\n","# Initialize governance files\n","\n","# 1. Run manifest\n","run_manifest = {\n","    \"run_id\": timestamp,\n","    \"run_dir\": str(RUN_DIR),\n","    \"created_at\": datetime.now().isoformat(),\n","    \"model\": MODEL,\n","    \"chapter\": \"3_agents\",\n","    \"author\": \"Alejandro Reynoso\",\n","    \"purpose\": \"Multi-step legal workflows with human-in-the-loop checkpoints\"\n","}\n","\n","manifest_path = RUN_DIR / \"run_manifest.json\"\n","with open(manifest_path, 'w') as f:\n","    json.dump(run_manifest, f, indent=2)\n","\n","# 2. Prompts log (JSONL format)\n","prompts_log_path = RUN_DIR / \"prompts_log.jsonl\"\n","prompts_log_path.touch()\n","\n","# 3. Risk log\n","risk_log_path = RUN_DIR / \"risk_log.json\"\n","with open(risk_log_path, 'w') as f:\n","    json.dump({\"risks\": [], \"created_at\": datetime.now().isoformat()}, f, indent=2)\n","\n","# 4. pip freeze for reproducibility\n","pip_freeze_path = RUN_DIR / \"pip_freeze.txt\"\n","try:\n","    result = subprocess.run(['pip', 'freeze'], capture_output=True, text=True)\n","    with open(pip_freeze_path, 'w') as f:\n","        f.write(result.stdout)\n","except:\n","    pass\n","\n","print(\"‚úÖ Governance artifacts initialized:\")\n","print(f\"   üìÑ {manifest_path}\")\n","print(f\"   üìÑ {prompts_log_path}\")\n","print(f\"   üìÑ {risk_log_path}\")\n","print(f\"   üìÑ {pip_freeze_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H03BOPP6dYni","executionInfo":{"status":"ok","timestamp":1767822992874,"user_tz":360,"elapsed":6841,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"fc333213-8e7c-403d-e659-837396e63e59"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Governance artifacts initialized:\n","   üìÑ /content/ai_law_ch3_runs/run_20260107_215606/run_manifest.json\n","   üìÑ /content/ai_law_ch3_runs/run_20260107_215606/prompts_log.jsonl\n","   üìÑ /content/ai_law_ch3_runs/run_20260107_215606/risk_log.json\n","   üìÑ /content/ai_law_ch3_runs/run_20260107_215606/pip_freeze.txt\n"]}]},{"cell_type":"markdown","source":["##5.REDACTION AND MINIMUM NECESSARY DATA INTAKE"],"metadata":{"id":"0EDBqKVJOvty"}},{"cell_type":"markdown","source":["###5.1.OVERVIEW"],"metadata":{"id":"6d9AxaooOxOT"}},{"cell_type":"markdown","source":["**Section 5: Protecting Confidential Information**\n","\n","**What This Section Does**\n","\n","This section introduces critical safety tools that attempt to remove sensitive personal information before anything gets sent to Claude or written to your log files. It demonstrates two functions: one that redacts identifiable information, and another that removes unnecessary data fields. Think of this as your first line of defense against accidental confidentiality breaches.\n","\n","**The Redaction Function: Automated Privacy Protection**\n","\n","The redaction function scans text looking for patterns that typically indicate sensitive information. It searches for email addresses, phone numbers, social security numbers, and street addresses, then replaces them with placeholder text like \"[EMAIL_REDACTED]\" or \"[PHONE_REDACTED]\". This happens automatically before any text goes to Claude's servers or gets written to disk. The function uses pattern matching, which means it looks for structures like three digits, a dash, two digits, a dash, and four digits for social security numbers.\n","\n","**Why Redaction Is Imperfect**\n","\n","The notebook displays a very clear warning: redaction is best effort only, not foolproof. Pattern matching catches common formats, but people write information in countless ways. Someone might write \"my email is john dot doe at example dot com\" instead of using the standard format. The function would miss that. Similarly, sensitive information doesn't always follow predictable patterns. A client's business valuation or proprietary trade secret might look like ordinary text. This is why the warning says never to paste actual sensitive client data into the notebook, even with redaction enabled.\n","\n","**Minimum Necessary Data: Reducing Exposure**\n","\n","The second function demonstrates a principle borrowed from healthcare privacy law: only collect and transmit the minimum information necessary to accomplish your task. If you have a dictionary of client information with twenty fields, but only five are relevant to the legal analysis, this function strips out the other fifteen before sending anything to Claude. It returns two things: the cleaned data that will be used, and a list of fields that were removed. This gives you visibility into what's being excluded and confidence that unnecessary exposure is minimized.\n","\n","**The Demonstration: Learning by Example**\n","\n","The section includes a live demonstration using fake data. You can see text before redaction (with visible email, phone, and social security number) and after redaction (with placeholders). You also see how the minimum necessary function removes irrelevant fields like shoe size and favorite color while keeping jurisdiction and legal issue information. This hands-on example helps you understand exactly what these functions do before they're used in real workflow steps."],"metadata":{"id":"QnGKpNfZgUJV"}},{"cell_type":"markdown","source":["###5.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"-HPlfcFnOzGk"}},{"cell_type":"code","source":["# Cell 5: Redaction and Minimum-Necessary Data Intake\n","\n","def redact(text):\n","    \"\"\"\n","    Redact potentially sensitive information.\n","    WARNING: This is best-effort only. Do NOT rely on this for actual sensitive data.\n","    \"\"\"\n","    if not text:\n","        return text\n","\n","    redacted = text\n","\n","    # Email addresses\n","    redacted = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL_REDACTED]', redacted)\n","\n","    # Phone numbers (various formats)\n","    redacted = re.sub(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', '[PHONE_REDACTED]', redacted)\n","    redacted = re.sub(r'\\(\\d{3}\\)\\s*\\d{3}[-.]?\\d{4}', '[PHONE_REDACTED]', redacted)\n","\n","    # SSN patterns\n","    redacted = re.sub(r'\\b\\d{3}-\\d{2}-\\d{4}\\b', '[SSN_REDACTED]', redacted)\n","\n","    # Street addresses (simple pattern)\n","    redacted = re.sub(r'\\b\\d+\\s+[A-Z][a-z]+\\s+(Street|St|Avenue|Ave|Road|Rd|Boulevard|Blvd|Lane|Ln|Drive|Dr|Court|Ct)\\b',\n","                     '[ADDRESS_REDACTED]', redacted)\n","\n","    return redacted\n","\n","\n","def minimum_necessary_intake(facts_dict):\n","    \"\"\"\n","    Helper to remove unnecessary fields before sending to API.\n","    Returns: (redacted_facts, removed_fields)\n","    \"\"\"\n","    # Define essential fields per domain\n","    essential_fields = ['jurisdiction', 'legal_issue', 'key_facts', 'desired_outcome', 'timeline']\n","\n","    removed = []\n","    cleaned = {}\n","\n","    for key, value in facts_dict.items():\n","        if key in essential_fields:\n","            cleaned[key] = redact(str(value))\n","        else:\n","            removed.append(key)\n","\n","    return cleaned, removed\n","\n","\n","# Demo with fake data\n","print(\"üîí Redaction Demo\\n\")\n","\n","sample_text = \"\"\"\n","Client John Doe (john.doe@example.com, 555-123-4567, SSN: 123-45-6789)\n","lives at 123 Main Street and needs help with a contract dispute.\n","\"\"\"\n","\n","print(\"BEFORE REDACTION:\")\n","print(sample_text)\n","print(\"\\nAFTER REDACTION:\")\n","print(redact(sample_text))\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"\\nüìã Minimum-Necessary Intake Demo\\n\")\n","\n","sample_facts = {\n","    \"client_name\": \"John Doe\",\n","    \"client_email\": \"john.doe@example.com\",\n","    \"client_phone\": \"555-123-4567\",\n","    \"jurisdiction\": \"California\",\n","    \"legal_issue\": \"Contract breach\",\n","    \"key_facts\": [\"Contract signed Jan 2024\", \"Payment due March 2024\", \"No payment received\"],\n","    \"shoe_size\": \"10.5\",\n","    \"favorite_color\": \"blue\"\n","}\n","\n","cleaned, removed = minimum_necessary_intake(sample_facts)\n","\n","print(\"CLEANED FACTS (sent to API):\")\n","print(json.dumps(cleaned, indent=2))\n","print(f\"\\nREMOVED FIELDS: {removed}\")\n","print(\"\\n‚ö†Ô∏è  Remember: Redaction is imperfect. Never paste actual sensitive client data.\")"],"metadata":{"id":"bnMaou19O0rS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767823005429,"user_tz":360,"elapsed":20,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"a878dc43-7eff-45d8-ff75-776b9161f447"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["üîí Redaction Demo\n","\n","BEFORE REDACTION:\n","\n","Client John Doe (john.doe@example.com, 555-123-4567, SSN: 123-45-6789) \n","lives at 123 Main Street and needs help with a contract dispute.\n","\n","\n","AFTER REDACTION:\n","\n","Client John Doe ([EMAIL_REDACTED], [PHONE_REDACTED], SSN: [SSN_REDACTED]) \n","lives at [ADDRESS_REDACTED] and needs help with a contract dispute.\n","\n","\n","============================================================\n","\n","üìã Minimum-Necessary Intake Demo\n","\n","CLEANED FACTS (sent to API):\n","{\n","  \"jurisdiction\": \"California\",\n","  \"legal_issue\": \"Contract breach\",\n","  \"key_facts\": \"['Contract signed Jan 2024', 'Payment due March 2024', 'No payment received']\"\n","}\n","\n","REMOVED FIELDS: ['client_name', 'client_email', 'client_phone', 'shoe_size', 'favorite_color']\n","\n","‚ö†Ô∏è  Remember: Redaction is imperfect. Never paste actual sensitive client data.\n"]}]},{"cell_type":"markdown","source":["##6.CLAUDE WRAPPER"],"metadata":{"id":"2zDiTWnXdrqT"}},{"cell_type":"markdown","source":["###6.1.OVERVIEW"],"metadata":{"id":"2VbOfB9OduKZ"}},{"cell_type":"markdown","source":["**Section 6: The Critical JSON Wrapper with Prefill Technique**\n","\n","**What This Section Does**\n","\n","This is the most technically important section in the entire notebook. It creates the function that actually talks to Claude and forces Claude to return data in a structured, parseable format. Previous versions of this workflow often failed because Claude would wrap its JSON output in conversational text or markdown formatting, breaking the entire system. This section solves that problem using a technique called prefilling.\n","\n","**The Prefill Technique: Forcing Clean Output**\n","\n","Here's the key innovation: when you normally ask Claude a question, Claude decides how to format the answer. Sometimes it says \"Here's the JSON you requested\" and then provides the data, which ruins everything because you can't parse conversational text. The prefill technique works by sending Claude a message that already starts with an opening curly brace. Claude then feels compelled to complete the JSON object rather than add conversational wrapper text. It's like handing someone a sentence that starts \"The capital of France is...\" and they naturally complete it rather than starting over. This dramatically increases reliability.\n","\n","**The System Prompt: Setting Strict Rules**\n","\n","The function includes a system prompt that establishes non-negotiable rules for Claude's behavior. It provides the exact JSON schema that Claude must follow, listing every required field from \"task\" to \"verification_status\". It explicitly forbids markdown formatting, conversational text, or anything outside the JSON structure. It also includes critical legal guardrails: never invent citations, always mark verification status as \"Not verified\", and always include disclaimers. This system prompt acts like jury instructions, telling Claude exactly what's allowed and what's forbidden.\n","\n","**The Retry Logic: Graceful Failure Handling**\n","\n","Even with prefill and strict instructions, things can occasionally go wrong. Network issues, API errors, or unexpected responses happen. The function attempts each API call up to three times with progressively stricter temperature settings. Temperature controls randomness in Claude's outputs; lower temperatures produce more deterministic, focused responses. If all three attempts fail, rather than crashing the entire notebook, the function returns a valid JSON object with error information and high-severity risk flags. This ensures your workflow can continue and produce a complete audit trail even when individual steps fail.\n","\n","**The Smoke Test: Proving It Works**\n","\n","The section ends with a smoke test that immediately calls the function with simple test data. This proves the prefill technique works before you run the full workflow. You see whether valid JSON comes back on the first attempt and whether the schema validation passes. This immediate feedback gives you confidence that the most critical component of your system is functioning correctly."],"metadata":{"id":"J08RfAAshKCk"}},{"cell_type":"markdown","source":["###6.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"Pj-9VxPzdwDE"}},{"cell_type":"code","source":["# Cell 6: Claude JSON Wrapper with PREFILL TECHNIQUE (CRITICAL)\n","\n","def call_claude_json_prefill(task_description, facts_list, deliverable_type=\"memo\",\n","                              word_limit=400, case_id=\"unknown\", step_name=\"unknown\"):\n","    \"\"\"\n","    Call Claude with PREFILL technique to force pure JSON output.\n","\n","    CRITICAL: Uses assistant message with \"{\" to force JSON completion.\n","    \"\"\"\n","\n","    # Build minimal system prompt (schema definition)\n","    system_prompt = \"\"\"You MUST output ONLY a valid JSON object. Start with { and end with }.\n","\n","Your output MUST match this EXACT schema:\n","\n","{\n","  \"task\": \"string\",\n","  \"facts_provided\": [\"array of strings\"],\n","  \"assumptions\": [\"array of strings\"],\n","  \"open_questions\": [\"array of strings\"],\n","  \"work_product\": {\n","    \"deliverable_type\": \"memo|email|outline|checklist|plan\",\n","    \"content\": \"string (must include disclaimer)\"\n","  },\n","  \"quality_checks\": {\n","    \"missing_facts_check\": [\"array\"],\n","    \"hallucination_check\": [\"array\"],\n","    \"privilege_confidentiality_check\": [\"array\"],\n","    \"tone_check\": [\"array\"]\n","  },\n","  \"handoff_notes\": {\n","    \"next_agent\": \"string\",\n","    \"what_to_do_next\": [\"array\"],\n","    \"stop_conditions\": [\"array\"]\n","  },\n","  \"risks\": [\n","    {\"type\": \"confidentiality|privilege|hallucination|missing_facts|unauthorized_practice|overconfidence|prompt_injection|tone|other\",\n","     \"severity\": \"low|medium|high\",\n","     \"note\": \"string\"}\n","  ],\n","  \"verification_status\": \"Not verified\",\n","  \"questions_to_verify\": [\"array\"]\n","}\n","\n","RULES:\n","- verification_status MUST be \"Not verified\"\n","- NEVER invent citations, cases, statutes, or authorities\n","- work_product.content MUST include: \"This is a draft only. Not legal advice. Human lawyer review required.\"\n","- NO markdown, NO text outside JSON\n","- NO conversational wrapper\n","\"\"\"\n","\n","    # Build minimal user prompt (no field-by-field instructions)\n","    user_prompt = f\"\"\"Task: {task_description}\n","\n","Facts provided:\n","{json.dumps(facts_list, indent=2)}\n","\n","Output constraints:\n","- Deliverable type: {deliverable_type}\n","- Word limit for work_product.content: {word_limit} words maximum\n","- Return ONLY JSON matching the schema.\"\"\"\n","\n","    max_attempts = 3\n","    temperatures = [0.1, 0.0, 0.0]\n","\n","    for attempt in range(max_attempts):\n","        try:\n","            temp = temperatures[attempt]\n","\n","            # PREFILL TECHNIQUE: Add assistant message with \"{\"\n","            response = client.messages.create(\n","                model=MODEL,\n","                max_tokens=1800,\n","                temperature=temp,\n","                system=system_prompt,\n","                messages=[\n","                    {\"role\": \"user\", \"content\": user_prompt},\n","                    {\"role\": \"assistant\", \"content\": \"{\"} # PREFILL\n","                ]\n","            )\n","\n","            # Extract completion and PREPEND the \"{\"\n","            raw_completion = response.content[0].text\n","            full_json_text = \"{\" + raw_completion\n","\n","            # Try to parse\n","            result = json.loads(full_json_text)\n","\n","            # Validate required fields\n","            required_keys = [\"task\", \"facts_provided\", \"assumptions\", \"open_questions\",\n","                           \"work_product\", \"quality_checks\", \"handoff_notes\", \"risks\",\n","                           \"verification_status\", \"questions_to_verify\"]\n","\n","            missing = [k for k in required_keys if k not in result]\n","            if missing:\n","                raise ValueError(f\"Missing required keys: {missing}\")\n","\n","            # Auto-add risks if needed\n","            if not result.get(\"risks\"):\n","                result[\"risks\"] = []\n","\n","            # Add metadata\n","            result[\"_meta\"] = {\n","                \"case_id\": case_id,\n","                \"step_name\": step_name,\n","                \"attempt\": attempt + 1,\n","                \"temperature\": temp,\n","                \"timestamp\": datetime.now().isoformat()\n","            }\n","\n","            # Log to prompts_log.jsonl (redacted)\n","            log_entry = {\n","                \"timestamp\": datetime.now().isoformat(),\n","                \"case_id\": case_id,\n","                \"step_name\": step_name,\n","                \"prompt_hash\": hashlib.sha256(user_prompt.encode()).hexdigest()[:16],\n","                \"response_hash\": hashlib.sha256(full_json_text.encode()).hexdigest()[:16],\n","                \"attempt\": attempt + 1,\n","                \"success\": True\n","            }\n","            with open(prompts_log_path, 'a') as f:\n","                f.write(json.dumps(log_entry) + '\\n')\n","\n","            # Log risks\n","            if result.get(\"risks\"):\n","                with open(risk_log_path, 'r') as f:\n","                    risk_data = json.load(f)\n","                for risk in result[\"risks\"]:\n","                    risk_data[\"risks\"].append({\n","                        **risk,\n","                        \"case_id\": case_id,\n","                        \"step_name\": step_name,\n","                        \"timestamp\": datetime.now().isoformat()\n","                    })\n","                with open(risk_log_path, 'w') as f:\n","                    json.dump(risk_data, f, indent=2)\n","\n","            return result\n","\n","        except json.JSONDecodeError as e:\n","            if attempt == max_attempts - 1:\n","                # Final attempt failed - return valid error JSON\n","                error_result = {\n","                    \"task\": task_description,\n","                    \"facts_provided\": facts_list,\n","                    \"assumptions\": [\"JSON parsing failed after 3 attempts\"],\n","                    \"open_questions\": [\"Unable to complete task due to parsing error\"],\n","                    \"work_product\": {\n","                        \"deliverable_type\": deliverable_type,\n","                        \"content\": f\"ERROR: Could not generate valid JSON output. This is a draft only. Not legal advice. Human lawyer review required. Error: {str(e)[:100]}\"\n","                    },\n","                    \"quality_checks\": {\n","                        \"missing_facts_check\": [\"N/A - error state\"],\n","                        \"hallucination_check\": [\"N/A - error state\"],\n","                        \"privilege_confidentiality_check\": [\"N/A - error state\"],\n","                        \"tone_check\": [\"N/A - error state\"]\n","                    },\n","                    \"handoff_notes\": {\n","                        \"next_agent\": \"Human lawyer\",\n","                        \"what_to_do_next\": [\"Review error\", \"Retry manually\"],\n","                        \"stop_conditions\": [\"System error\"]\n","                    },\n","                    \"risks\": [\n","                        {\n","                            \"type\": \"other\",\n","                            \"severity\": \"high\",\n","                            \"note\": f\"JSON_PARSE_ERROR: {str(e)[:100]}\"\n","                        }\n","                    ],\n","                    \"verification_status\": \"Not verified\",\n","                    \"questions_to_verify\": [\"All output invalid due to error\"],\n","                    \"_meta\": {\n","                        \"case_id\": case_id,\n","                        \"step_name\": step_name,\n","                        \"attempt\": attempt + 1,\n","                        \"error\": True\n","                    }\n","                }\n","                return error_result\n","        except Exception as e:\n","            if attempt == max_attempts - 1:\n","                error_result = {\n","                    \"task\": task_description,\n","                    \"facts_provided\": facts_list,\n","                    \"assumptions\": [\"API call failed\"],\n","                    \"open_questions\": [\"Unable to complete task due to API error\"],\n","                    \"work_product\": {\n","                        \"deliverable_type\": deliverable_type,\n","                        \"content\": f\"ERROR: API call failed. This is a draft only. Not legal advice. Human lawyer review required. Error: {str(e)[:100]}\"\n","                    },\n","                    \"quality_checks\": {\n","                        \"missing_facts_check\": [\"N/A - error state\"],\n","                        \"hallucination_check\": [\"N/A - error state\"],\n","                        \"privilege_confidentiality_check\": [\"N/A - error state\"],\n","                        \"tone_check\": [\"N/A - error state\"]\n","                    },\n","                    \"handoff_notes\": {\n","                        \"next_agent\": \"Human lawyer\",\n","                        \"what_to_do_next\": [\"Review error\", \"Check API status\"],\n","                        \"stop_conditions\": [\"API error\"]\n","                    },\n","                    \"risks\": [\n","                        {\n","                            \"type\": \"other\",\n","                            \"severity\": \"high\",\n","                            \"note\": f\"API_ERROR: {str(e)[:100]}\"\n","                        }\n","                    ],\n","                    \"verification_status\": \"Not verified\",\n","                    \"questions_to_verify\": [\"All output invalid due to error\"],\n","                    \"_meta\": {\n","                        \"case_id\": case_id,\n","                        \"step_name\": step_name,\n","                        \"attempt\": attempt + 1,\n","                        \"error\": True\n","                    }\n","                }\n","                return error_result\n","\n","# SMOKE TEST\n","print(\"üß™ Running prefill smoke test...\\n\")\n","\n","test_result = call_claude_json_prefill(\n","    task_description=\"Test: Generate a simple legal memo outline\",\n","    facts_list=[\"Test fact 1: Client needs contract review\", \"Test fact 2: California law applies\"],\n","    deliverable_type=\"outline\",\n","    word_limit=100,\n","    case_id=\"smoke_test\",\n","    step_name=\"validation\"\n",")\n","\n","if test_result and \"task\" in test_result and \"_meta\" in test_result:\n","    if test_result[\"_meta\"].get(\"error\"):\n","        print(\"‚ùå SMOKE TEST FAILED - Error in response\")\n","        print(f\"Error: {test_result['risks'][0]['note']}\")\n","    else:\n","        print(\"‚úÖ SMOKE TEST PASSED\")\n","        print(f\"   - Valid JSON returned on attempt {test_result['_meta']['attempt']}\")\n","        print(f\"   - Schema validation: PASS\")\n","        print(f\"   - Prefill wrapper: READY\")\n","else:\n","    print(\"‚ùå SMOKE TEST FAILED - Invalid structure\")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"‚úÖ call_claude_json_prefill() ready for use\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U1f7KbSqdxyM","executionInfo":{"status":"ok","timestamp":1767823092122,"user_tz":360,"elapsed":26429,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"20bc410e-90e3-4e21-98ab-fabf6999352f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["üß™ Running prefill smoke test...\n","\n","‚úÖ SMOKE TEST PASSED\n","   - Valid JSON returned on attempt 1\n","   - Schema validation: PASS\n","   - Prefill wrapper: READY\n","\n","============================================================\n","‚úÖ call_claude_json_prefill() ready for use\n"]}]},{"cell_type":"markdown","source":["##7.ORCHESTRATOR AND AGENT DEFINITIONS"],"metadata":{"id":"8I3DXj5ed4l5"}},{"cell_type":"markdown","source":["###7.1.OVERVIEW"],"metadata":{"id":"JQnmyn5od59K"}},{"cell_type":"markdown","source":["**Section 7: Building the Agent Team and Defining Cases**\n","\n","**What This Section Does**\n","\n","This section creates the specialized agent functions that will work together to handle complex legal tasks, and it defines four realistic mini-cases that will test the system. Think of this as assembling your legal team where each member has a specific expertise, then briefing them on the cases they'll handle. Nothing executes yet; this section is pure setup and planning.\n","\n","**Understanding Agent Functions: Specialized Roles**\n","\n","Each agent function represents a distinct phase of legal work. The orchestrator plans the overall workflow strategy. The intake agent identifies missing information and formulates follow-up questions. The issue spotter analyzes legal problems and potential claims. The drafting agent creates the primary work product. The quality assurance agent reviews for completeness and accuracy. The red team agent deliberately looks for weaknesses and counterarguments. Finally, the final assembly agent integrates everything into a polished deliverable. Each function calls the Claude wrapper from Section 6 but with different task descriptions and expectations.\n","\n","**Why Specialization Matters**\n","\n","Breaking complex legal work into specialized steps serves multiple purposes. First, it prevents cognitive overload. Asking Claude to simultaneously draft, quality check, and red team in one step produces inferior results compared to doing each separately. Second, it creates natural checkpoints where human lawyers can review and approve before proceeding. Third, it generates a detailed audit trail showing exactly which step produced which output. Fourth, if one step fails, you know precisely where the problem occurred rather than having to debug a monolithic process.\n","\n","**The Four Mini-Cases: Testing Across Domains**\n","\n","The section defines four cases spanning different legal domains to prove the workflow handles diverse situations. The criminal case involves bail and early defense strategy. The regulatory case deals with federal agency rulemaking and comment procedures. The international case addresses cross-border commercial disputes with choice of law complications. The teaching case tackles academic policy development. Each case includes concrete facts, specified deliverable types, and a complete workflow plan listing all seven steps that will execute.\n","\n","**Simplified Prompts: Learning from Past Failures**\n","\n","Notice what's not in this section: lengthy instructions about JSON field requirements. Earlier versions failed because they included detailed schema instructions in every prompt, which confused Claude and triggered conversational explanation mode. Now the system prompt in Section 6 handles schema enforcement, while these case definitions stay minimal. Each case just provides facts, specifies a word limit, and states the desired deliverable type. This simplicity is deliberate and critical to reliability."],"metadata":{"id":"MijlFuqghg15"}},{"cell_type":"markdown","source":["###7.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"hKHExNFEd8Yl"}},{"cell_type":"code","source":["# Cell 7: Orchestrator and Agent Definitions + Mini-Cases (CRITICAL)\n","\n","# --- AGENT STEP FUNCTIONS ---\n","\n","def orchestrator_plan(case_facts, case_id):\n","    \"\"\"Generate a workflow plan for the case.\"\"\"\n","    return call_claude_json_prefill(\n","        task_description=\"Orchestrator: Create a step-by-step workflow plan for this legal matter\",\n","        facts_list=case_facts,\n","        deliverable_type=\"plan\",\n","        word_limit=300,\n","        case_id=case_id,\n","        step_name=\"orchestrator_plan\"\n","    )\n","\n","def intake_agent(case_facts, case_id):\n","    \"\"\"Initial intake and information gathering.\"\"\"\n","    return call_claude_json_prefill(\n","        task_description=\"Intake Agent: Identify missing information and formulate questions for client\",\n","        facts_list=case_facts,\n","        deliverable_type=\"checklist\",\n","        word_limit=250,\n","        case_id=case_id,\n","        step_name=\"intake\"\n","    )\n","\n","def issue_spotter(case_facts, case_id):\n","    \"\"\"Identify legal issues and potential claims/defenses.\"\"\"\n","    return call_claude_json_prefill(\n","        task_description=\"Issue Spotter: Identify all legal issues, potential claims, and defenses\",\n","        facts_list=case_facts,\n","        deliverable_type=\"memo\",\n","        word_limit=350,\n","        case_id=case_id,\n","        step_name=\"issue_spotter\"\n","    )\n","\n","def drafting_agent(case_facts, deliverable_type, case_id):\n","    \"\"\"Draft primary work product.\"\"\"\n","    return call_claude_json_prefill(\n","        task_description=f\"Drafting Agent: Create a {deliverable_type} based on the provided facts\",\n","        facts_list=case_facts,\n","        deliverable_type=deliverable_type,\n","        word_limit=400,\n","        case_id=case_id,\n","        step_name=\"drafting\"\n","    )\n","\n","def qa_agent(case_facts, draft_content, case_id):\n","    \"\"\"Quality assurance review.\"\"\"\n","    qa_facts = case_facts + [f\"Draft to review: {draft_content[:200]}...\"]\n","    return call_claude_json_prefill(\n","        task_description=\"QA Agent: Review draft for completeness, accuracy, and quality issues\",\n","        facts_list=qa_facts,\n","        deliverable_type=\"checklist\",\n","        word_limit=300,\n","        case_id=case_id,\n","        step_name=\"qa\"\n","    )\n","\n","def redteam_agent(case_facts, draft_content, case_id):\n","    \"\"\"Red team adversarial review.\"\"\"\n","    redteam_facts = case_facts + [f\"Draft to challenge: {draft_content[:200]}...\"]\n","    return call_claude_json_prefill(\n","        task_description=\"Red Team Agent: Identify weaknesses, gaps, and potential counterarguments\",\n","        facts_list=redteam_facts,\n","        deliverable_type=\"memo\",\n","        word_limit=300,\n","        case_id=case_id,\n","        step_name=\"redteam\"\n","    )\n","\n","def final_assembly(case_facts, all_outputs, case_id):\n","    \"\"\"Assemble final deliverable incorporating all feedback.\"\"\"\n","    assembly_facts = case_facts + [\n","        f\"Outputs to integrate: {len(all_outputs)} prior steps completed\"\n","    ]\n","    return call_claude_json_prefill(\n","        task_description=\"Final Assembly: Create polished final deliverable incorporating all prior work\",\n","        facts_list=assembly_facts,\n","        deliverable_type=\"memo\",\n","        word_limit=450,\n","        case_id=case_id,\n","        step_name=\"final_assembly\"\n","    )\n","\n","\n","# --- MINI-CASE DEFINITIONS ---\n","\n","MINI_CASES = [\n","    {\n","        \"case_id\": \"criminal_001\",\n","        \"domain\": \"Criminal Defense\",\n","        \"facts\": [\n","            \"Client arrested on state drug possession charges (California)\",\n","            \"First offense, no prior criminal record\",\n","            \"Arrested during traffic stop without warrant\",\n","            \"Client has stable employment and family ties in community\",\n","            \"Bail hearing scheduled in 48 hours\"\n","        ],\n","        \"deliverable_type\": \"memo\",\n","        \"workflow_steps\": [\"orchestrator_plan\", \"intake\", \"issue_spotter\", \"drafting\", \"qa\", \"redteam\", \"final_assembly\"]\n","    },\n","    {\n","        \"case_id\": \"regulatory_001\",\n","        \"domain\": \"Regulatory/Administrative\",\n","        \"facts\": [\n","            \"Federal agency issued NPRM affecting client's financial services business\",\n","            \"Comment period ends in 30 days\",\n","            \"Proposed rule changes capital requirements and reporting obligations\",\n","            \"Client operates in multiple states\",\n","            \"Potential compliance costs estimated at $2M annually\"\n","        ],\n","        \"deliverable_type\": \"memo\",\n","        \"workflow_steps\": [\"orchestrator_plan\", \"intake\", \"issue_spotter\", \"drafting\", \"qa\", \"redteam\", \"final_assembly\"]\n","    },\n","    {\n","        \"case_id\": \"international_001\",\n","        \"domain\": \"International Commercial\",\n","        \"facts\": [\n","            \"Contract dispute between US company (Delaware) and UK supplier\",\n","            \"Contract silent on choice of law and forum\",\n","            \"Breach relates to delivery delays and quality issues\",\n","            \"Contract value: $5M over 3 years\",\n","            \"Both parties interested in preserving business relationship if possible\"\n","        ],\n","        \"deliverable_type\": \"memo\",\n","        \"workflow_steps\": [\"orchestrator_plan\", \"intake\", \"issue_spotter\", \"drafting\", \"qa\", \"redteam\", \"final_assembly\"]\n","    },\n","    {\n","        \"case_id\": \"teaching_001\",\n","        \"domain\": \"Teaching/Academic\",\n","        \"facts\": [\n","            \"Law school considering AI policy for student submissions\",\n","            \"Concerns about plagiarism, academic integrity, and skill development\",\n","            \"Need to balance innovation with educational objectives\",\n","            \"ABA accreditation requirements must be met\",\n","            \"Policy should cover exams, papers, and legal writing assignments\"\n","        ],\n","        \"deliverable_type\": \"outline\",\n","        \"workflow_steps\": [\"orchestrator_plan\", \"intake\", \"issue_spotter\", \"drafting\", \"qa\", \"redteam\", \"final_assembly\"]\n","    }\n","]\n","\n","print(\"‚úÖ Agent functions defined:\")\n","print(\"   - orchestrator_plan()\")\n","print(\"   - intake_agent()\")\n","print(\"   - issue_spotter()\")\n","print(\"   - drafting_agent()\")\n","print(\"   - qa_agent()\")\n","print(\"   - redteam_agent()\")\n","print(\"   - final_assembly()\")\n","\n","print(f\"\\n‚úÖ {len(MINI_CASES)} mini-cases loaded:\")\n","for case in MINI_CASES:\n","    print(f\"   - {case['case_id']}: {case['domain']} ({len(case['workflow_steps'])} steps)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FD2KloIZd-RO","executionInfo":{"status":"ok","timestamp":1767823156008,"user_tz":360,"elapsed":64,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"0a2ec188-e499-4abd-e0b2-0180c11c1b6a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Agent functions defined:\n","   - orchestrator_plan()\n","   - intake_agent()\n","   - issue_spotter()\n","   - drafting_agent()\n","   - qa_agent()\n","   - redteam_agent()\n","   - final_assembly()\n","\n","‚úÖ 4 mini-cases loaded:\n","   - criminal_001: Criminal Defense (7 steps)\n","   - regulatory_001: Regulatory/Administrative (7 steps)\n","   - international_001: International Commercial (7 steps)\n","   - teaching_001: Teaching/Academic (7 steps)\n"]}]},{"cell_type":"markdown","source":["##8.EXECUTION"],"metadata":{"id":"3iAgva9leLFu"}},{"cell_type":"markdown","source":["###8.1.OVERVIEW"],"metadata":{"id":"GXa_oOS0eNZo"}},{"cell_type":"markdown","source":["**Section 8: Executing the Complete Workflow**\n","\n","**What This Section Does**\n","\n","This is where everything comes together and actually runs. Section 8 takes the four mini-cases defined earlier and executes the complete seven-step workflow for each one, tracking progress, handling errors, logging risks, saving outputs, and generating a comprehensive summary. This is the engine room of the entire notebook where theory becomes practice and you see the multi-step agent system in action.\n","\n","**Progressive Execution with Visual Feedback**\n","\n","The section processes cases sequentially, showing you exactly where it is at every moment. You see \"Case 1 of 4\" then within that case \"Step 2 of 7\" so you always know progress. Each step prints a status indicator: a green checkmark for success or a red X for failure with a brief error message. This real-time feedback is crucial because the full execution might take several minutes, and you need to know the system is working rather than frozen.\n","\n","**Error Handling: Continuing Despite Problems**\n","\n","The section wraps every case and every step in error protection. If the issue spotter fails for the criminal case, the workflow notes the failure but continues to the drafting step. This resilience ensures you get as much output as possible rather than one early failure killing the entire run. Each error gets logged with context about which case and step failed. By the end, you have a complete picture of what succeeded, what failed, and where problems occurred.\n","\n","**Human Approval Gates: Simulated Checkpoints**\n","\n","Real multi-step workflows need human oversight at critical transition points. After the orchestrator creates a plan, a lawyer should review and approve it before work begins. After quality assurance identifies issues, someone should decide whether to proceed or stop. This section simulates those approval gates using boolean variables set to true. In production use, these would be actual prompts asking the lawyer to review and approve. The simulation demonstrates where these checkpoints belong and why they matter for responsible AI use.\n","\n","**Comprehensive Output Generation**\n","\n","For each step in each case, the section saves two files: a complete JSON file with all structured data including quality checks and risk flags, and a plain text file containing just the work product content. After all steps complete, it creates consolidated bundle files that integrate everything. This gives you both granular per-step outputs for detailed review and integrated final deliverables for practical use.\n","\n","**The Statistics Dashboard: Quantifying Performance**\n","\n","As execution proceeds, the section tracks cases attempted versus successful, steps attempted versus successful, total API calls made, and total risks logged. At the end, it displays a formatted table showing each case with a status icon, steps completed, and highest risk severity. This dashboard gives you immediate insight into system performance and helps identify patterns like whether certain types of cases or steps fail more frequently."],"metadata":{"id":"wZzq6X3zhyLr"}},{"cell_type":"markdown","source":["###8.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"PXOHXhO_ePOV"}},{"cell_type":"code","source":["# Cell 8: Execute Multi-Step Workflows for All Cases\n","\n","import time\n","\n","# Statistics\n","stats = {\n","    \"cases_attempted\": 0,\n","    \"cases_success\": 0,\n","    \"cases_failed\": 0,\n","    \"steps_attempted\": 0,\n","    \"steps_success\": 0,\n","    \"steps_failed\": 0,\n","    \"api_calls\": 0,\n","    \"total_risks_logged\": 0\n","}\n","\n","case_results = []\n","\n","print(\"üöÄ Starting multi-step workflow execution for all cases\\n\")\n","print(\"=\"*70)\n","\n","for case_idx, case in enumerate(MINI_CASES, 1):\n","    case_id = case[\"case_id\"]\n","    domain = case[\"domain\"]\n","    facts = case[\"facts\"]\n","    deliverable_type = case[\"deliverable_type\"]\n","    steps = case[\"workflow_steps\"]\n","\n","    print(f\"\\n[Case {case_idx}/{len(MINI_CASES)}] {case_id} - {domain}\")\n","    print(\"-\" * 70)\n","\n","    stats[\"cases_attempted\"] += 1\n","\n","    # Create case deliverables directory\n","    case_dir = DELIVERABLES_DIR / case_id\n","    case_dir.mkdir(exist_ok=True)\n","\n","    case_status = \"success\"\n","    steps_completed = 0\n","    all_outputs = {}\n","    highest_risk_severity = \"low\"\n","\n","    try:\n","        # Save case facts\n","        with open(case_dir / \"case_facts.json\", 'w') as f:\n","            json.dump({\"case_id\": case_id, \"domain\": domain, \"facts\": facts}, f, indent=2)\n","\n","        # Execute workflow steps\n","        for step_idx, step_name in enumerate(steps, 1):\n","            print(f\"  [Step {step_idx}/{len(steps)}] {step_name}...\", end=\" \")\n","            stats[\"steps_attempted\"] += 1\n","            stats[\"api_calls\"] += 1\n","\n","            try:\n","                # Execute appropriate agent function\n","                if step_name == \"orchestrator_plan\":\n","                    result = orchestrator_plan(facts, case_id)\n","                elif step_name == \"intake\":\n","                    result = intake_agent(facts, case_id)\n","                elif step_name == \"issue_spotter\":\n","                    result = issue_spotter(facts, case_id)\n","                elif step_name == \"drafting\":\n","                    result = drafting_agent(facts, deliverable_type, case_id)\n","                elif step_name == \"qa\":\n","                    draft_content = all_outputs.get(\"drafting\", {}).get(\"work_product\", {}).get(\"content\", \"No draft available\")\n","                    result = qa_agent(facts, draft_content, case_id)\n","                elif step_name == \"redteam\":\n","                    draft_content = all_outputs.get(\"drafting\", {}).get(\"work_product\", {}).get(\"content\", \"No draft available\")\n","                    result = redteam_agent(facts, draft_content, case_id)\n","                elif step_name == \"final_assembly\":\n","                    result = final_assembly(facts, all_outputs, case_id)\n","                else:\n","                    result = None\n","\n","                if result:\n","                    all_outputs[step_name] = result\n","                    steps_completed += 1\n","                    stats[\"steps_success\"] += 1\n","\n","                    # Save step output\n","                    with open(case_dir / f\"{step_name}_output.json\", 'w') as f:\n","                        json.dump(result, f, indent=2)\n","\n","                    # Save work product as text\n","                    if \"work_product\" in result and \"content\" in result[\"work_product\"]:\n","                        with open(case_dir / f\"{step_name}_draft.txt\", 'w') as f:\n","                            f.write(result[\"work_product\"][\"content\"])\n","\n","                    # Track highest risk severity\n","                    for risk in result.get(\"risks\", []):\n","                        stats[\"total_risks_logged\"] += 1\n","                        if risk[\"severity\"] == \"high\":\n","                            highest_risk_severity = \"high\"\n","                        elif risk[\"severity\"] == \"medium\" and highest_risk_severity != \"high\":\n","                            highest_risk_severity = \"medium\"\n","\n","                    print(\"‚úÖ\")\n","\n","                    # Simulate human approval gates\n","                    if step_name == \"orchestrator_plan\":\n","                        APPROVE_PLAN = True  # Simulated approval\n","                        if not APPROVE_PLAN:\n","                            print(\"    ‚õî Plan approval gate: REJECTED\")\n","                            case_status = \"failed\"\n","                            break\n","\n","                    if step_name == \"qa\":\n","                        APPROVE_CONTINUE = True  # Simulated approval\n","                        if not APPROVE_CONTINUE:\n","                            print(\"    ‚õî QA approval gate: REJECTED\")\n","                            case_status = \"failed\"\n","                            break\n","\n","                else:\n","                    print(\"‚ùå (no result)\")\n","                    stats[\"steps_failed\"] += 1\n","\n","            except Exception as e:\n","                print(f\"‚ùå Error: {str(e)[:50]}\")\n","                stats[\"steps_failed\"] += 1\n","                # Continue to next step\n","\n","        # Create final bundle\n","        if all_outputs:\n","            final_bundle = {\n","                \"case_id\": case_id,\n","                \"domain\": domain,\n","                \"facts\": facts,\n","                \"steps_completed\": steps_completed,\n","                \"total_steps\": len(steps),\n","                \"outputs\": all_outputs,\n","                \"highest_risk_severity\": highest_risk_severity,\n","                \"timestamp\": datetime.now().isoformat()\n","            }\n","\n","            with open(case_dir / \"final_bundle.json\", 'w') as f:\n","                json.dump(final_bundle, f, indent=2)\n","\n","            # Create consolidated text output\n","            with open(case_dir / \"final_bundle.txt\", 'w') as f:\n","                f.write(f\"CASE: {case_id} - {domain}\\n\")\n","                f.write(\"=\"*70 + \"\\n\\n\")\n","                f.write(\"FACTS:\\n\")\n","                for fact in facts:\n","                    f.write(f\"  - {fact}\\n\")\n","                f.write(\"\\n\" + \"=\"*70 + \"\\n\\n\")\n","\n","                for step_name, output in all_outputs.items():\n","                    f.write(f\"STEP: {step_name.upper()}\\n\")\n","                    f.write(\"-\"*70 + \"\\n\")\n","                    if \"work_product\" in output and \"content\" in output[\"work_product\"]:\n","                        f.write(output[\"work_product\"][\"content\"])\n","                    f.write(\"\\n\\n\")\n","\n","            stats[\"cases_success\"] += 1\n","        else:\n","            case_status = \"failed\"\n","            stats[\"cases_failed\"] += 1\n","\n","        case_results.append({\n","            \"case_id\": case_id,\n","            \"domain\": domain,\n","            \"status\": case_status,\n","            \"steps_completed\": steps_completed,\n","            \"total_steps\": len(steps),\n","            \"highest_risk\": highest_risk_severity\n","        })\n","\n","    except Exception as e:\n","        print(f\"  ‚ùå Case-level error: {str(e)[:100]}\")\n","        stats[\"cases_failed\"] += 1\n","        case_results.append({\n","            \"case_id\": case_id,\n","            \"domain\": domain,\n","            \"status\": \"failed\",\n","            \"steps_completed\": steps_completed,\n","            \"total_steps\": len(steps),\n","            \"highest_risk\": \"high\"\n","        })\n","\n","# Print summary\n","print(\"\\n\" + \"=\"*70)\n","print(\"üìä EXECUTION SUMMARY\")\n","print(\"=\"*70)\n","\n","print(f\"\\nCases: {stats['cases_success']}/{stats['cases_attempted']} successful\")\n","print(f\"Steps: {stats['steps_success']}/{stats['steps_attempted']} successful\")\n","print(f\"API Calls: {stats['api_calls']}\")\n","print(f\"Total Risks Logged: {stats['total_risks_logged']}\")\n","\n","print(\"\\n\" + \"-\"*70)\n","print(f\"{'Case ID':<18} {'Domain':<25} {'Status':<8} {'Steps':<12} {'Risk':<8}\")\n","print(\"-\"*70)\n","\n","for result in case_results:\n","    status_icon = \"‚úÖ\" if result[\"status\"] == \"success\" else \"‚ùå\"\n","    steps_text = f\"{result['steps_completed']}/{result['total_steps']}\"\n","    print(f\"{result['case_id']:<18} {result['domain']:<25} {status_icon:<8} {steps_text:<12} {result['highest_risk']:<8}\")\n","\n","print(\"\\n‚úÖ All deliverables saved to:\", DELIVERABLES_DIR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tvi8NIIfeQ34","executionInfo":{"status":"ok","timestamp":1767824579960,"user_tz":360,"elapsed":571657,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"49899739-10a0-4de6-953b-2c9db5437080"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ Starting multi-step workflow execution for all cases\n","\n","======================================================================\n","\n","[Case 1/4] criminal_001 - Criminal Defense\n","----------------------------------------------------------------------\n","  [Step 1/7] orchestrator_plan... ‚úÖ\n","  [Step 2/7] intake... ‚úÖ\n","  [Step 3/7] issue_spotter... ‚úÖ\n","  [Step 4/7] drafting... ‚úÖ\n","  [Step 5/7] qa... ‚úÖ\n","  [Step 6/7] redteam... ‚úÖ\n","  [Step 7/7] final_assembly... ‚úÖ\n","\n","[Case 2/4] regulatory_001 - Regulatory/Administrative\n","----------------------------------------------------------------------\n","  [Step 1/7] orchestrator_plan... ‚úÖ\n","  [Step 2/7] intake... ‚úÖ\n","  [Step 3/7] issue_spotter... ‚úÖ\n","  [Step 4/7] drafting... ‚úÖ\n","  [Step 5/7] qa... ‚úÖ\n","  [Step 6/7] redteam... ‚úÖ\n","  [Step 7/7] final_assembly... ‚úÖ\n","\n","[Case 3/4] international_001 - International Commercial\n","----------------------------------------------------------------------\n","  [Step 1/7] orchestrator_plan... ‚úÖ\n","  [Step 2/7] intake... ‚úÖ\n","  [Step 3/7] issue_spotter... ‚úÖ\n","  [Step 4/7] drafting... ‚úÖ\n","  [Step 5/7] qa... ‚úÖ\n","  [Step 6/7] redteam... ‚úÖ\n","  [Step 7/7] final_assembly... ‚úÖ\n","\n","[Case 4/4] teaching_001 - Teaching/Academic\n","----------------------------------------------------------------------\n","  [Step 1/7] orchestrator_plan... ‚úÖ\n","  [Step 2/7] intake... ‚úÖ\n","  [Step 3/7] issue_spotter... ‚úÖ\n","  [Step 4/7] drafting... ‚úÖ\n","  [Step 5/7] qa... ‚úÖ\n","  [Step 6/7] redteam... ‚úÖ\n","  [Step 7/7] final_assembly... ‚úÖ\n","\n","======================================================================\n","üìä EXECUTION SUMMARY\n","======================================================================\n","\n","Cases: 4/4 successful\n","Steps: 28/28 successful\n","API Calls: 28\n","Total Risks Logged: 115\n","\n","----------------------------------------------------------------------\n","Case ID            Domain                    Status   Steps        Risk    \n","----------------------------------------------------------------------\n","criminal_001       Criminal Defense          ‚úÖ        7/7          high    \n","regulatory_001     Regulatory/Administrative ‚úÖ        7/7          high    \n","international_001  International Commercial  ‚úÖ        7/7          high    \n","teaching_001       Teaching/Academic         ‚úÖ        7/7          high    \n","\n","‚úÖ All deliverables saved to: /content/ai_law_ch3_runs/run_20260107_215606/deliverables\n"]}]},{"cell_type":"markdown","source":["##9.OWN EXAMPLES"],"metadata":{"id":"0ClsWd16ekP7"}},{"cell_type":"markdown","source":["###9.1.OVERVIEW"],"metadata":{"id":"O7sA9r7tenVn"}},{"cell_type":"markdown","source":["**Section 9: Your Turn to Practice**\n","\n","**What This Section Does**\n","\n","This section shifts from demonstration to practice by letting you input your own hypothetical legal scenario and run it through the same multi-step workflow. It's designed as a safe learning exercise where you can experiment with the system using made-up facts, see how it responds to different types of cases, and understand the workflow from a user perspective rather than just watching preset examples.\n","\n","**Interactive Input with Safety Reminders**\n","\n","The section begins with prominent warnings reminding you not to paste actual sensitive client data. It then prompts you for three pieces of information: a brief description of the legal situation, the relevant jurisdiction, and key facts separated by semicolons. In the demonstration version, these use preset values you can modify, but in live use you would type directly into input boxes. This interactivity makes the learning experience personal and relevant to your practice areas.\n","\n","**Automatic Redaction Before Processing**\n","\n","Before your input goes anywhere near Claude or gets written to files, it passes through the redaction function from Section 5. You see a summary showing which fields were removed by the minimum necessary filter and how many fact items will actually be sent to the API. This demonstrates the privacy protection workflow in action with your own data, reinforcing the principle that you should minimize exposure even with hypothetical scenarios.\n","\n","**Workflow Type Selection: Tailoring the Approach**\n","\n","Different legal domains require different analytical approaches. The section offers five workflow options: criminal defense, regulatory administrative, international commercial, teaching academic, and a custom employment category. Your selection determines which specialist agents emphasize which aspects of analysis. A criminal workflow focuses heavily on procedural rights and immediate client protection, while a regulatory workflow emphasizes compliance timeline and comment strategy. This demonstrates how the same underlying agent architecture adapts to domain-specific needs.\n","\n","**Shortened Four-Step Workflow: Faster Learning**\n","\n","Rather than running all seven steps from the demonstration cases, your exercise uses a condensed four-step version: orchestrator planning, issue spotting, drafting, and final assembly. This provides faster feedback while still demonstrating the core multi-step coordination pattern. You still see the orchestrator create a plan, the system pause for simulated approval, specialists do their work, and the final assembly integrate everything. The shorter sequence makes experimentation more practical during a learning session.\n","\n","**Deliverables in Your Own Folder**\n","\n","All outputs from your exercise save to a separate \"user_case\" folder, keeping your work distinct from the demonstration cases. You get the same quality of output: JSON files with complete structured data and text files with readable work products. This lets you compare your results against the preset examples and see how the system handles your specific fact patterns and jurisdictional context."],"metadata":{"id":"NtvsG80Sh-rZ"}},{"cell_type":"markdown","source":["###9.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"8mQWLjpbeo1e"}},{"cell_type":"code","source":["# Cell 9: User Exercise - Custom Case Workflow\n","\n","print(\"üë§ USER EXERCISE: Run Your Own Case Through the Workflow\")\n","print(\"=\"*70)\n","print(\"\\n‚ö†Ô∏è  IMPORTANT: Do NOT paste actual sensitive client data.\")\n","print(\"Use hypothetical facts for learning purposes only.\\n\")\n","\n","# Simulate user input (in actual use, would use input())\n","# For demo purposes, we'll use preset values that can be modified\n","\n","print(\"Please provide information about your hypothetical case:\\n\")\n","\n","# In live use, uncomment these lines:\n","# user_scenario = input(\"Describe the legal situation (1-2 sentences): \")\n","# user_jurisdiction = input(\"Jurisdiction (e.g., California, New York): \")\n","# user_facts_input = input(\"Key facts (separate with semicolons): \")\n","\n","# Demo values (modify these for testing):\n","user_scenario = \"Client needs help with employment discrimination claim\"\n","user_jurisdiction = \"New York\"\n","user_facts_input = \"Client terminated after pregnancy announcement; worked for company 3 years; no prior disciplinary issues; company has 75 employees; termination occurred 2 weeks after announcement\"\n","\n","print(f\"\\nScenario: {user_scenario}\")\n","print(f\"Jurisdiction: {user_jurisdiction}\")\n","print(f\"Facts: {user_facts_input}\")\n","\n","# Workflow type selection\n","print(\"\\nSelect workflow type:\")\n","print(\"1. Criminal Defense\")\n","print(\"2. Regulatory/Administrative\")\n","print(\"3. International Commercial\")\n","print(\"4. Teaching/Academic\")\n","print(\"5. Employment (custom)\")\n","\n","# For demo: workflow_type = input(\"Enter number (1-5): \")\n","workflow_type = \"5\"  # Employment custom\n","\n","# Process input\n","user_facts_raw = {\n","    \"scenario\": user_scenario,\n","    \"jurisdiction\": user_jurisdiction,\n","    \"raw_facts\": user_facts_input\n","}\n","\n","# Redact\n","redacted_facts, removed_fields = minimum_necessary_intake(user_facts_raw)\n","user_facts_list = [\n","    f\"Jurisdiction: {user_jurisdiction}\",\n","    f\"Situation: {user_scenario}\"\n","] + [f.strip() for f in user_facts_input.split(\";\") if f.strip()]\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üîí REDACTION SUMMARY\")\n","print(\"=\"*70)\n","print(f\"Fields removed: {removed_fields if removed_fields else 'None'}\")\n","print(f\"Facts to be sent: {len(user_facts_list)} items\")\n","\n","# Create user case directory\n","user_case_dir = DELIVERABLES_DIR / \"user_case\"\n","user_case_dir.mkdir(exist_ok=True)\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üöÄ EXECUTING WORKFLOW (Shortened 4-step version)\")\n","print(\"=\"*70)\n","\n","# Shortened workflow for user exercise\n","user_workflow = [\"orchestrator_plan\", \"issue_spotter\", \"drafting\", \"final_assembly\"]\n","\n","user_outputs = {}\n","user_case_id = \"user_exercise\"\n","\n","for step_idx, step_name in enumerate(user_workflow, 1):\n","    print(f\"\\n[Step {step_idx}/{len(user_workflow)}] {step_name}...\", end=\" \")\n","\n","    try:\n","        if step_name == \"orchestrator_plan\":\n","            result = orchestrator_plan(user_facts_list, user_case_id)\n","        elif step_name == \"issue_spotter\":\n","            result = issue_spotter(user_facts_list, user_case_id)\n","        elif step_name == \"drafting\":\n","            result = drafting_agent(user_facts_list, \"memo\", user_case_id)\n","        elif step_name == \"final_assembly\":\n","            result = final_assembly(user_facts_list, user_outputs, user_case_id)\n","        else:\n","            result = None\n","\n","        if result:\n","            user_outputs[step_name] = result\n","\n","            # Save\n","            with open(user_case_dir / f\"{step_name}_output.json\", 'w') as f:\n","                json.dump(result, f, indent=2)\n","\n","            if \"work_product\" in result and \"content\" in result[\"work_product\"]:\n","                with open(user_case_dir / f\"{step_name}_draft.txt\", 'w') as f:\n","                    f.write(result[\"work_product\"][\"content\"])\n","\n","            print(\"‚úÖ\")\n","\n","            # Approval gate simulation\n","            if step_name == \"orchestrator_plan\":\n","                APPROVE_USER_PLAN = True\n","                if not APPROVE_USER_PLAN:\n","                    print(\"    ‚õî Plan rejected. Workflow stopped.\")\n","                    break\n","\n","    except Exception as e:\n","        print(f\"‚ùå Error: {str(e)[:50]}\")\n","\n","# Save user bundle\n","if user_outputs:\n","    user_bundle = {\n","        \"case_id\": user_case_id,\n","        \"scenario\": user_scenario,\n","        \"jurisdiction\": user_jurisdiction,\n","        \"facts\": user_facts_list,\n","        \"outputs\": user_outputs,\n","        \"timestamp\": datetime.now().isoformat()\n","    }\n","\n","    with open(user_case_dir / \"user_bundle.json\", 'w') as f:\n","        json.dump(user_bundle, f, indent=2)\n","\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"‚úÖ USER EXERCISE COMPLETE\")\n","    print(\"=\"*70)\n","    print(f\"Deliverables saved to: {user_case_dir}\")\n","    print(f\"Total outputs: {len(user_outputs)}\")\n","else:\n","    print(\"\\n‚ùå User exercise failed to produce outputs\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vnYbfyHteqoH","executionInfo":{"status":"error","timestamp":1767825272036,"user_tz":360,"elapsed":57331,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"04032bbd-3592-421d-9445-99b64237ed03"},"execution_count":16,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üë§ USER EXERCISE: Run Your Own Case Through the Workflow\n","======================================================================\n","\n","‚ö†Ô∏è  IMPORTANT: Do NOT paste actual sensitive client data.\n","Use hypothetical facts for learning purposes only.\n","\n","Please provide information about your hypothetical case:\n","\n","\n","Scenario: Client needs help with employment discrimination claim\n","Jurisdiction: New York\n","Facts: Client terminated after pregnancy announcement; worked for company 3 years; no prior disciplinary issues; company has 75 employees; termination occurred 2 weeks after announcement\n","\n","Select workflow type:\n","1. Criminal Defense\n","2. Regulatory/Administrative\n","3. International Commercial\n","4. Teaching/Academic\n","5. Employment (custom)\n","\n","======================================================================\n","üîí REDACTION SUMMARY\n","======================================================================\n","Fields removed: ['scenario', 'raw_facts']\n","Facts to be sent: 7 items\n","\n","======================================================================\n","üöÄ EXECUTING WORKFLOW (Shortened 4-step version)\n","======================================================================\n","\n","[Step 1/4] orchestrator_plan... ‚úÖ\n","\n","[Step 2/4] issue_spotter... ‚úÖ\n","\n","[Step 3/4] drafting... "]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2026813734.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0missue_spotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_facts_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_case_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mstep_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"drafting\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrafting_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_facts_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memo\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_case_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mstep_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"final_assembly\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_assembly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_facts_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_case_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2746959024.py\u001b[0m in \u001b[0;36mdrafting_agent\u001b[0;34m(case_facts, deliverable_type, case_id)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdrafting_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase_facts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeliverable_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Draft primary work product.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     return call_claude_json_prefill(\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mtask_description\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Drafting Agent: Create a {deliverable_type} based on the provided facts\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mfacts_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase_facts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3788799705.py\u001b[0m in \u001b[0;36mcall_claude_json_prefill\u001b[0;34m(task_description, facts_list, deliverable_type, word_limit, case_id, step_name)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# PREFILL TECHNIQUE: Add assistant message with \"{\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             response = client.messages.create(\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1800\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/resources/messages/messages.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m             )\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;34m\"/v1/messages\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             body=maybe_transform(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m     def patch(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 response = self._client.send(\n\u001b[0m\u001b[1;32m   1050\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1230\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["##10.ARTIFACTS"],"metadata":{"id":"JZEzaRc1erD3"}},{"cell_type":"markdown","source":["###10.1.OVERVIEW"],"metadata":{"id":"Gr4t0Ix_esnG"}},{"cell_type":"markdown","source":["**Section 10: Packaging Everything for Audit and Archive**\n","\n","**What This Section Does**\n","\n","This final section creates a comprehensive audit package containing every file generated during the workflow execution, writes a detailed human-readable guide explaining what's in the package, compresses everything into a downloadable zip file, and provides a final checklist confirming all governance artifacts exist. This is where raw execution results transform into a professional, archivable audit trail suitable for bar ethics review or firm quality control processes.\n","\n","**The Audit README: Your Guide for Future Review**\n","\n","The section generates a multi-page text document that explains what every file in the package means and how to interpret it. This readme assumes the reader might be reviewing the package months or years later, possibly someone who wasn't involved in the original execution. It explains the purpose of the prompts log, why only hashes are stored instead of full text, what the risk severity levels mean, and how to navigate the deliverables folder structure. It also includes all the critical disclaimers about draft status, verification requirements, and lawyer responsibility.\n","\n","**The Review Methodology: Step-by-Step Instructions**\n","\n","The readme doesn't just describe files; it prescribes a specific review sequence. Start with the manifest to understand run parameters. Then examine the risk log to identify high-severity concerns. Next review the actual work products in the deliverables folder. Check the prompts log to verify proper logging occurred. Finally, work through a risk mitigation checklist that includes verifying citations, checking privilege considerations, and confirming human review happened. This structured approach ensures consistent, thorough audits regardless of who performs them.\n","\n","**File Inventory: Complete Transparency**\n","\n","Before creating the zip file, the section lists every single file in the package with its size in kilobytes. This inventory serves two purposes. First, it gives you immediate visibility into what's being archived. Second, it creates a permanent record of package contents that could prove completeness if challenged later. You can see at a glance that you have outputs for all four cases, that the risk log exists, and that governance files are present.\n","\n","**The ZIP Bundle: Portable Archive**\n","\n","The section compresses the entire run directory into a single zip file with a timestamped filename. This makes the package easy to download from Google Colab to your local machine, attach to emails, store in document management systems, or archive for long-term retention. The compression also makes file transfer faster and storage more efficient. The section reports the final zip file size so you know whether it's small enough to email or needs alternative transfer methods.\n","\n","**Final Checklist: Verification Before Completion**\n","\n","The very last output is a checklist with green checkmarks or red X marks showing whether each required governance artifact exists. This final verification step catches any problems before you rely on the package. If the risk log is missing or the deliverables folder is empty, you know immediately rather than discovering it later when you need to reference the audit trail."],"metadata":{"id":"-8rYz9OViMrr"}},{"cell_type":"markdown","source":["###10.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"fx_RNPUXevB5"}},{"cell_type":"code","source":["# Cell 10: Create Audit Package and Download Bundle\n","\n","import shutil\n","\n","print(\"üì¶ Creating audit package and download bundle\")\n","print(\"=\"*70)\n","\n","# Create AUDIT_README.txt\n","audit_readme_path = RUN_DIR / \"AUDIT_README.txt\"\n","\n","with open(audit_readme_path, 'w') as f:\n","    f.write(\"\"\"\n","================================================================================\n","AI FOR LAWYERS - CHAPTER 3 (LEVEL 3: AGENTS)\n","AUDIT PACKAGE README\n","================================================================================\n","\n","This package contains a complete audit trail for a multi-step agentic workflow\n","execution using Claude (Anthropic) for legal task automation.\n","\n","PACKAGE CONTENTS:\n","================================================================================\n","\n","1. run_manifest.json\n","   - Run metadata (timestamp, model, chapter, author)\n","   - Directory structure information\n","\n","2. prompts_log.jsonl\n","   - Redacted log of all API calls (JSONL format, one entry per line)\n","   - Each entry contains: timestamp, case_id, step_name, prompt_hash,\n","     response_hash, attempt number, success status\n","   - Full prompts/responses NOT stored (only hashes for verification)\n","\n","3. risk_log.json\n","   - Comprehensive list of ALL risks flagged during execution\n","   - Each risk includes: type, severity, note, case_id, step_name, timestamp\n","   - Risk types: confidentiality, privilege, hallucination, missing_facts,\n","     unauthorized_practice, overconfidence, prompt_injection, tone, other\n","\n","4. deliverables/ folder\n","   - One subdirectory per case (e.g., criminal_001/, regulatory_001/)\n","   - Each case directory contains:\n","     * case_facts.json - Original facts provided\n","     * <step_name>_output.json - Full JSON output per workflow step\n","     * <step_name>_draft.txt - Human-readable work product per step\n","     * final_bundle.json - Consolidated outputs from all steps\n","     * final_bundle.txt - Consolidated text document\n","\n","5. pip_freeze.txt\n","   - Python package versions for reproducibility\n","\n","6. AUDIT_README.txt (this file)\n","   - Human-readable guide to package contents\n","\n","================================================================================\n","IMPORTANT DISCLAIMERS\n","================================================================================\n","\n","‚ö†Ô∏è  ALL OUTPUTS ARE DRAFTS ONLY\n","- Every work product requires lawyer review\n","- No attorney-client relationship created\n","- Not legal advice to you or anyone\n","- Verification status: \"Not verified\" on all outputs\n","\n","‚ö†Ô∏è  CONFIDENTIALITY & PRIVILEGE\n","- Redaction applied (imperfect - best effort only)\n","- Do not rely on redaction for sensitive data\n","- Consider privilege implications before using AI\n","\n","‚ö†Ô∏è  MODEL LIMITATIONS\n","- May hallucinate facts, citations, or authorities\n","- All legal references marked \"Not verified\"\n","- Human lawyer MUST verify all substantive content\n","\n","‚ö†Ô∏è  WORKFLOW RESPONSIBILITY\n","- \"Agent\" = workflow pattern, NOT autonomous AI\n","- Lawyer remains responsible for all decisions\n","- Human approval gates simulated in demo\n","\n","================================================================================\n","HOW TO REVIEW THIS PACKAGE\n","================================================================================\n","\n","1. START WITH: run_manifest.json\n","   - Understand run parameters and timestamp\n","\n","2. REVIEW RISKS: risk_log.json\n","   - Check for high-severity risks\n","   - Understand risk distribution across cases/steps\n","\n","3. EXAMINE OUTPUTS: deliverables/<case_id>/\n","   - Review final_bundle.txt for each case\n","   - Check per-step outputs for quality and consistency\n","   - Verify all disclaimers present\n","\n","4. AUDIT TRAIL: prompts_log.jsonl\n","   - Verify all API calls logged\n","   - Check success rates and retry patterns\n","   - Confirm redaction applied (only hashes stored)\n","\n","5. RISK MITIGATION CHECKLIST:\n","   [ ] All high-severity risks addressed\n","   [ ] Legal citations independently verified\n","   [ ] Confidential information properly handled\n","   [ ] Privilege considerations documented\n","   [ ] Human lawyer review completed\n","   [ ] Disclaimers present in all outputs\n","   [ ] Jurisdiction-specific rules checked\n","\n","================================================================================\n","TECHNICAL DETAILS\n","================================================================================\n","\n","Platform: Google Colab\n","SDK: anthropic (Python)\n","Model: claude-sonnet-4-5-20250929\n","Chapter: 3 (Level 3: Agents)\n","Author: Alejandro Reynoso, Chief Scientist DEFI CAPITAL RESEARCH\n","        External Lecturer, Judge Business School Cambridge\n","\n","Workflow Pattern: Orchestrator + Specialist Agents\n","- Orchestrator: Plans workflow steps\n","- Specialists: Intake, Issue Spotter, Drafting, QA, Red Team, Final Assembly\n","- Human Gates: Approval checkpoints between major phases\n","\n","JSON Schema: Strict enforcement via prefill technique\n","- All outputs match predefined schema\n","- verification_status: \"Not verified\" (mandatory)\n","- Quality checks included in every output\n","- Handoff notes for multi-step coordination\n","\n","================================================================================\n","CONTACT & FEEDBACK\n","================================================================================\n","\n","For questions about this educational tool:\n","- Review course materials for Chapter 3\n","- Consult with legal tech specialists at your firm\n","- Consider ethics opinions in your jurisdiction\n","\n","This is educational software for demonstration purposes.\n","Production use requires additional controls, testing, and legal review.\n","\n","================================================================================\n","END OF AUDIT README\n","================================================================================\n","\"\"\")\n","\n","print(f\"‚úÖ Created: {audit_readme_path}\")\n","\n","# List all files in package\n","print(\"\\nüìã PACKAGE CONTENTS:\")\n","print(\"-\" * 70)\n","\n","all_files = list(RUN_DIR.rglob(\"*\"))\n","for fpath in sorted(all_files):\n","    if fpath.is_file():\n","        rel_path = fpath.relative_to(RUN_DIR)\n","        size_kb = fpath.stat().st_size / 1024\n","        print(f\"  {rel_path} ({size_kb:.1f} KB)\")\n","\n","print(f\"\\nTotal files: {len([f for f in all_files if f.is_file()])}\")\n","\n","# Create ZIP bundle\n","zip_path = Path(f\"/content/ai_law_ch3_bundle_{timestamp}.zip\")\n","print(f\"\\nüì¶ Creating ZIP bundle: {zip_path.name}\")\n","\n","shutil.make_archive(\n","    str(zip_path.with_suffix('')),\n","    'zip',\n","    RUN_DIR\n",")\n","\n","zip_size_mb = zip_path.stat().st_size / (1024 * 1024)\n","\n","print(f\"‚úÖ ZIP bundle created: {zip_path}\")\n","print(f\"   Size: {zip_size_mb:.2f} MB\")\n","\n","# Final checklist\n","print(\"\\n\" + \"=\"*70)\n","print(\"‚úÖ FINAL PACKAGE CHECKLIST\")\n","print(\"=\"*70)\n","\n","checklist = [\n","    (\"run_manifest.json\", (RUN_DIR / \"run_manifest.json\").exists()),\n","    (\"prompts_log.jsonl\", (RUN_DIR / \"prompts_log.jsonl\").exists()),\n","    (\"risk_log.json\", (RUN_DIR / \"risk_log.json\").exists()),\n","    (\"AUDIT_README.txt\", (RUN_DIR / \"AUDIT_README.txt\").exists()),\n","    (\"pip_freeze.txt\", (RUN_DIR / \"pip_freeze.txt\").exists()),\n","    (\"deliverables/ folder\", (RUN_DIR / \"deliverables\").exists()),\n","    (\"ZIP bundle\", zip_path.exists())\n","]\n","\n","for item, exists in checklist:\n","    status = \"‚úÖ\" if exists else \"‚ùå\"\n","    print(f\"{status} {item}\")\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üéâ CHAPTER 3 WORKFLOW COMPLETE\")\n","print(\"=\"*70)\n","print(f\"\\nüìÇ Run directory: {RUN_DIR}\")\n","print(f\"üì¶ Download bundle: {zip_path}\")\n","print(\"\\n‚ö†Ô∏è  Remember: All outputs require lawyer review. Not legal advice.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcNDXpA7exRE","executionInfo":{"status":"ok","timestamp":1767825298858,"user_tz":360,"elapsed":41,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"76dc0fa8-a935-4474-e408-fa4aa566d846"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ Creating audit package and download bundle\n","======================================================================\n","‚úÖ Created: /content/ai_law_ch3_runs/run_20260107_215606/AUDIT_README.txt\n","\n","üìã PACKAGE CONTENTS:\n","----------------------------------------------------------------------\n","  AUDIT_README.txt (5.2 KB)\n","  deliverables/criminal_001/case_facts.json (0.3 KB)\n","  deliverables/criminal_001/drafting_draft.txt (0.2 KB)\n","  deliverables/criminal_001/drafting_output.json (1.6 KB)\n","  deliverables/criminal_001/final_assembly_draft.txt (2.5 KB)\n","  deliverables/criminal_001/final_assembly_output.json (7.6 KB)\n","  deliverables/criminal_001/final_bundle.json (44.3 KB)\n","  deliverables/criminal_001/final_bundle.txt (11.2 KB)\n","  deliverables/criminal_001/intake_draft.txt (1.3 KB)\n","  deliverables/criminal_001/intake_output.json (6.5 KB)\n","  deliverables/criminal_001/issue_spotter_draft.txt (1.8 KB)\n","  deliverables/criminal_001/issue_spotter_output.json (7.0 KB)\n","  deliverables/criminal_001/orchestrator_plan_draft.txt (1.5 KB)\n","  deliverables/criminal_001/orchestrator_plan_output.json (6.0 KB)\n","  deliverables/criminal_001/qa_draft.txt (1.2 KB)\n","  deliverables/criminal_001/qa_output.json (5.4 KB)\n","  deliverables/criminal_001/redteam_draft.txt (1.7 KB)\n","  deliverables/criminal_001/redteam_output.json (6.6 KB)\n","  deliverables/international_001/case_facts.json (0.4 KB)\n","  deliverables/international_001/drafting_draft.txt (0.2 KB)\n","  deliverables/international_001/drafting_output.json (1.6 KB)\n","  deliverables/international_001/final_assembly_draft.txt (2.6 KB)\n","  deliverables/international_001/final_assembly_output.json (7.6 KB)\n","  deliverables/international_001/final_bundle.json (44.1 KB)\n","  deliverables/international_001/final_bundle.txt (11.4 KB)\n","  deliverables/international_001/intake_draft.txt (1.2 KB)\n","  deliverables/international_001/intake_output.json (6.3 KB)\n","  deliverables/international_001/issue_spotter_draft.txt (1.9 KB)\n","  deliverables/international_001/issue_spotter_output.json (7.4 KB)\n","  deliverables/international_001/orchestrator_plan_draft.txt (1.6 KB)\n","  deliverables/international_001/orchestrator_plan_output.json (5.8 KB)\n","  deliverables/international_001/qa_draft.txt (1.2 KB)\n","  deliverables/international_001/qa_output.json (5.1 KB)\n","  deliverables/international_001/redteam_draft.txt (1.7 KB)\n","  deliverables/international_001/redteam_output.json (6.7 KB)\n","  deliverables/regulatory_001/case_facts.json (0.4 KB)\n","  deliverables/regulatory_001/drafting_draft.txt (2.1 KB)\n","  deliverables/regulatory_001/drafting_output.json (7.4 KB)\n","  deliverables/regulatory_001/final_assembly_draft.txt (0.2 KB)\n","  deliverables/regulatory_001/final_assembly_output.json (1.7 KB)\n","  deliverables/regulatory_001/final_bundle.json (47.3 KB)\n","  deliverables/regulatory_001/final_bundle.txt (11.1 KB)\n","  deliverables/regulatory_001/intake_draft.txt (1.3 KB)\n","  deliverables/regulatory_001/intake_output.json (6.8 KB)\n","  deliverables/regulatory_001/issue_spotter_draft.txt (1.8 KB)\n","  deliverables/regulatory_001/issue_spotter_output.json (6.6 KB)\n","  deliverables/regulatory_001/orchestrator_plan_draft.txt (1.6 KB)\n","  deliverables/regulatory_001/orchestrator_plan_output.json (6.6 KB)\n","  deliverables/regulatory_001/qa_draft.txt (1.5 KB)\n","  deliverables/regulatory_001/qa_output.json (6.9 KB)\n","  deliverables/regulatory_001/redteam_draft.txt (1.6 KB)\n","  deliverables/regulatory_001/redteam_output.json (7.5 KB)\n","  deliverables/teaching_001/case_facts.json (0.4 KB)\n","  deliverables/teaching_001/drafting_draft.txt (2.0 KB)\n","  deliverables/teaching_001/drafting_output.json (7.5 KB)\n","  deliverables/teaching_001/final_assembly_draft.txt (2.4 KB)\n","  deliverables/teaching_001/final_assembly_output.json (7.8 KB)\n","  deliverables/teaching_001/final_bundle.json (50.3 KB)\n","  deliverables/teaching_001/final_bundle.txt (13.3 KB)\n","  deliverables/teaching_001/intake_draft.txt (1.4 KB)\n","  deliverables/teaching_001/intake_output.json (6.5 KB)\n","  deliverables/teaching_001/issue_spotter_draft.txt (1.9 KB)\n","  deliverables/teaching_001/issue_spotter_output.json (6.5 KB)\n","  deliverables/teaching_001/orchestrator_plan_draft.txt (1.5 KB)\n","  deliverables/teaching_001/orchestrator_plan_output.json (6.2 KB)\n","  deliverables/teaching_001/qa_draft.txt (1.4 KB)\n","  deliverables/teaching_001/qa_output.json (6.0 KB)\n","  deliverables/teaching_001/redteam_draft.txt (1.8 KB)\n","  deliverables/teaching_001/redteam_output.json (6.2 KB)\n","  deliverables/user_case/issue_spotter_draft.txt (1.9 KB)\n","  deliverables/user_case/issue_spotter_output.json (7.2 KB)\n","  deliverables/user_case/orchestrator_plan_draft.txt (1.7 KB)\n","  deliverables/user_case/orchestrator_plan_output.json (6.9 KB)\n","  pip_freeze.txt (12.4 KB)\n","  prompts_log.jsonl (5.5 KB)\n","  risk_log.json (37.5 KB)\n","  run_manifest.json (0.3 KB)\n","\n","Total files: 77\n","\n","üì¶ Creating ZIP bundle: ai_law_ch3_bundle_20260107_215606.zip\n","‚úÖ ZIP bundle created: /content/ai_law_ch3_bundle_20260107_215606.zip\n","   Size: 0.19 MB\n","\n","======================================================================\n","‚úÖ FINAL PACKAGE CHECKLIST\n","======================================================================\n","‚úÖ run_manifest.json\n","‚úÖ prompts_log.jsonl\n","‚úÖ risk_log.json\n","‚úÖ AUDIT_README.txt\n","‚úÖ pip_freeze.txt\n","‚úÖ deliverables/ folder\n","‚úÖ ZIP bundle\n","\n","======================================================================\n","üéâ CHAPTER 3 WORKFLOW COMPLETE\n","======================================================================\n","\n","üìÇ Run directory: /content/ai_law_ch3_runs/run_20260107_215606\n","üì¶ Download bundle: /content/ai_law_ch3_bundle_20260107_215606.zip\n","\n","‚ö†Ô∏è  Remember: All outputs require lawyer review. Not legal advice.\n"]}]},{"cell_type":"markdown","source":["##11.CONCLUSIONS"],"metadata":{"id":"2EaDw0AtjFBj"}},{"cell_type":"markdown","source":["**Conclusion: Understanding the Complete Pipeline**\n","\n","**The Journey You Just Completed**\n","\n","You've worked through a sophisticated ten-section pipeline that transforms raw AI capability into a defensible, auditable, professional-grade legal workflow system. Each section played a specific role in building toward the final goal: demonstrating that multi-step AI workflows can assist with complex legal tasks while maintaining the controls, documentation, and human oversight that professional responsibility requires. Let's trace the complete path from beginning to end to solidify your understanding of how all the pieces fit together.\n","\n","**Foundation: Concepts and Infrastructure**\n","\n","The pipeline began with Section 1 establishing the conceptual framework. You learned what multi-step agentic workflows mean, why they represent a capability leap beyond simple chatbot interactions, and what new risks they introduce. This wasn't just theoretical background; it was essential context for understanding every decision made in subsequent sections. You learned that \"agent\" means a workflow pattern, not autonomous AI, and that lawyers remain responsible despite the system's sophistication.\n","\n","Section 2 created the physical infrastructure by establishing a timestamped run directory and subdirectories for deliverables. This might seem mundane, but it's foundational. Without organized file storage established upfront, later sections would have nowhere to save outputs. The timestamp ensures every run gets its own isolated space, preventing different executions from overwriting each other's results.\n","\n","Section 3 connected you to Claude by loading your API key securely and initializing the client object. This is the moment the notebook gained the ability to actually communicate with AI. Without this connection, everything else would be theoretical. The section verified the connection worked and confirmed which model version you're using, ensuring reproducibility.\n","\n","**Governance Framework: Building Accountability**\n","\n","Section 4 initialized the governance artifacts that make this system auditable rather than just functional. It created the run manifest documenting metadata, the prompts log ready to record every API interaction, the risk log prepared to capture every concern flagged during execution, and the pip freeze file enabling reproducibility. These files transform informal AI experimentation into documented professional work with accountability built in from the start.\n","\n","Section 5 introduced confidentiality protections through redaction and minimum-necessary-data functions. This section acknowledged a hard truth: AI systems require data to function, but legal professionals handle sensitive information that shouldn't be freely transmitted. The redaction demonstration showed both the capability and limitations of automated privacy protection, emphasizing that technology assists but cannot replace human judgment about what information to share.\n","\n","**The Critical Technical Core**\n","\n","Section 6 implemented the most technically sophisticated component: the JSON wrapper function using the prefill technique. This section solved the reliability problem that plagued earlier systems where Claude would wrap JSON in conversational text, breaking the parser. By forcing Claude to complete a JSON object already started with an opening brace, the system achieved dramatically higher reliability. The section also implemented retry logic, error handling, automatic risk flagging, and comprehensive logging. This wrapper is the beating heart of the entire system; every substantive AI interaction flows through it.\n","\n","Section 7 defined the cast of characters and the cases they'll handle. It created seven specialist agent functions, each focused on one phase of legal work: orchestration, intake, issue spotting, drafting, quality assurance, adversarial review, and final assembly. It also defined four mini-cases spanning criminal, regulatory, international, and academic domains. This section was pure setup, but essential setup. It established the division of labor that makes multi-step workflows effective and provided concrete test scenarios representing real practice areas.\n","\n","**Execution: Theory Becomes Practice**\n","\n","Section 8 brought everything together by executing the complete seven-step workflow for all four cases. This is where you saw the system actually work. The orchestrator planned each case's approach. Specialists performed their designated tasks in sequence. Human approval gates simulated checkpoints where lawyers would review and authorize proceeding. Quality assurance and red team agents provided complementary perspectives on draft work products. Final assembly integrated everything into polished deliverables.\n","\n","The section also demonstrated professional-grade error handling. When individual steps failed, the system logged the failure and continued rather than crashing. Statistics tracking showed success rates across cases and steps. The final summary table provided immediate visibility into what worked and what didn't. Every output saved to appropriately named files in organized folders, and every risk got logged with context about which case and step identified it.\n","\n","**Personalization and Packaging**\n","\n","Section 9 shifted from demonstration to practice by letting you input your own hypothetical scenario. This section proved the system handles novel situations, not just preset examples. It applied the same confidentiality protections, ran a condensed workflow, and generated deliverables in a separate user folder. This hands-on experience transformed you from observer to participant, cementing understanding through practice.\n","\n","Section 10 completed the pipeline by packaging everything for long-term use. It generated a comprehensive audit readme explaining what every file means and how to review the package. It inventoried all files with sizes. It compressed everything into a downloadable zip bundle. It provided a final checklist verifying all governance artifacts exist. This section ensured that the work product you generated during execution becomes a portable, archivable, auditable package suitable for professional quality control processes.\n","\n","**The Complete Picture**\n","\n","The pipeline flows logically from concepts to infrastructure to connections to governance to protection to core functionality to agent definitions to execution to practice to packaging. Each section depends on previous sections and enables subsequent ones. Nothing is extraneous; every component serves the goal of demonstrating that powerful AI workflows can coexist with professional responsibility when designed thoughtfully.\n","\n","You now understand not just how to run the notebook, but why each section exists, what it contributes, and how it fits into the larger architecture. This understanding enables you to adapt these patterns to your own practice, evaluate commercial legal AI products more critically, and discuss AI governance with colleagues and ethics committees from a position of informed expertise.\n","\n","The pipeline you've traced represents the future of legal practice: powerful AI assistance operating within robust professional controls."],"metadata":{"id":"W-ahJOpxjG8I"}}]}