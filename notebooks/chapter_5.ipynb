{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1DWGlbsc94b6iPgsYrWd0x7S1CHYYi7xy","timestamp":1767875149799}],"toc_visible":true,"authorship_tag":"ABX9TyOHHIanJXQh+hEoXuyFkjqj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**AI LAW, CHAPTER 5. ORGANIZATIONS**\n","\n","---"],"metadata":{"id":"WvlVGWFzi3KB"}},{"cell_type":"markdown","source":["##0.REFERENCE"],"metadata":{"id":"Z-2P4HNIjBdw"}},{"cell_type":"markdown","source":["https://chatgpt.com/share/695fb8a4-501c-8012-b08b-906083964e03"],"metadata":{"id":"OWUPTQdDkKTh"}},{"cell_type":"markdown","source":["##1.CONTEXT"],"metadata":{"id":"-FcBs1sCjCzD"}},{"cell_type":"markdown","source":["This notebook is not “a chatbot in a browser.” It is a small, auditable workflow that treats generative AI the way a responsible legal team must treat it: as a fallible drafting and reasoning aid operating inside a controlled process, with a record of what happened, what was assumed, what is missing, what is risky, and what must be verified before anyone relies on the output. If you have only used chatbots in apps or on the internet, you are used to a simple interaction: you type a question, you get an answer, and you move on. That is fine for casual uses—summaries, brainstorming, or learning. It is not fine for legal work where confidentiality, privilege, accuracy, supervision, and professional responsibility are not “nice to have” features but baseline obligations. Chapter 5 matters because it shows the transition from “individual lawyer using AI” to “an organization using AI,” and that transition is where risk and governance either become real—or become expensive.\n","\n","Here is what we are doing, precisely. We are simulating a “mini-firm” workflow: a structured pipeline that takes a matter from first contact to a controlled set of deliverables, with checkpoints and an audit trail. The pipeline has stages that mirror real legal operations: intake, conflicts/engagement checks, scope definition, workplan, drafting, quality assurance and red-teaming, sign-off preparation, and audit packaging. At each stage, the system produces outputs in a strict, structured format—JSON—so that we can reliably capture what the AI produced and what a supervising lawyer should review. We are not asking the AI to “be right.” We are forcing the AI to be explicit about what it knows, what it assumes, what it does not know, and what must be verified. That is the core difference between “chat” and “legal use.”\n","\n","The model we call (Claude) is powerful, but it is still a probabilistic system. It can sound confident and still be wrong. It can follow instructions and still drift. It can produce a beautiful paragraph that includes a detail that was never provided. In ordinary chatbot usage, those limitations are annoying; in legal work, they can be harmful. They can mislead a client, undermine a filing, create a false record, or cause a lawyer to miss a critical fact. That is why this notebook begins with a safety envelope: you do not paste confidential client information; you redact by default; you label everything “Not verified”; and you treat outputs as drafts requiring human review. These are not “compliance decorations.” They are practical controls that reduce the chance that AI becomes the weak link in your professional obligations.\n","\n","This notebook also differs from typical chatbot use because it is designed to be replayable and auditable. In a standard chat session, you have a conversation history, but it is not a structured operational record. In legal settings—especially organizations—what matters is not only the final text but how it was produced. What inputs were used? What instructions were given? Which model version was called? What risks were flagged? What steps were taken to check and correct the draft? This notebook generates governance artifacts automatically: a run manifest that records the model and parameters, a prompts log that records redacted inputs and output hashes, a risk log that aggregates flagged risks, and a deliverables folder that stores stage-by-stage outputs. At the end, it bundles everything into a single zip file you can retain as an “audit bundle.” The point is not surveillance; the point is accountability—so that a supervising attorney can review the work, understand what happened, and decide whether and how to rely on it.\n","\n","A critical technical aspect of this notebook, and one of the main lessons from earlier chapters, is reliability in structured output. Large language models are trained to be conversational, which means they often add polite explanations (“Here is your JSON”) or wrap outputs in formatting. That breaks automated parsing and, in a workflow system, a broken parse is not a small nuisance—it stops the pipeline. In Chapter 5 we therefore enforce structured output using a technique that “steers” the model to complete a JSON object rather than write free-form text. In plain terms: instead of hoping the model behaves, we shape the interaction so it is much more likely to behave. This is an important organizational lesson. At Level 5, you do not rely on best intentions; you design controls that make failure less likely and make failures visible when they occur.\n","\n","The mini-firm simulation also introduces the concept of “separation of concerns.” In real practice, intake is not drafting; conflicts checks are not strategy; QA is not the same as client communication. A single person may do multiple roles, but the roles remain distinct because each role has different risks and different required checks. This notebook encodes that separation. Intake produces a checklist and open questions. Conflicts produces questions and boundaries. Scope clarifies what is in and out. Workplan lays out steps and approval gates. Draft produces a first-pass work product appropriate to the domain. QA and red-team stress test the draft for missing facts, overconfidence, tone, and injection-style manipulation. Sign-off does not “rewrite the memo”; it creates a package for the lawyer to review and verify. Audit organizes the artifacts so the matter can be replayed and defended. That is the organizational maturity move: legal work is not only “writing.” It is process.\n","\n","You will also see why we insist on “Not verified.” In casual chatbot usage, you might accept a plausible explanation as “good enough.” In legal work, plausible is dangerous. This notebook forces outputs to include “questions to verify” and prohibits invented authorities. If a rule, case, or statute is needed, the correct behavior is not to fabricate it; it is to identify that verification is required and ask for the source. This is how you operationalize candor and accuracy in AI-assisted workflows: you build the uncertainty into the artifact rather than leaving it in someone’s head.\n","\n","Finally, Chapter 5 matters because it is the bridge from personal experimentation to institutional readiness. Many lawyers can use a chatbot to draft an email. That is Level 1. Some can use AI to structure analysis. That is Level 2. Some can build multi-step workflows. That is Level 3. Some can create reusable assets. That is Level 4. But an organization needs something more: it needs repeatability, boundaries, logging, and supervisory control. In other words, it needs a system that behaves like a firm behaves. Chapter 5 is the blueprint for that: a mini-firm simulation you can run, inspect, and improve. If you understand this notebook, you understand the difference between “AI as a helpful tool” and “AI as a governed operational capability”—and that difference is where legal organizations will either gain safe leverage or accumulate hidden risk.\n","\n","If you take only one thing from this notebook, take this: in legal work, the value of AI is not just the words it produces. The value is a controlled workflow that makes drafts faster while making risks clearer, verification easier, and accountability non-negotiable. That is what we are building here.\n"],"metadata":{"id":"_Ml4fNUCkLN5"}},{"cell_type":"markdown","source":["##2.LIBRARIES AND ENVIRONMENT"],"metadata":{"id":"eG_Lx09fjEuz"}},{"cell_type":"code","source":["# Cell 2 (Code)\n","# Goal: Install/imports + create run directory (timezone-aware UTC; no utcnow() deprecation warning)\n","# Output: prints run directory path\n","\n","!pip -q install anthropic\n","\n","import os, json, re, hashlib, platform, textwrap, traceback, subprocess\n","from datetime import datetime, timezone\n","from pathlib import Path\n","\n","RUN_ID = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n","RUN_DIR = Path(f\"/content/ai_law_ch5_runs/run_{RUN_ID}\")\n","DELIVER_DIR = RUN_DIR / \"deliverables\"\n","DELIVER_DIR.mkdir(parents=True, exist_ok=True)\n","\n","print(\"Run directory:\", str(RUN_DIR))\n"],"metadata":{"id":"-Ia-uZJQ6ofY","executionInfo":{"status":"ok","timestamp":1767880957013,"user_tz":360,"elapsed":3121,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"63b36000-c691-4609-d622-99c68ba47775","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Run directory: /content/ai_law_ch5_runs/run_20260108T140237Z\n"]}]},{"cell_type":"markdown","source":["##3.API SETUP AND CLIENT INITIALIZATION"],"metadata":{"id":"QdO9R5i3jKgk"}},{"cell_type":"markdown","source":["###3.1.OVERVIEW"],"metadata":{"id":"A6Rac3CPjMYb"}},{"cell_type":"markdown","source":["**API Key Setup and Client Initialization**\n","\n","This section establishes the connection between your Google Colab notebook and the Anthropic API service. Think of it as setting up a phone line before making a call - you need the right credentials and connection details to communicate with Claude.\n","\n","**What Happens in This Section**\n","\n","First, the notebook retrieves your Anthropic API key from Google Colab's secure storage system called \"Secrets\". This is similar to retrieving a password from a password manager rather than writing it directly in your code. The key acts as your authorization credential, proving you have permission to use the Claude API service.\n","\n","Next, the system stores this key in an environment variable. Environment variables are temporary storage locations that programs can access during their execution. This makes the key available to other parts of the notebook without repeatedly typing it.\n","\n","Then, the code creates a \"client\" object using the Anthropic library. The client is your communication interface - it handles all the technical details of sending requests to Claude and receiving responses. Without this client, your notebook cannot interact with the AI model.\n","\n","Finally, the section specifies which Claude model to use. In this notebook, we use Claude Haiku version four point five. Different models have different capabilities, speeds, and costs. Haiku is designed for efficiency while maintaining high quality output, making it suitable for production legal workflows where you need reliable performance.\n","\n","**Why This Matters for Legal Practice**\n","\n","For lawyers using AI tools, proper API initialization is a governance requirement, not just a technical step. The approach here demonstrates several best practices. First, keeping API keys in secure storage rather than hardcoding them prevents accidental exposure if you share the notebook. Second, explicitly declaring which model version you use creates an audit trail - six months later, you can verify exactly which AI system generated a particular output. Third, the error handling ensures you receive clear feedback if something goes wrong during setup, rather than mysterious failures later in the workflow.\n","\n","**What You See When Running**\n","\n","When this section executes successfully, you will see three confirmation messages indicating the API key loaded correctly, displaying the model name, and confirming the client initialized. If there is a problem, you will see an error message directing you to add your API key to Colab Secrets using the key icon in the sidebar. This immediate feedback helps you catch configuration issues before attempting to generate any legal assets.\n","\n","**Connection to the Overall Workflow**\n","\n","Everything that follows in this notebook depends on this initialization. Without a properly configured client and model specification, the asset generation pipeline cannot function. This section is the foundation that enables all subsequent governance-tracked AI interactions."],"metadata":{"id":"E93QEc-BkQrz"}},{"cell_type":"markdown","source":["###3.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"-KwUcrNBjOP3"}},{"cell_type":"code","source":["# Cell 3 (Code)\n","# Goal: API key setup + Anthropic client initialization (explicit)\n","# Output: prints key loaded yes/no and model name\n","\n","import anthropic\n","from google.colab import userdata\n","\n","ANTHROPIC_API_KEY = userdata.get(\"ANTHROPIC_API_KEY\")\n","if not ANTHROPIC_API_KEY:\n","    raise RuntimeError(\n","        \"Missing ANTHROPIC_API_KEY. In Colab: Right panel → Secrets → add ANTHROPIC_API_KEY, then re-run Cell 3.\"\n","    )\n","\n","os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n","\n","client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n","\n","MODEL = \"claude-haiku-4-5-20251001\"  # REQUIRED by user\n","DEFAULT_TEMPERATURE = 0.1\n","RETRY_TEMPERATURE = 0.0\n","MIN_MAX_TOKENS = 1800\n","\n","print(\"API key loaded:\", \"yes\" if bool(ANTHROPIC_API_KEY) else \"no\")\n","print(\"Model:\", MODEL)\n"],"metadata":{"id":"DMPEMYXMjQVN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767880961855,"user_tz":360,"elapsed":613,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"d319bfe2-9b3f-45fc-aba6-9b94bfe71581"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["API key loaded: yes\n","Model: claude-haiku-4-5-20251001\n"]}]},{"cell_type":"markdown","source":["##4.GOVERNANCE UTILITIES"],"metadata":{"id":"qyA9WzYLjQvV"}},{"cell_type":"markdown","source":["###4.1.OVERVIEW"],"metadata":{"id":"DUJeUPvLjTsI"}},{"cell_type":"markdown","source":["**Cell 4: Governance Utilities and Run Artifacts (Why This Matters)**\n","\n","**What Cell 4 does**  \n","Cell 4 creates the “paper trail” for the entire notebook run. It sets up a few small utilities that let the notebook write structured files and append records safely. Then it immediately generates the core governance artifacts: the run manifest, the prompt log file, the risk log file, and a dependency snapshot. From this point on, every important step in the pipeline can leave a trace that a supervising lawyer can review later.\n","\n","**Why legal workflows need this, but casual chatbot use does not**  \n","When people use a chatbot in an app, they typically focus only on the final text. In legal work, that is not enough. If a draft influences client advice, a filing, or a negotiation, you need to be able to answer basic questions later: What model was used? What settings were used? What was asked? What risks were flagged? What did the system assume? A governed workflow does not rely on memory or screenshots. It produces a structured audit record by design.\n","\n","**The run manifest: what it records and why it matters**  \n","The run manifest is a small JSON file that captures the “identity” of the run: when it happened, which chapter/pipeline is being executed, which model was used, and what key parameters were set. Think of it as the cover sheet for the entire run. If you rerun the notebook next week, the manifest helps you confirm whether you are truly reproducing the same conditions.\n","\n","**The prompts log: why it exists and what it avoids**  \n","The prompts log stores one record per model call, but it is designed to be safe. The notebook logs only redacted content plus hashes, so you can verify integrity without storing sensitive client material. This log supports accountability: you can see what the system asked the model to do at each stage and confirm that the workflow followed the intended steps.\n","\n","**The risk log: how it supports supervision**  \n","The risk log aggregates the risk flags produced across stages and matters. Instead of burying risks inside long drafts, the risk log makes them easy to review. This is essential for organizational use: it allows a supervisor to quickly spot high-severity issues like missing facts, confidentiality concerns, or hallucination risk.\n","\n","**What you should see after Cell 4 runs**  \n","Cell 4 prints the file paths of the artifacts it created. This is your confirmation that the notebook is now operating as a controlled pipeline with a persistent audit trail, not as an ephemeral chat session.\n"],"metadata":{"id":"8SSmrUtfkRo3"}},{"cell_type":"markdown","source":["###4.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"k2xcl99ijWWi"}},{"cell_type":"code","source":["# Cell 4 (Code)\n","# Goal: Governance utilities + write run_manifest + init logs (+ pip_freeze.txt)\n","# Output: prints artifact file paths\n","\n","def now_iso():\n","    return datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n","\n","def sha256_text(s: str) -> str:\n","    return hashlib.sha256(s.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n","\n","def write_json(path: Path, obj) -> None:\n","    path.parent.mkdir(parents=True, exist_ok=True)\n","    path.write_text(json.dumps(obj, indent=2, ensure_ascii=False))\n","\n","def append_jsonl(path: Path, record: dict) -> None:\n","    path.parent.mkdir(parents=True, exist_ok=True)\n","    with path.open(\"a\", encoding=\"utf-8\") as f:\n","        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n","\n","MANIFEST_PATH = RUN_DIR / \"run_manifest.json\"\n","PROMPTS_LOG_PATH = RUN_DIR / \"prompts_log.jsonl\"\n","RISK_LOG_PATH = RUN_DIR / \"risk_log.json\"\n","PIP_FREEZE_PATH = RUN_DIR / \"pip_freeze.txt\"\n","\n","# pip freeze for reproducibility\n","try:\n","    freeze_txt = subprocess.check_output([\"pip\", \"freeze\"], text=True)\n","except Exception:\n","    freeze_txt = \"pip freeze failed\"\n","PIP_FREEZE_PATH.write_text(freeze_txt)\n","\n","run_manifest = {\n","    \"run_id\": RUN_ID,\n","    \"timestamp_utc\": now_iso(),\n","    \"chapter\": \"Chapter 5 — Level 5 (Organizations)\",\n","    \"model\": MODEL,\n","    \"params\": {\n","        \"temperature_default\": DEFAULT_TEMPERATURE,\n","        \"temperature_retry\": RETRY_TEMPERATURE,\n","        \"max_tokens_min\": MIN_MAX_TOKENS\n","    },\n","    \"environment\": {\n","        \"python_version\": platform.python_version(),\n","        \"platform\": platform.platform(),\n","    },\n","    \"purpose\": \"Mini-firm simulation: intake → checks → workflow → QA → sign-off → audit (governance-first).\"\n","}\n","\n","write_json(MANIFEST_PATH, run_manifest)\n","\n","# initialize logs\n","if not PROMPTS_LOG_PATH.exists():\n","    PROMPTS_LOG_PATH.write_text(\"\", encoding=\"utf-8\")\n","if not RISK_LOG_PATH.exists():\n","    write_json(RISK_LOG_PATH, {\"run_id\": RUN_ID, \"timestamp_utc\": now_iso(), \"risks\": []})\n","\n","print(\"Created:\")\n","print(\" -\", str(MANIFEST_PATH))\n","print(\" -\", str(PROMPTS_LOG_PATH))\n","print(\" -\", str(RISK_LOG_PATH))\n","print(\" -\", str(PIP_FREEZE_PATH))\n"],"metadata":{"id":"rxLKqYUYjYAm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767880967850,"user_tz":360,"elapsed":1806,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"9e14631a-1b63-4b00-86aa-91f068f2e20b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Created:\n"," - /content/ai_law_ch5_runs/run_20260108T140237Z/run_manifest.json\n"," - /content/ai_law_ch5_runs/run_20260108T140237Z/prompts_log.jsonl\n"," - /content/ai_law_ch5_runs/run_20260108T140237Z/risk_log.json\n"," - /content/ai_law_ch5_runs/run_20260108T140237Z/pip_freeze.txt\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3690011035.py:6: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n"]}]},{"cell_type":"markdown","source":["##5.REDACTION AND MINIMUM NECESSARYN INTAKE HELPERS"],"metadata":{"id":"Rdk2NsbajYha"}},{"cell_type":"markdown","source":["###5.1.OVERVIEW"],"metadata":{"id":"Ri4JhmeGjZ3i"}},{"cell_type":"markdown","source":["**Redaction and Minimum-Necessary Intake Utilities**\n","\n","This section implements privacy protection mechanisms that prevent sensitive client information from being inadvertently exposed during AI interactions. Think of it as establishing attorney-client privilege safeguards before handling confidential materials - you create protective barriers first, then work within those boundaries.\n","\n","**Understanding the Redaction Function**\n","\n","The redaction function scans text for common patterns of personally identifiable information and replaces them with placeholder labels. Specifically, it searches for email addresses, telephone numbers in United States formats, Social Security numbers, and street addresses. When it finds these patterns, it substitutes them with labels like EMAIL REDACTED or PHONE REDACTED. The function also tracks what types of information it removed, returning both the cleaned text and a list of redacted categories.\n","\n","**How Pattern Matching Works**\n","\n","The redaction uses what programmers call regular expressions, which are sophisticated search patterns that can identify text structures. For email addresses, the pattern looks for words, followed by the at symbol, followed by more words, a dot, and a domain extension. For phone numbers, it searches for three digits, possibly a separator like a dash or dot, three more digits, another separator, and four final digits. For Social Security numbers, it expects exactly the format three digits dash two digits dash four digits. For street addresses, it looks for a number followed by capitalized words ending with street types like Street, Avenue, Road, or Boulevard.\n","\n","These patterns catch standard formatting reliably. If someone writes five five five dash one two three dash four five six seven, the pattern recognizes it as a phone number. If someone writes john dot smith at example dot com, the pattern recognizes it as an email. This automation means you don't have to manually review every piece of text hunting for identifiers to remove.\n","\n","**Critical Limitations You Must Understand**\n","\n","The notebook explicitly and repeatedly warns that redaction is imperfect and operates on a best-effort basis. Pattern-based redaction cannot catch everything. Names standing alone without accompanying identifiers will pass through undetected. If your text says \"Maria Torres called yesterday,\" the redaction function has no way to know that Maria Torres is a real client rather than a hypothetical example. Case-specific facts that could identify individuals but don't match standard patterns will also pass through. A unique medical condition, an unusual business transaction, or a distinctive family situation might identify someone even without standard identifiers present.\n","\n","Information in unusual formats escapes pattern matching. If someone writes their phone number as five five five one two three four five six seven with no separators, the pattern looking for digit groups with separators will miss it. If an email uses an unusual format or includes special characters, the standard email pattern might not match. If an address is abbreviated or formatted non-standardly, the address pattern might not catch it.\n","\n","**Why This Approach Despite Limitations**\n","\n","Given these limitations, why use pattern-based redaction at all? Because it provides a meaningful safety net that catches the most common identifiers in their most common formats. Most people write phone numbers with separators. Most people format Social Security numbers with dashes. Most people write email addresses in standard format. Catching these common cases prevents the majority of accidental exposures.\n","\n","The alternative would be no automated protection at all, relying entirely on human vigilance to avoid entering sensitive information. Human attention wavers, especially during repetitive tasks or long work sessions. Automated redaction provides consistent protection that never gets tired or distracted. It's not perfect, but it's substantially better than nothing.\n","\n","**The Demonstration**\n","\n","The section runs a live demonstration using deliberately fake data containing all four protected identifier types. You see the original text with an email address, phone number, street address, and Social Security number clearly visible. Then you see the redacted version with each identifier replaced by its corresponding placeholder. Finally you see a summary listing which categories were removed: emails, phone numbers, Social Security numbers, and addresses.\n","\n","This concrete example serves multiple purposes. First, it proves the redaction function actually works as described. Second, it shows you exactly what the placeholders look like so you can recognize them in later outputs. Third, it demonstrates the reporting mechanism that tells you what was removed. Fourth, it reinforces through visual example what the function can and cannot do.\n","\n","**Minimum-Necessary Fields Function**\n","\n","The section also includes a utility for filtering data dictionaries to keep only required fields. This implements the principle of data minimization, sending only the minimum information necessary to accomplish the task. If you have a data structure with twenty fields describing a client, but only five of those fields are relevant to generating a particular asset, this function strips away the unnecessary fifteen fields.\n","\n","Why does this matter? Because every piece of information sent to an external API represents potential exposure risk. Even with strong contractual protections and technical safeguards, minimizing what you share reduces risk. If the five fields you need don't include the client's full name, home address, or financial details, those sensitive items never leave your control at all.\n","\n","**Integration Into the Pipeline**\n","\n","This redaction infrastructure doesn't exist in isolation. It gets invoked repeatedly throughout the entire pipeline. Before sending case facts to the API, the generate asset function applies redaction. Before logging prompts to the prompts log file, the logging function applies redaction. Before writing responses to disk, the system applies redaction. This layered approach creates multiple opportunities to catch and remove sensitive information before it could be exposed.\n","\n","**Warning Messages**\n","\n","The section concludes with a prominent warning message displayed every time it runs: \"WARNING: Redaction is imperfect. Do NOT paste sensitive client data.\" This repeated warning serves a crucial function. It prevents complacency. Every time you run the notebook, you see this reminder that the technical safeguard has limits. This keeps the limitation front of mind rather than letting you forget about it after the first explanation.\n","\n","**Professional Responsibility Context**\n","\n","For lawyers, this section addresses a fundamental ethical tension. You need factual context for AI tools to generate useful outputs. Generic requests produce generic results. Specific requests with concrete details produce practical results. But providing those specific details risks exposing confidential client information, violating your duty to protect client confidences and potentially waiving attorney-client privilege.\n","\n","The redaction approach here represents one strategy for managing this tension. Provide enough specificity for usefulness, but automatically scrub obvious identifiers before transmission. However, the warnings emphasize that technology alone cannot ensure confidentiality. Sound professional judgment about what information to include remains essential. Some matters are too sensitive for any AI involvement regardless of technical safeguards. Some facts are too uniquely identifying even without standard identifiers. Lawyers must exercise judgment rather than blindly trusting automated protection.\n","\n","**Building Toward Asset Generation**\n","\n","With this privacy protection layer in place, the notebook can proceed to actual asset generation with reduced confidentiality risk. The next sections will show API calls and structured outputs. Throughout all of that, you can trust that redaction occurred before any external transmission. This foundational privacy layer makes the subsequent workflow ethically defensible rather than reckless."],"metadata":{"id":"oMEx3BRrkT9r"}},{"cell_type":"markdown","source":["###5.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"HJDPCKaZjcEB"}},{"cell_type":"code","source":["# Cell 5 (Code)\n","# Goal: Redaction + minimum-necessary intake helper (never write unredacted to disk)\n","# Output: demo before/after with fake data\n","\n","EMAIL_RE = re.compile(r\"\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[A-Za-z]{2,}\\b\")\n","PHONE_RE = re.compile(r\"(\\+?\\d{1,2}\\s*)?(\\(?\\d{3}\\)?[\\s.-]?)?\\d{3}[\\s.-]?\\d{4}\\b\")\n","SSN_RE = re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\")\n","# very rough address heuristic\n","ADDR_RE = re.compile(r\"\\b\\d{1,6}\\s+[A-Za-z0-9.\\- ]+\\s+(Street|St|Avenue|Ave|Road|Rd|Boulevard|Blvd|Lane|Ln|Drive|Dr)\\b\", re.IGNORECASE)\n","\n","def redact(text: str):\n","    removed = {\"emails\": [], \"phones\": [], \"ssns\": [], \"addresses\": []}\n","    t = text\n","\n","    removed[\"emails\"] = EMAIL_RE.findall(t)\n","    t = EMAIL_RE.sub(\"[REDACTED_EMAIL]\", t)\n","\n","    removed[\"phones\"] = PHONE_RE.findall(t)\n","    t = PHONE_RE.sub(\"[REDACTED_PHONE]\", t)\n","\n","    removed[\"ssns\"] = SSN_RE.findall(t)\n","    t = SSN_RE.sub(\"[REDACTED_SSN]\", t)\n","\n","    removed[\"addresses\"] = ADDR_RE.findall(t)\n","    t = ADDR_RE.sub(\"[REDACTED_ADDRESS]\", t)\n","\n","    # normalize removed fields (phones regex returns tuples)\n","    removed[\"phones\"] = [\"\".join(p).strip() for p in removed[\"phones\"] if \"\".join(p).strip()]\n","    return t, removed\n","\n","def minimum_necessary_facts(raw_text: str):\n","    redacted_text, removed = redact(raw_text)\n","    # Simple heuristic: split into short bullets\n","    bullets = [b.strip(\"- \").strip() for b in re.split(r\"[\\n•]+\", redacted_text) if b.strip()]\n","    bullets = bullets[:10]\n","    return {\"redacted_text\": redacted_text, \"facts_bullets\": bullets, \"removed_fields\": removed}\n","\n","# Demo with fake data (safe)\n","demo = \"Client John Doe, email john@acme.com, phone (212) 555-1212, SSN 123-45-6789, address 10 Main Street.\"\n","mn = minimum_necessary_facts(demo)\n","print(\"BEFORE:\\n\", demo)\n","print(\"\\nAFTER (REDACTED):\\n\", mn[\"redacted_text\"])\n","print(\"\\nREMOVED FIELDS:\\n\", json.dumps(mn[\"removed_fields\"], indent=2))\n"],"metadata":{"id":"OdY_DwOFjdx1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767878873140,"user_tz":360,"elapsed":22,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"2e624a78-7b90-470f-9376-26382f9eac10"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["BEFORE:\n"," Client John Doe, email john@acme.com, phone (212) 555-1212, SSN 123-45-6789, address 10 Main Street.\n","\n","AFTER (REDACTED):\n"," Client John Doe, email [REDACTED_EMAIL], phone [REDACTED_PHONE], SSN [REDACTED_SSN], address [REDACTED_ADDRESS].\n","\n","REMOVED FIELDS:\n"," {\n","  \"emails\": [\n","    \"john@acme.com\"\n","  ],\n","  \"phones\": [\n","    \"(212)\"\n","  ],\n","  \"ssns\": [\n","    \"123-45-6789\"\n","  ],\n","  \"addresses\": [\n","    \"Street\"\n","  ]\n","}\n"]}]},{"cell_type":"markdown","source":["##6.CLAUDE WRAPPER"],"metadata":{"id":"37Md4ig9jePY"}},{"cell_type":"markdown","source":["###6.1.OVERVIEW"],"metadata":{"id":"CFUHJxTnjf9a"}},{"cell_type":"markdown","source":["**Cell 6: The Reliable “JSON-Only” Claude Wrapper (Why This Matters Most)**\n","\n","**What Cell 6 does**  \n","Cell 6 builds the single most important piece of the notebook: the function that calls Claude and reliably returns a structured result the rest of the pipeline can use. Every later stage—intake, conflicts, scope, drafting, QA, sign-off, and audit—depends on this wrapper. If the wrapper is unreliable, the entire pipeline collapses because downstream steps cannot safely parse or trust the model’s output format.\n","\n","**Why we had problems in earlier chapters**  \n","In earlier notebooks, Claude often responded like a helpful human assistant: it added “Here is the JSON,” inserted explanations, or wrapped the JSON in formatting. Even when we asked for strict JSON, the model’s conversational instincts sometimes won. That behavior is harmless in a chat window, but it is damaging in a workflow system because automated processing needs predictable structure.\n","\n","**The key fix: the prefill technique**  \n","Cell 6 uses a “prefill” technique to force structure. Instead of asking Claude to start from scratch, we begin the assistant’s response with a single opening curly brace. This gently pushes the model into “completion mode,” so it continues the JSON object rather than drifting into conversation. The notebook then reconstructs the full JSON and parses it. In practice, this dramatically increases first-attempt success and reduces the need for retries.\n","\n","**Defense-in-depth: retries and extraction fallbacks**  \n","Even with prefill, the wrapper includes backup protections. If parsing fails, it retries the call with stricter instructions and lower randomness. If that still fails, it uses a few extraction strategies that try to recover a JSON object from text. The goal is not to be clever; the goal is to keep the pipeline stable. A stable pipeline is safer than a brittle one, because brittle systems encourage users to bypass controls when things break.\n","\n","**Schema validation: preventing “almost-correct” outputs**  \n","Cell 6 also checks that the response includes exactly the required fields and nothing extra. This matters because “almost correct” JSON can hide missing sections, omitted risks, or a missing verification list. Schema validation ensures every stage output contains the same supervisory structure: facts, assumptions, open questions, controls applied, stage output, handoff, risks, and verification tasks.\n","\n","**Logging and risk capture: making supervision possible**  \n","Cell 6 writes a record to the prompts log for each call and updates the risk log with any flagged risks. This is how apparent “drafting” becomes an organizational process. The logs are not optional extras; they are what allow a reviewing lawyer to see what the model did, what could be wrong, and what must be verified.\n","\n","**The smoke test: proving the wrapper works before the pipeline runs**  \n","At the end of Cell 6, the notebook runs a small smoke test that confirms the wrapper can produce valid, schema-compliant JSON. This is a practical safeguard: it catches format failures early, before you run multiple matters through multiple stages.\n","\n","**Why Cell 6 is essential for legal use**  \n","Legal workflows require repeatability, structure, and reviewability. Cell 6 is the engineering step that turns a conversational model into a controlled component inside a supervised pipeline. Without it, you do not have a workflow—you have a chat session dressed up as a notebook.\n"],"metadata":{"id":"nI6BO3C4kXRG"}},{"cell_type":"markdown","source":["###6.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"kCgz7QJjjhwA"}},{"cell_type":"code","source":["# Cell 6 (Code) — CRITICAL RELIABILITY\n","# Goal: Prefill-enforced JSON wrapper (fixes Claude non-JSON behavior) + extraction fallback + schema validation + retries + smoke test\n","# Output: PASS/FAIL diagnostics\n","\n","# ---- STRICT SCHEMA (Chapter 5 “Organization pipeline stage output”) ----\n","REQUIRED_KEYS = [\n","    \"task\",\n","    \"stage\",\n","    \"matter_id\",\n","    \"facts_provided\",\n","    \"assumptions\",\n","    \"open_questions\",\n","    \"controls_applied\",\n","    \"stage_output\",\n","    \"handoff\",\n","    \"risks\",\n","    \"verification_status\",\n","    \"questions_to_verify\"\n","]\n","\n","def schema_is_valid(obj: dict):\n","    if not isinstance(obj, dict):\n","        return False, \"Parsed object is not a dict\"\n","    keys = list(obj.keys())\n","    missing = [k for k in REQUIRED_KEYS if k not in obj]\n","    extra = [k for k in keys if k not in REQUIRED_KEYS]\n","    if missing:\n","        return False, f\"Missing keys: {missing}\"\n","    if extra:\n","        return False, f\"Extra keys not allowed: {extra}\"\n","    # minimal type checks\n","    if obj.get(\"verification_status\") != \"Not verified\":\n","        return False, \"verification_status must be 'Not verified'\"\n","    return True, \"ok\"\n","\n","def extract_json_from_text(text: str):\n","    # Strategy 1: as-is\n","    try:\n","        return json.loads(text)\n","    except Exception:\n","        pass\n","\n","    # Strategy 3: strip fenced blocks first (common failure mode)\n","    fenced = re.search(r\"```(?:json)?\\s*(\\{.*\\})\\s*```\", text, flags=re.DOTALL)\n","    if fenced:\n","        try:\n","            return json.loads(fenced.group(1))\n","        except Exception:\n","            pass\n","\n","    # Strategy 2: first { to last }\n","    i = text.find(\"{\")\n","    j = text.rfind(\"}\")\n","    if i != -1 and j != -1 and j > i:\n","        candidate = text[i:j+1]\n","        try:\n","            return json.loads(candidate)\n","        except Exception:\n","            pass\n","\n","    # Strategy 4: bracket balancing scan\n","    start = text.find(\"{\")\n","    if start == -1:\n","        return None\n","    depth = 0\n","    for idx in range(start, len(text)):\n","        ch = text[idx]\n","        if ch == \"{\":\n","            depth += 1\n","        elif ch == \"}\":\n","            depth -= 1\n","            if depth == 0:\n","                candidate = text[start:idx+1]\n","                try:\n","                    return json.loads(candidate)\n","                except Exception:\n","                    return None\n","    return None\n","\n","SYSTEM_PROMPT = textwrap.dedent(f\"\"\"\n","You are a legal workflow assistant for US lawyers.\n","\n","CRITICAL: Output ONLY a JSON object. No prose. No markdown. No code fences.\n","Your response must start with {{ and end with }}. Nothing before, nothing after.\n","\n","You MUST follow this exact JSON schema (no extra keys):\n","{{\n","  \"task\": \"...\",\n","  \"stage\": \"intake|conflicts|scope|workplan|draft|qa|signoff|audit\",\n","  \"matter_id\": \"...\",\n","  \"facts_provided\": [\"...\"],\n","  \"assumptions\": [\"...\"],\n","  \"open_questions\": [\"...\"],\n","  \"controls_applied\": [\"...\"],\n","  \"stage_output\": {{\n","    \"type\": \"checklist|memo|email|plan|package\",\n","    \"summary\": \"...\",\n","    \"items\": [\"...\"]\n","  }},\n","  \"handoff\": {{\n","    \"next_stage\": \"...\",\n","    \"needs_human_approval\": true,\n","    \"approval_question\": \"...\",\n","    \"stop_if\": [\"...\"]\n","  }},\n","  \"risks\": [\n","    {{\"type\":\"confidentiality|privilege|hallucination|missing_facts|unauthorized_practice|overconfidence|prompt_injection|tone|other\",\n","      \"severity\":\"low|medium|high\",\n","      \"note\":\"...\"}}\n","  ],\n","  \"verification_status\": \"Not verified\",\n","  \"questions_to_verify\": [\"...\"]\n","}}\n","\n","Rules:\n","- verification_status must always be \"Not verified\"\n","- Never invent legal authorities or citations\n","- Put missing facts in open_questions and verification tasks in questions_to_verify\n","- stage_output.summary must be concise (<= 120 words)\n","\"\"\").strip()\n","\n","def call_claude_json_prefill(*, task: str, stage: str, matter_id: str, facts: list, user_instruction: str,\n","                            max_tokens: int = MIN_MAX_TOKENS):\n","    \"\"\"\n","    PREFILL TECHNIQUE:\n","    We add an assistant message content \"{\" so Claude continues the JSON object rather than chatting.\n","    We then prepend \"{\" back before parsing.\n","    \"\"\"\n","    # Minimal user prompt (do NOT over-instruct; system enforces schema)\n","    redacted_instruction, _ = redact(user_instruction)\n","    payload = (\n","        f\"Task: {task}\\n\"\n","        f\"Stage: {stage}\\n\"\n","        f\"Matter ID: {matter_id}\\n\"\n","        f\"Facts:\\n- \" + \"\\n- \".join([str(x) for x in facts]) + \"\\n\"\n","        f\"Instruction: {redacted_instruction}\\n\"\n","        f\"Return ONLY JSON.\"\n","    )\n","\n","    attempts = [\n","        {\"temperature\": DEFAULT_TEMPERATURE, \"prefix\": \"\"},\n","        {\"temperature\": RETRY_TEMPERATURE, \"prefix\": \"OUTPUT ONLY JSON. NO TEXT. \"},\n","        {\"temperature\": RETRY_TEMPERATURE, \"prefix\": \"OUTPUT ONLY JSON. NO TEXT. \"}\n","    ]\n","\n","    last_error = None\n","    for attempt_idx, a in enumerate(attempts, start=1):\n","        t = a[\"temperature\"]\n","        prefix = a[\"prefix\"]\n","\n","        messages = [\n","            {\"role\": \"user\", \"content\": prefix + payload},\n","            {\"role\": \"assistant\", \"content\": \"{\"}  # PREFILL\n","        ]\n","\n","        try:\n","            resp = client.messages.create(\n","                model=MODEL,\n","                max_tokens=max_tokens,\n","                temperature=t,\n","                system=SYSTEM_PROMPT,\n","                messages=messages,\n","            )\n","\n","            # Anthropic SDK: resp.content is a list of content blocks; join text blocks\n","            text_out = \"\"\n","            for block in resp.content:\n","                if getattr(block, \"type\", None) == \"text\":\n","                    text_out += block.text\n","\n","            # Reconstruct full JSON\n","            reconstructed = \"{\" + (text_out or \"\").strip()\n","\n","            parsed = None\n","            try:\n","                parsed = json.loads(reconstructed)\n","            except Exception:\n","                parsed = extract_json_from_text(reconstructed) or extract_json_from_text(text_out or \"\")\n","\n","            if parsed is None:\n","                raise ValueError(\"JSON parse failed (even after fallback extraction).\")\n","\n","            ok, msg = schema_is_valid(parsed)\n","            if not ok:\n","                raise ValueError(f\"Schema validation failed: {msg}\")\n","\n","            # Log prompt/response (redacted only)\n","            append_jsonl(PROMPTS_LOG_PATH, {\n","                \"ts_utc\": now_iso(),\n","                \"attempt\": attempt_idx,\n","                \"temperature\": t,\n","                \"task\": task,\n","                \"stage\": stage,\n","                \"matter_id\": matter_id,\n","                \"prompt_redacted\": payload,\n","                \"prompt_hash\": sha256_text(payload),\n","                \"response_hash\": sha256_text(json.dumps(parsed, ensure_ascii=False)),\n","            })\n","\n","            # Update risk log\n","            risk_log = json.loads(RISK_LOG_PATH.read_text(encoding=\"utf-8\"))\n","            for r in parsed.get(\"risks\", []):\n","                risk_log[\"risks\"].append({\n","                    \"ts_utc\": now_iso(),\n","                    \"matter_id\": matter_id,\n","                    \"stage\": stage,\n","                    **r\n","                })\n","            write_json(RISK_LOG_PATH, risk_log)\n","\n","            return parsed\n","\n","        except Exception as e:\n","            last_error = f\"Attempt {attempt_idx} failed: {repr(e)}\"\n","            # log failure minimally (redacted)\n","            append_jsonl(PROMPTS_LOG_PATH, {\n","                \"ts_utc\": now_iso(),\n","                \"attempt\": attempt_idx,\n","                \"temperature\": t,\n","                \"task\": task,\n","                \"stage\": stage,\n","                \"matter_id\": matter_id,\n","                \"prompt_redacted\": payload,\n","                \"prompt_hash\": sha256_text(payload),\n","                \"error\": last_error\n","            })\n","\n","    # Error fallback (MUST still match schema)\n","    fallback = {\n","        \"task\": task,\n","        \"stage\": stage,\n","        \"matter_id\": matter_id,\n","        \"facts_provided\": facts,\n","        \"assumptions\": [],\n","        \"open_questions\": [\"System error: JSON generation/parsing failed. Re-run with simpler facts or smaller content request.\"],\n","        \"controls_applied\": [\"prefill_json_enforcement\", \"retry_logic\", \"schema_validation\"],\n","        \"stage_output\": {\n","            \"type\": \"memo\",\n","            \"summary\": \"Error fallback generated. This stage did not complete successfully.\",\n","            \"items\": [\n","                \"This is a draft only. Not legal advice. Human lawyer review required.\",\n","                f\"Error: {last_error}\"\n","            ]\n","        },\n","        \"handoff\": {\n","            \"next_stage\": \"audit\",\n","            \"needs_human_approval\": True,\n","            \"approval_question\": \"Do you want to retry this stage with fewer facts and a shorter instruction?\",\n","            \"stop_if\": [\"Output remains invalid JSON after retry.\"]\n","        },\n","        \"risks\": [\n","            {\"type\": \"other\", \"severity\": \"high\", \"note\": f\"JSON_PARSE_ERROR: {last_error}\"}\n","        ],\n","        \"verification_status\": \"Not verified\",\n","        \"questions_to_verify\": []\n","    }\n","\n","    # add to risk log\n","    risk_log = json.loads(RISK_LOG_PATH.read_text(encoding=\"utf-8\"))\n","    for r in fallback[\"risks\"]:\n","        risk_log[\"risks\"].append({\"ts_utc\": now_iso(), \"matter_id\": matter_id, \"stage\": stage, **r})\n","    write_json(RISK_LOG_PATH, risk_log)\n","\n","    return fallback\n","\n","# ---- Smoke test (fast, minimal) ----\n","print(\"=\" * 70)\n","print(\"SMOKE TEST (Cell 6): Prefill JSON enforcement\")\n","print(\"=\" * 70)\n","\n","smoke = call_claude_json_prefill(\n","    task=\"smoke_test\",\n","    stage=\"intake\",\n","    matter_id=\"SMOKE-001\",\n","    facts=[\"Client sent a contract yesterday for review.\", \"No confidential details provided.\"],\n","    user_instruction=\"Create an intake checklist and 3 open questions. Keep stage_output.summary short.\"\n",")\n","\n","ok, msg = schema_is_valid(smoke)\n","print(\"Smoke test schema valid:\", ok, \"|\", msg)\n","print(\"Stage:\", smoke.get(\"stage\"), \"| Matter:\", smoke.get(\"matter_id\"))\n","print(\"Summary preview:\", (smoke.get(\"stage_output\", {}).get(\"summary\", \"\")[:120] + \"...\"))\n","print(\"=\" * 70)\n"],"metadata":{"id":"KRFtFfx3jjxl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767878881513,"user_tz":360,"elapsed":5330,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"6235a1b4-c8a4-4255-d8f0-30fd57015510"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","SMOKE TEST (Cell 6): Prefill JSON enforcement\n","======================================================================\n","Smoke test schema valid: True | ok\n","Stage: intake | Matter: SMOKE-001\n","Summary preview: Initial intake for contract review. Client has submitted document but scope and details remain undefined. Proceed to con...\n","======================================================================\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3690011035.py:6: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n"]}]},{"cell_type":"markdown","source":["##7.CASE BUILDERS"],"metadata":{"id":"DJNCfXIIjkPw"}},{"cell_type":"markdown","source":["###7.1.OVERVIEW"],"metadata":{"id":"XsBE2Am4jl8Z"}},{"cell_type":"markdown","source":["**Cell 7: Defining the “Mini-Firm” Pipeline and the Matters We Will Run**\n","\n","**What Cell 7 does**  \n","Cell 7 is where the notebook becomes a true organizational simulation. Instead of treating AI as a single-step drafting tool, we define a full workflow that resembles how a small firm or legal team actually operates. Cell 7 creates two essential things: the pipeline stages we will follow, and the set of matters (mini-cases) that will run through those stages.\n","\n","**The pipeline stages: the structure of the mini-firm**  \n","Cell 7 lays out the stages in a clear sequence. Each stage represents a different responsibility that, in real practice, might be handled by different people or checked by different controls. The stages are organized so that the system does not jump to conclusions too early. We begin by gathering information, then we check boundaries and risk, then we plan, then we draft, then we test quality, then we prepare for lawyer sign-off, and finally we create the audit bundle. This sequence is intentional: it prevents “draft-first thinking,” which is one of the main ways AI becomes risky in legal work.\n","\n","**The matters: why we use recurring mini-cases**  \n","Cell 7 also defines the matters the pipeline will process. We keep the same four domains across the entire book—Criminal, Regulatory/Administrative, International, and Teaching/Academia—so you can see how capabilities evolve across levels. At Level 5, the important shift is that each matter is no longer a single prompt. Each matter becomes a structured file of facts that the pipeline can process repeatedly and consistently.\n","\n","**Why the facts are concrete and bounded**  \n","In earlier chapters, vague facts and open-ended prompts made it too easy for the model to “fill in blanks” and produce confident-sounding content that was not grounded. In Cell 7, each matter includes concrete details, but still leaves some information missing. This is deliberate. We want the model to surface missing facts in the “open questions” field rather than quietly inventing them. This is one of the most important governance behaviors for legal AI.\n","\n","**Why the stage instructions are minimal**  \n","Cell 7 sets short, stage-specific instructions instead of long, complicated directions. The strict structure is enforced by the system prompt and schema in Cell 6, not by long user prompts. This design avoids triggering the model’s “explanation mode” and makes it more likely to produce clean, machine-readable outputs.\n","\n","**What you should see after Cell 7 runs**  \n","Cell 7 prints the pipeline stages and confirms the matters are loaded with their IDs and domains. This is your checkpoint that the notebook has a defined workflow and defined inputs. From here, Cell 8 can run the entire mini-firm simulation in a predictable, repeatable way.\n"],"metadata":{"id":"9n0xlWLwkYyX"}},{"cell_type":"markdown","source":["###7.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"lG1Zy3yNjolJ"}},{"cell_type":"code","source":["# Cell 7 (Code)\n","# Goal: Define the Chapter 5 mini-firm pipeline + 4 recurring matters (minimal prompts)\n","# Output: prints matter IDs and pipeline stages\n","\n","PIPELINE_STAGES = [\"intake\", \"conflicts\", \"scope\", \"workplan\", \"draft\", \"qa\", \"signoff\", \"audit\"]\n","\n","def build_matter(case_id: str, domain: str, facts: list):\n","    return {\n","        \"matter_id\": case_id,\n","        \"domain\": domain,\n","        \"facts\": facts\n","    }\n","\n","# Four recurring matters (sanitized, concrete, bounded)\n","MATTERS = [\n","    build_matter(\n","        \"CRIM-001\",\n","        \"Criminal\",\n","        [\n","            \"Defendant: Alex R. (redacted), first-time felony charge alleged (details unknown).\",\n","            \"Court date in 10 days; counsel must prepare for bail/conditions request.\",\n","            \"Employment: full-time (3 years) and stable housing; family in jurisdiction.\",\n","            \"Prior record: unknown; immigration status: unknown.\",\n","            \"Client’s main concern: avoid detention; keep job; comply with conditions.\"\n","        ]\n","    ),\n","    build_matter(\n","        \"REG-001\",\n","        \"Regulatory/Administrative\",\n","        [\n","            \"Client: First Community Bank ($2B assets; 15 branches).\",\n","            \"Proposed rule summary provided internally (not quoted): new reporting + controls within 120 days.\",\n","            \"Implementation cost estimate: $450k–$700k first year; 2 FTE ongoing.\",\n","            \"Vendor dependency: core banking vendor lead time 6–9 months.\",\n","            \"Goal: prepare comment strategy + verification list (no legal citations).\"\n","        ]\n","    ),\n","    build_matter(\n","        \"INTL-001\",\n","        \"International\",\n","        [\n","            \"Client: US services company contracting with vendor in another country (country not specified).\",\n","            \"Contract value: $1.2M/year; payment net-30; deliverables monthly.\",\n","            \"Prior dispute with vendor over delays (informal emails only).\",\n","            \"Client prefers faster dispute resolution; cost-sensitive; wants predictable enforcement.\",\n","            \"Need options: governing law + forum/arbitration (must be 'Not verified').\"\n","        ]\n","    ),\n","    build_matter(\n","        \"TEACH-001\",\n","        \"Teaching/Academia\",\n","        [\n","            \"Course: Contracts (upper-level), 60 students, mixed assessments (memo + exam).\",\n","            \"Instructor wants AI allowed for brainstorming but not for final graded submissions.\",\n","            \"Existing honor code exists (not quoted).\",\n","            \"Concern: fairness, disclosure, enforceability, and clear edge-case handling.\",\n","            \"Goal: produce policy + FAQ + enforcement checklist.\"\n","        ]\n","    ),\n","]\n","\n","# Minimal per-stage instruction patterns (keep short to avoid “explanatory mode”)\n","STAGE_INSTRUCTIONS = {\n","    \"intake\":   \"Create a structured intake checklist and 5 open questions. No citations.\",\n","    \"conflicts\":\"Create a conflicts/engagement-risk checklist + 5 questions to verify conflicts and scope boundaries.\",\n","    \"scope\":    \"Draft a scope statement (bullet items) + out-of-scope list + assumptions; keep it practical.\",\n","    \"workplan\": \"Create a 7-step workplan with human approval gates and audit artifacts to save at each step.\",\n","    \"draft\":    \"Produce a draft work product appropriate to the domain (<= 350 words) with disclaimer included.\",\n","    \"qa\":       \"Run QA + red-team: list weakest links, missing facts, and prompt-injection risks; propose fixes.\",\n","    \"signoff\":  \"Create a sign-off package: what the lawyer must review, what must be verified, and client-safe messaging notes.\",\n","    \"audit\":    \"Create an audit bundle index: list all artifacts produced, hashes to compute, and replay instructions.\"\n","}\n","\n","print(\"Pipeline stages:\", PIPELINE_STAGES)\n","print(\"\\nMatters loaded:\")\n","for m in MATTERS:\n","    print(\"-\", m[\"matter_id\"], \"|\", m[\"domain\"])\n"],"metadata":{"id":"vr1Zv5vTjqQk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767878906606,"user_tz":360,"elapsed":15,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"babd9d23-4426-4dab-b800-c7f90a7337f1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Pipeline stages: ['intake', 'conflicts', 'scope', 'workplan', 'draft', 'qa', 'signoff', 'audit']\n","\n","Matters loaded:\n","- CRIM-001 | Criminal\n","- REG-001 | Regulatory/Administrative\n","- INTL-001 | International\n","- TEACH-001 | Teaching/Academia\n"]}]},{"cell_type":"markdown","source":["##8.EXECUTION"],"metadata":{"id":"JkTAbrbOjqv_"}},{"cell_type":"markdown","source":["###8.1.OVERVIEW"],"metadata":{"id":"b99o2uIcjsOl"}},{"cell_type":"markdown","source":["**Cell 8: Executing the Full Mini-Firm Workflow and Saving Stage-by-Stage Deliverables**\n","\n","**What Cell 8 does**  \n","Cell 8 is where the notebook actually “runs the firm.” It takes each matter defined in Cell 7 and pushes it through every stage of the pipeline in order. For each matter, it calls the Claude wrapper from Cell 6 at each stage, receives a structured JSON result, and saves that result as a durable deliverable. The output is not a single document; it is a complete sequence of artifacts that shows how the final work product was produced and reviewed.\n","\n","**How the notebook runs matters through stages**  \n","Cell 8 loops over matters one by one. For each matter, it runs stage-by-stage: intake, conflicts, scope, workplan, drafting, QA/red-team, sign-off preparation, and audit packaging. At each stage, it uses the same pattern: it sends the matter’s facts plus a short stage instruction, and it requires the model to return a strictly structured response. This consistency is the point. The goal is a repeatable operational workflow, not an ad hoc conversation.\n","\n","**What gets saved at every stage and why it matters**  \n","For each stage, Cell 8 saves two files: a structured JSON file and a human-readable text file. The JSON file preserves the supervisory structure: facts, assumptions, open questions, controls applied, stage output, handoff instructions, risks, and verification tasks. The text file is designed for quick review by a lawyer who wants to read the output without opening JSON. Saving both formats ensures the work is both auditable and practical.\n","\n","**Progress indicators and transparency**  \n","Cell 8 prints clear progress messages such as which matter is running and which stage is currently being processed. This is not cosmetic. In organizational workflows, visibility matters. If something breaks, you want to know exactly where it broke, and you want to see which outputs were already saved.\n","\n","**Human-in-the-loop gates are simulated here**  \n","Cell 8 also demonstrates approval gates. In real legal operations, certain transitions require human confirmation, such as approving the plan before drafting or approving the sign-off package before client-facing use. In the notebook, these approvals are simulated with simple on/off settings. The important idea is not the mechanism; it is the discipline: the pipeline is designed to stop or pause when human review is required.\n","\n","**Error handling: why the pipeline keeps going**  \n","Cell 8 is built to be resilient. If a stage fails for a particular matter—for example, due to a temporary API issue or an unexpected parsing problem—the notebook does not collapse. Instead, it catches the error, records it, generates a structured fallback deliverable, and continues. This is essential in real organizations. A brittle system encourages people to bypass controls when something goes wrong. A resilient system preserves governance even under failure.\n","\n","**Statistics and final summary**  \n","At the end of the run, Cell 8 prints a summary table showing each matter’s status, how many stages completed, and the highest risk severity encountered. It also reports totals, such as how many model calls were made and how many stage runs succeeded or failed. This summary is the supervisor’s dashboard in miniature: a quick way to understand what happened and where attention is needed.\n","\n","**What you should have after Cell 8 completes**  \n","You should end Cell 8 with a deliverables folder containing subfolders for each matter, and inside each subfolder a complete trail of stage outputs. This is the defining feature of Chapter 5: instead of a single draft, you have an organized, reviewable, replayable record of an AI-assisted legal workflow.\n"],"metadata":{"id":"aS-JzPa3ka9V"}},{"cell_type":"markdown","source":["###8.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"dRNaC7A2juTs"}},{"cell_type":"code","source":["# Cell 8 (Code)\n","# Goal: Run the full Chapter 5 “mini-firm” pipeline across 4 matters with robust error handling\n","# Output: progress indicators + summary table + paths to deliverables\n","\n","def save_stage_outputs(matter_id: str, stage: str, obj: dict):\n","    case_dir = DELIVER_DIR / matter_id\n","    case_dir.mkdir(parents=True, exist_ok=True)\n","\n","    json_path = case_dir / f\"{stage}_output.json\"\n","    txt_path = case_dir / f\"{stage}_output.txt\"\n","\n","    write_json(json_path, obj)\n","\n","    # Human-readable rendering (no external links)\n","    lines = []\n","    lines.append(\"This is a draft only. Not legal advice. Human lawyer review required.\\n\")\n","    lines.append(f\"Matter: {matter_id} | Stage: {stage}\\n\")\n","    lines.append(\"FACTS PROVIDED:\\n- \" + \"\\n- \".join(obj.get(\"facts_provided\", [])) + \"\\n\")\n","    lines.append(\"ASSUMPTIONS:\\n- \" + \"\\n- \".join(obj.get(\"assumptions\", [])) + \"\\n\")\n","    lines.append(\"OPEN QUESTIONS:\\n- \" + \"\\n- \".join(obj.get(\"open_questions\", [])) + \"\\n\")\n","    lines.append(\"CONTROLS APPLIED:\\n- \" + \"\\n- \".join(obj.get(\"controls_applied\", [])) + \"\\n\")\n","\n","    so = obj.get(\"stage_output\", {})\n","    lines.append(f\"STAGE OUTPUT TYPE: {so.get('type','')}\\n\")\n","    lines.append(f\"SUMMARY:\\n{so.get('summary','')}\\n\")\n","    items = so.get(\"items\", [])\n","    if items:\n","        lines.append(\"ITEMS:\\n- \" + \"\\n- \".join(items) + \"\\n\")\n","\n","    ho = obj.get(\"handoff\", {})\n","    lines.append(\"HANDOFF:\\n\")\n","    lines.append(f\"- next_stage: {ho.get('next_stage','')}\\n\")\n","    lines.append(f\"- needs_human_approval: {ho.get('needs_human_approval', True)}\\n\")\n","    lines.append(f\"- approval_question: {ho.get('approval_question','')}\\n\")\n","    stop_if = ho.get(\"stop_if\", [])\n","    if stop_if:\n","        lines.append(\"STOP IF:\\n- \" + \"\\n- \".join(stop_if) + \"\\n\")\n","\n","    risks = obj.get(\"risks\", [])\n","    if risks:\n","        lines.append(\"RISKS:\\n\" + \"\\n\".join([f\"- ({r.get('severity')}) {r.get('type')}: {r.get('note')}\" for r in risks]) + \"\\n\")\n","\n","    lines.append(\"VERIFICATION STATUS: Not verified\\n\")\n","    qv = obj.get(\"questions_to_verify\", [])\n","    if qv:\n","        lines.append(\"QUESTIONS TO VERIFY:\\n- \" + \"\\n- \".join(qv) + \"\\n\")\n","\n","    txt_path.write_text(\"\".join(lines), encoding=\"utf-8\")\n","    return str(json_path), str(txt_path)\n","\n","# Human-in-the-loop gates (simulate approvals)\n","APPROVE_PLAN = True\n","APPROVE_FINAL = True\n","\n","stats = {\n","    \"total_matters\": len(MATTERS),\n","    \"matters_success\": 0,\n","    \"matters_failed\": 0,\n","    \"total_calls\": 0,\n","    \"stage_success\": 0,\n","    \"stage_failed\": 0\n","}\n","\n","summary_rows = []\n","\n","for mi, matter in enumerate(MATTERS, start=1):\n","    matter_id = matter[\"matter_id\"]\n","    domain = matter[\"domain\"]\n","    facts = matter[\"facts\"]\n","\n","    print(f\"\\n[Case {mi}/{len(MATTERS)}] Processing matter: {matter_id} ({domain})\")\n","    case_ok = True\n","    stages_completed = 0\n","    highest_sev = \"low\"\n","\n","    for si, stage in enumerate(PIPELINE_STAGES, start=1):\n","        print(f\"  [Stage {si}/{len(PIPELINE_STAGES)}] {stage} ...\")\n","\n","        # Simulated gates\n","        if stage == \"workplan\" and not APPROVE_PLAN:\n","            print(\"    ❌ Skipped (plan not approved).\")\n","            case_ok = False\n","            break\n","        if stage == \"signoff\" and not APPROVE_FINAL:\n","            print(\"    ❌ Skipped (final not approved).\")\n","            case_ok = False\n","            break\n","\n","        try:\n","            instruction = STAGE_INSTRUCTIONS[stage]\n","\n","            result = call_claude_json_prefill(\n","                task=f\"Chapter5_{domain}_{stage}\",\n","                stage=stage,\n","                matter_id=matter_id,\n","                facts=facts,\n","                user_instruction=instruction,\n","                max_tokens=max(MIN_MAX_TOKENS, 1800)\n","            )\n","            stats[\"total_calls\"] += 1\n","\n","            # add a few controls_applied locally (defense-in-depth)\n","            result[\"controls_applied\"] = list(set(result.get(\"controls_applied\", []) + [\n","                \"redaction_default\",\n","                \"no_invented_authority\",\n","                \"verification_status_not_verified\",\n","                \"prefill_json_enforcement\",\n","                \"schema_validation\",\n","                \"stage_based_gates\"\n","            ]))\n","\n","            jp, tp = save_stage_outputs(matter_id, stage, result)\n","            print(\"    ✅ Saved:\", jp)\n","            stages_completed += 1\n","            stats[\"stage_success\"] += 1\n","\n","            # compute highest severity\n","            sev_rank = {\"low\": 1, \"medium\": 2, \"high\": 3}\n","            for r in result.get(\"risks\", []):\n","                if sev_rank.get(r.get(\"severity\",\"low\"), 1) > sev_rank.get(highest_sev, 1):\n","                    highest_sev = r.get(\"severity\",\"low\")\n","\n","        except Exception as e:\n","            stats[\"stage_failed\"] += 1\n","            case_ok = False\n","            print(\"    ❌ Failed:\", repr(e))\n","            traceback.print_exc()\n","\n","            # create a valid error deliverable (schema-conformant)\n","            err_obj = {\n","                \"task\": f\"Chapter5_{domain}_{stage}\",\n","                \"stage\": stage,\n","                \"matter_id\": matter_id,\n","                \"facts_provided\": facts,\n","                \"assumptions\": [],\n","                \"open_questions\": [\"Stage failed due to a runtime error. Review error details and retry.\"],\n","                \"controls_applied\": [\"error_handling\", \"schema_conformant_fallback\"],\n","                \"stage_output\": {\n","                    \"type\": \"memo\",\n","                    \"summary\": \"Error fallback. Stage did not complete.\",\n","                    \"items\": [\n","                        \"This is a draft only. Not legal advice. Human lawyer review required.\",\n","                        f\"Error: {repr(e)}\"\n","                    ]\n","                },\n","                \"handoff\": {\n","                    \"next_stage\": \"audit\",\n","                    \"needs_human_approval\": True,\n","                    \"approval_question\": \"Do you want to retry this stage with fewer facts and a shorter instruction?\",\n","                    \"stop_if\": [\"Repeated errors or invalid JSON persists.\"]\n","                },\n","                \"risks\": [\n","                    {\"type\": \"other\", \"severity\": \"high\", \"note\": f\"RUNTIME_ERROR: {repr(e)}\"}\n","                ],\n","                \"verification_status\": \"Not verified\",\n","                \"questions_to_verify\": []\n","            }\n","            save_stage_outputs(matter_id, stage, err_obj)\n","            highest_sev = \"high\"\n","            # proceed to next stage (continue processing despite failure)\n","            continue\n","\n","    if case_ok:\n","        stats[\"matters_success\"] += 1\n","        status = \"✅\"\n","    else:\n","        stats[\"matters_failed\"] += 1\n","        status = \"❌\"\n","\n","    summary_rows.append((matter_id, domain, status, stages_completed, highest_sev))\n","\n","# Print summary table\n","print(\"\\n\" + \"=\" * 70)\n","print(\"CHAPTER 5 PIPELINE SUMMARY\")\n","print(\"=\" * 70)\n","print(f\"Matters: {stats['total_matters']} | Success: {stats['matters_success']} | Failed: {stats['matters_failed']}\")\n","print(f\"Stages success: {stats['stage_success']} | Stages failed: {stats['stage_failed']} | API calls: {stats['total_calls']}\")\n","print(\"-\" * 70)\n","print(f\"{'Matter':<10} {'Domain':<22} {'Status':<6} {'Stages':<7} {'TopRisk':<7}\")\n","print(\"-\" * 70)\n","for r in summary_rows:\n","    print(f\"{r[0]:<10} {r[1]:<22} {r[2]:<6} {str(r[3]):<7} {r[4]:<7}\")\n","print(\"-\" * 70)\n","print(\"Deliverables root:\", str(DELIVER_DIR))\n","print(\"=\" * 70)\n"],"metadata":{"id":"pzSrHbYcjwPJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767879510909,"user_tz":360,"elapsed":546222,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"5067f8d8-fda8-4a47-e884-57adf43cb539"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[Case 1/4] Processing matter: CRIM-001 (Criminal)\n","  [Stage 1/8] intake ...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3690011035.py:6: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n"]},{"output_type":"stream","name":"stdout","text":["    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/CRIM-001/intake_output.json\n","  [Stage 2/8] conflicts ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/CRIM-001/conflicts_output.json\n","  [Stage 3/8] scope ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/CRIM-001/scope_output.json\n","  [Stage 4/8] workplan ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/CRIM-001/workplan_output.json\n","  [Stage 5/8] draft ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/CRIM-001/draft_output.json\n","  [Stage 6/8] qa ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/CRIM-001/qa_output.json\n","  [Stage 7/8] signoff ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/CRIM-001/signoff_output.json\n","  [Stage 8/8] audit ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/CRIM-001/audit_output.json\n","\n","[Case 2/4] Processing matter: REG-001 (Regulatory/Administrative)\n","  [Stage 1/8] intake ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/REG-001/intake_output.json\n","  [Stage 2/8] conflicts ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/REG-001/conflicts_output.json\n","  [Stage 3/8] scope ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/REG-001/scope_output.json\n","  [Stage 4/8] workplan ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/REG-001/workplan_output.json\n","  [Stage 5/8] draft ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/REG-001/draft_output.json\n","  [Stage 6/8] qa ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/REG-001/qa_output.json\n","  [Stage 7/8] signoff ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/REG-001/signoff_output.json\n","  [Stage 8/8] audit ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/REG-001/audit_output.json\n","\n","[Case 3/4] Processing matter: INTL-001 (International)\n","  [Stage 1/8] intake ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/INTL-001/intake_output.json\n","  [Stage 2/8] conflicts ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/INTL-001/conflicts_output.json\n","  [Stage 3/8] scope ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/INTL-001/scope_output.json\n","  [Stage 4/8] workplan ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/INTL-001/workplan_output.json\n","  [Stage 5/8] draft ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/INTL-001/draft_output.json\n","  [Stage 6/8] qa ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/INTL-001/qa_output.json\n","  [Stage 7/8] signoff ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/INTL-001/signoff_output.json\n","  [Stage 8/8] audit ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/INTL-001/audit_output.json\n","\n","[Case 4/4] Processing matter: TEACH-001 (Teaching/Academia)\n","  [Stage 1/8] intake ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/TEACH-001/intake_output.json\n","  [Stage 2/8] conflicts ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/TEACH-001/conflicts_output.json\n","  [Stage 3/8] scope ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/TEACH-001/scope_output.json\n","  [Stage 4/8] workplan ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/TEACH-001/workplan_output.json\n","  [Stage 5/8] draft ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/TEACH-001/draft_output.json\n","  [Stage 6/8] qa ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/TEACH-001/qa_output.json\n","  [Stage 7/8] signoff ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/TEACH-001/signoff_output.json\n","  [Stage 8/8] audit ...\n","    ✅ Saved: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables/TEACH-001/audit_output.json\n","\n","======================================================================\n","CHAPTER 5 PIPELINE SUMMARY\n","======================================================================\n","Matters: 4 | Success: 4 | Failed: 0\n","Stages success: 32 | Stages failed: 0 | API calls: 32\n","----------------------------------------------------------------------\n","Matter     Domain                 Status Stages  TopRisk\n","----------------------------------------------------------------------\n","CRIM-001   Criminal               ✅      8       high   \n","REG-001    Regulatory/Administrative ✅      8       high   \n","INTL-001   International          ✅      8       high   \n","TEACH-001  Teaching/Academia      ✅      8       high   \n","----------------------------------------------------------------------\n","Deliverables root: /content/ai_law_ch5_runs/run_20260108T131732Z/deliverables\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##9.USER'S EXERCISES"],"metadata":{"id":"DNWQdm9Mjws3"}},{"cell_type":"markdown","source":["###9.1.OVERVIEW"],"metadata":{"id":"Ze1FRb6mjxsg"}},{"cell_type":"markdown","source":["**Cell 9: Your Matter Exercise (Safe Intake, Redaction, and a Shortened Organizational Pipeline)**\n","\n","**What Cell 9 does**  \n","Cell 9 lets you run the same Chapter 5 approach on your own scenario, but in a controlled and safer way. Instead of processing one of the pre-defined matters from Cell 7, you provide a short, sanitized description of a matter. The notebook then applies the same governance principles: it redacts sensitive patterns, converts the text into minimum-necessary facts, and runs a shortened version of the mini-firm workflow to generate structured outputs and saved deliverables.\n","\n","**Why this exercise is intentionally “sanitized” and “shortened”**  \n","This notebook is a teaching tool, not a secure matter management system. In real practice, you would use approved systems, internal policies, and client consent standards before using any external model. Cell 9 therefore emphasizes a strict rule: do not paste confidential or privileged material. It also uses a shortened pipeline because the goal is learning the workflow pattern rather than recreating an entire production environment.\n","\n","**The intake and redaction step: your first safeguard**  \n","Cell 9 begins by asking you for a scenario. Before the model sees anything, the notebook applies redaction and shows you a summary of what was removed. This makes the privacy control visible. The point is not that redaction is perfect; it is that legal users must adopt a “minimum necessary” mindset and confirm what they are sending to a model.\n","\n","**Choosing a domain: matching the workflow to the matter type**  \n","Next, Cell 9 asks you to choose a domain such as criminal, regulatory, international, or teaching. This choice matters because it shapes what the drafting stage produces and what the QA stage focuses on. Even in a simplified exercise, organizational workflows must be sensitive to context. A one-size-fits-all prompt is a common cause of AI misuse in legal settings.\n","\n","**Running a shortened but governed pipeline**  \n","Cell 9 then runs several key stages that represent the organizational core: intake, scope, drafting, QA/red-team, sign-off preparation, and audit packaging. Even though it is shortened, it still preserves the Chapter 5 logic: do not draft first, do not skip QA, and do not treat outputs as final. Each stage produces structured outputs that include open questions, risks, and verification tasks.\n","\n","**What gets saved and why that is the real lesson**  \n","Just like the main run in Cell 8, Cell 9 saves outputs to a dedicated folder for your matter. You get both a JSON version and a human-readable text version per stage. This teaches the core habit of Level 5: AI outputs are not “messages.” They are workflow artifacts that must be reviewable, traceable, and easy to supervise.\n","\n","**What you should see after Cell 9 runs**  \n","You should see a confirmation of where your deliverables were saved and a clear record of the redaction summary. The most important outcome is not the draft itself. The most important outcome is that your matter went through a controlled sequence with explicit uncertainty, explicit risk flags, and a sign-off-oriented output that a lawyer can responsibly review.\n"],"metadata":{"id":"QDyRDRTtkcAt"}},{"cell_type":"markdown","source":["###9.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"5S-pgIxxj1cv"}},{"cell_type":"code","source":["# Cell 9 (Code)\n","# Goal: User exercise (sanitized intake) + run a shortened pipeline (still includes QA + signoff + audit)\n","# Output: redaction summary + saved paths\n","\n","print(\"USER EXERCISE (Do NOT paste confidential/privileged information.)\")\n","raw = input(\"\\nPaste a SANITIZED scenario (no names, no confidential facts). Press Enter when done:\\n> \").strip()\n","\n","mn = minimum_necessary_facts(raw)\n","print(\"\\nREDACTION SUMMARY (best-effort; imperfect):\")\n","print(json.dumps(mn[\"removed_fields\"], indent=2))\n","\n","# Choose domain workflow\n","domain_choice = input(\"\\nChoose domain: criminal | regulatory | international | teaching\\n> \").strip().lower()\n","domain_map = {\n","    \"criminal\": \"Criminal\",\n","    \"regulatory\": \"Regulatory/Administrative\",\n","    \"international\": \"International\",\n","    \"teaching\": \"Teaching/Academia\"\n","}\n","domain = domain_map.get(domain_choice, \"Regulatory/Administrative\")\n","\n","user_matter_id = f\"USER-{domain_choice[:4].upper()}-{RUN_ID[-6:]}\"\n","facts = mn[\"facts_bullets\"] if mn[\"facts_bullets\"] else [\"User provided minimal sanitized scenario; details missing.\"]\n","\n","SHORT_PIPELINE = [\"intake\", \"scope\", \"draft\", \"qa\", \"signoff\", \"audit\"]\n","\n","print(f\"\\nRunning shortened pipeline for: {user_matter_id} ({domain})\")\n","for stage in SHORT_PIPELINE:\n","    try:\n","        instruction = STAGE_INSTRUCTIONS.get(stage, \"Create a concise stage output. Return ONLY JSON.\")\n","        result = call_claude_json_prefill(\n","            task=f\"Chapter5_USER_{domain}_{stage}\",\n","            stage=stage,\n","            matter_id=user_matter_id,\n","            facts=facts,\n","            user_instruction=instruction,\n","            max_tokens=max(MIN_MAX_TOKENS, 1800)\n","        )\n","        result[\"controls_applied\"] = list(set(result.get(\"controls_applied\", []) + [\n","            \"user_exercise\",\n","            \"redaction_default\",\n","            \"prefill_json_enforcement\",\n","            \"schema_validation\"\n","        ]))\n","        jp, tp = save_stage_outputs(user_matter_id, stage, result)\n","        print(f\"  ✅ {stage}: saved {jp}\")\n","    except Exception as e:\n","        print(f\"  ❌ {stage} failed:\", repr(e))\n","        traceback.print_exc()\n","\n","print(\"\\nUser deliverables saved under:\", str(DELIVER_DIR / user_matter_id))\n"],"metadata":{"id":"JhDf9zHzj3Yr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##10.AUDIT ARTIFACTS"],"metadata":{"id":"wI0cvSCvj4CQ"}},{"cell_type":"markdown","source":["###10.1.OVERVIEW"],"metadata":{"id":"vzhRfU4Zj5Wl"}},{"cell_type":"markdown","source":["**Cell 10: Audit Readme and Final Bundle (Turning a Run into a Defensible Record)**\n","\n","**What Cell 10 does**  \n","Cell 10 is the closing step that turns everything you did in the notebook into a single, organized package. It creates a short audit readme that explains what the run produced and how to review it, and then it bundles the entire run directory into one compressed file. This is the moment where the notebook stops being “a series of outputs” and becomes an auditable record of a controlled workflow.\n","\n","**Why this step is essential for Level 5 (Organizations)**  \n","At an organizational level, the output is not just the final draft. The output is the chain of artifacts that supports supervision, quality control, and accountability. Without an audit bundle, you have a fragile situation: useful text exists, but you cannot easily show how it was created, what was assumed, what risks were flagged, or what needs verification. Cell 10 exists to prevent that. It is the institutional habit: preserve the run, make it reviewable, and make it reproducible.\n","\n","**The audit readme: what it provides**  \n","The audit readme is a plain-language map of the run. It identifies the run ID, model name, and the governance artifacts that were created. It explains what each artifact is for, and it provides a short review checklist that a supervising lawyer could follow. This matters because organizational review should not depend on the original notebook author remembering what happened. The audit readme makes the run self-explanatory.\n","\n","**What gets bundled and why the bundle is valuable**  \n","Cell 10 includes the run manifest, prompts log, risk log, dependency snapshot, and the full deliverables folder. In practical terms, this means you can hand the bundle to someone else—another lawyer, a supervisor, or an internal reviewer—and they can see what the system did without rerunning anything. The bundle also supports “replay” thinking: if someone wants to reproduce the run, the manifest and dependency snapshot provide the starting point.\n","\n","**How this differs from saving a chat transcript**  \n","Saving a chat transcript captures conversation, but it does not capture workflow structure, stage outputs, risk aggregation, or reproducibility context. The bundle produced by Cell 10 is more like a matter file: it is organized, stage-based, and designed for review. That is the key organizational difference. The notebook is not trying to be a better chat app. It is trying to behave like a controlled legal process.\n","\n","**What you should see after Cell 10 runs**  \n","You should see confirmation that the audit readme was created, a list of the top-level files in the run directory, and the path to the final compressed bundle. That bundle is the final product of Chapter 5: a complete mini-firm run packaged in a way that supports supervision, accountability, and safe iteration.\n"],"metadata":{"id":"UtT7WhulkdQp"}},{"cell_type":"markdown","source":["###10.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"vHS-9n2yj69I"}},{"cell_type":"code","source":["# Cell 10 (Code)\n","# Goal: AUDIT_README + zip bundle + print file list + zip path\n","# Output: zip path + included artifacts checklist\n","\n","AUDIT_README_PATH = RUN_DIR / \"AUDIT_README.txt\"\n","\n","audit_text = f\"\"\"\n","Chapter 5 — Level 5 (Organizations): Audit Readme\n","Run ID: {RUN_ID}\n","Timestamp (UTC): {now_iso()}\n","Model: {MODEL}\n","\n","DISCLAIMER\n","- This is a draft-only workflow demonstration. Not legal advice.\n","- Human lawyer review required for any reliance-bearing use.\n","- verification_status is always \"Not verified\" by design.\n","\n","ARTIFACTS\n","1) run_manifest.json\n","   - What: run configuration (model, params, environment, purpose)\n","   - Why: reproducibility + governance record\n","\n","2) prompts_log.jsonl\n","   - What: one record per Claude call (REDACTED prompt + hashes)\n","   - Why: audit trail without storing sensitive content\n","\n","3) risk_log.json\n","   - What: consolidated list of risk flags per matter per stage\n","   - Why: supervisory review + escalation\n","\n","4) pip_freeze.txt\n","   - What: dependency snapshot\n","   - Why: reproducibility\n","\n","5) deliverables/<matter_id>/\n","   - Each stage produces:\n","     - <stage>_output.json (structured)\n","     - <stage>_output.txt  (human-readable)\n","   - Why: traceable workflow outputs by stage\n","\n","REPLAY INSTRUCTIONS\n","- Re-run Cells 2–10 in order.\n","- Ensure ANTHROPIC_API_KEY is set in Colab Secrets.\n","- Compare hashes in prompts_log.jsonl if needed.\n","\n","REVIEW CHECKLIST (MINIMUM)\n","- Confirm no sensitive data was pasted.\n","- Review open_questions + questions_to_verify before any reliance.\n","- Confirm risks are understood and mitigated.\n","- Lawyer sign-off required before client-facing use.\n","\"\"\".strip()\n","\n","AUDIT_README_PATH.write_text(audit_text, encoding=\"utf-8\")\n","\n","# Zip the run directory\n","zip_path = Path(f\"{RUN_DIR}.zip\")\n","try:\n","    subprocess.check_call([\"bash\", \"-lc\", f\"cd {RUN_DIR.parent} && zip -qr {zip_path.name} {RUN_DIR.name}\"])\n","except Exception as e:\n","    raise RuntimeError(f\"Zip failed: {repr(e)}\")\n","\n","# Print file list (top-level)\n","print(\"Created AUDIT_README:\", str(AUDIT_README_PATH))\n","print(\"\\nTop-level files in run directory:\")\n","for p in sorted(RUN_DIR.glob(\"*\")):\n","    print(\" -\", p.name)\n","\n","print(\"\\nZip bundle:\", str(zip_path))\n","print(\"\\nIncluded checklist:\")\n","print(\" - run_manifest.json\")\n","print(\" - prompts_log.jsonl\")\n","print(\" - risk_log.json\")\n","print(\" - pip_freeze.txt\")\n","print(\" - deliverables/ (per matter per stage JSON + TXT)\")\n","print(\" - AUDIT_README.txt\")\n"],"metadata":{"id":"wPDfj-45j8c5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##11.CONCLUSIONS"],"metadata":{"id":"GacXZ2Fzj9V8"}},{"cell_type":"markdown","source":["**Conclusion: The Chapter 5 Mini-Firm Pipeline, Step by Step**\n","\n","This notebook is a practical demonstration of what it means to use generative AI at **Level 5 (Organizations)**: not as a conversational chatbot that “answers questions,” but as a component inside a **governed legal workflow**. The central lesson is simple and non-negotiable: once AI becomes part of an organization’s work product pipeline, the relevant question is no longer “Did the model draft something useful?” The relevant question becomes “Can we explain, reproduce, supervise, and defend how this draft was produced—without compromising confidentiality, privilege, or accuracy?” Chapter 5 answers that question by building a mini-firm simulation that mirrors how real legal work should flow, stage by stage, with explicit controls and an audit trail.\n","\n","**Step 1: Intake (structured capture of what we know and what we do not know)**  \n","The pipeline begins with intake because legal work is only as good as the facts you start with. In this stage, the notebook converts a user’s scenario into **sanitized, minimum-necessary facts** and then forces the system to generate an intake output that is not a “solution,” but a **checklist and a set of open questions**. That difference matters. A chatbot tries to be helpful by “finishing the task.” A governed pipeline must first define the task boundary and expose missing inputs. Intake produces a structured artifact that a lawyer can review quickly: the facts provided, assumptions being made, and a list of information needed before any reliance.\n","\n","**Step 2: Conflicts and engagement risk checks (organizational safeguards before work begins)**  \n","Next, the notebook simulates the early institutional gatekeeping that many lawyers skip when using consumer chat tools. Conflicts checks, engagement boundaries, and risk triggers (such as sensitive parties or unclear representation) are not optional in organizational practice. This stage creates a conflicts/engagement checklist and highlights what must be verified internally before substantive drafting proceeds. The output is designed to support supervision: it does not “decide” representation; it enumerates what the firm must confirm.\n","\n","**Step 3: Scope definition (what is in, what is out, and what is explicitly not being done)**  \n","Scope is where legal risk often hides, especially with AI. Without scope discipline, an AI draft can drift into advice outside the agreed task, or use assumptions as if they were facts. This stage outputs a scope statement in plain terms: deliverables, constraints, and an explicit out-of-scope list. It also forces the separation between “facts provided” and “assumptions,” which is one of the most important professional responsibility controls in AI-assisted practice. A scope artifact is not busywork; it is a guardrail.\n","\n","**Step 4: Workplan (a supervised sequence with human gates and artifact expectations)**  \n","The workplan stage converts the matter into a plan with **human approval points** and a list of artifacts to preserve. This is the organizational shift: rather than asking the AI to jump straight into a draft, we require a structured sequence—what happens next, what decisions require human confirmation, and what to store to maintain a defensible record. The workplan stage is where the “mini-firm” becomes visible: it defines roles, steps, and stop conditions, and it makes supervision operational instead of aspirational.\n","\n","**Step 5: Drafting (a controlled work product draft, never a final answer)**  \n","Only after intake, checks, scope, and plan do we draft. Even here, the notebook’s goal is not to produce a final legal conclusion; it is to produce a **draft work product** suitable for lawyer review. The drafting stage is deliberately constrained: it includes disclaimers, avoids invented authority, and remains “Not verified.” The key is that drafting is no longer a standalone event. It is one stage inside a system that already knows what is missing and what must be verified.\n","\n","**Step 6: QA and red-team (stress testing before anyone relies on the output)**  \n","Quality assurance is where Level 5 differs sharply from casual chatbot use. This stage forces the system to identify weakest links, missing facts, tone risks, and prompt-injection style vulnerabilities. Importantly, the red-team pass is not an abstract lecture; it is an output artifact that lists concrete failure modes and suggested fixes. In organizational use, QA is not a luxury. It is how you prevent plausible-sounding drafts from becoming unreviewed reliance.\n","\n","**Step 7: Sign-off package (what a supervising lawyer must review and verify)**  \n","In a real firm, the last mile is not “make the draft prettier.” The last mile is preparing a sign-off package that makes review efficient and responsible. This stage produces a structured review set: what must be checked, what must be verified, what can be safely communicated to a client, and what must remain tentative. This stage reinforces the central rule: the lawyer owns the final output, and the notebook is designed to make that ownership manageable rather than overwhelming.\n","\n","**Step 8: Audit bundle (reproducibility, traceability, and organizational memory)**  \n","Finally, the pipeline generates an audit index and bundles the run. This is the organizational maturity move that most chatbot usage lacks. The notebook records a manifest of the environment and model, a prompts log (redacted), a risk log, and staged deliverables. The point is not to create paperwork for its own sake; it is to enable accountability. If a question arises later—what was asked, what was assumed, what was produced, and what risks were identified—this pipeline can answer it.\n","\n","**Why the pipeline works (and why it must be different for legal use)**  \n","A consumer chatbot optimizes for conversational helpfulness. This pipeline optimizes for supervised legal operations: minimal sensitive input, structured uncertainty, explicit verification tasks, and retained artifacts. That is the core of Chapter 5: a mini-firm that transforms AI from a “clever text generator” into a governed workflow component. In practice, this is how legal organizations can use AI safely: not by trusting the model more, but by designing the process so trust is never required.\n"],"metadata":{"id":"TWRRC-L_0HAX"}}]}